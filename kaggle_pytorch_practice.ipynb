{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5444/2393603853.py:17: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X = pd.concat([X[['age','hypertension','heart_disease','avg_glucose_level','bmi']],pd.get_dummies(data=X[['gender','work_type','ever_married','smoking_status','Residence_type']])],1)\n",
      "/home/pedro/anaconda3/envs/dc_claas/lib/python3.9/site-packages/imblearn/utils/_validation.py:586: FutureWarning: Pass sampling_strategy=0.5 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Lambda, ToTensor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "dataset = pd.read_csv('/home/pedro/Documentos/Kaggle_DSs/full_data.csv')\n",
    "\n",
    "y = dataset.iloc[:,-1]\n",
    "X = dataset.iloc[:,:-1] \n",
    "from imblearn import under_sampling, over_sampling\n",
    "\n",
    "X = pd.concat([X[['age','hypertension','heart_disease','avg_glucose_level','bmi']],pd.get_dummies(data=X[['gender','work_type','ever_married','smoking_status','Residence_type']])],1)\n",
    "X[['age','avg_glucose_level','bmi']] = RobustScaler().fit_transform(X[['age','avg_glucose_level','bmi']])\n",
    "X, y = over_sampling.SMOTE(0.5).fit_resample(X=X,y=y)\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.values.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.values.astype(np.float32))\n",
    "y_train = torch.from_numpy(np.array(y_train))\n",
    "y_test = torch.from_numpy(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor_ds(object):\n",
    "    def __init__(self,tensor:torch.Tensor):\n",
    "        self.X = tensor[:,:-1]\n",
    "        self.y = tensor[:,-1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,values):\n",
    "        return self.X[values], self.y[values]\n",
    "\n",
    "tensor_train = torch.concat((X_train, y_train.unsqueeze(1)), dim=1)\n",
    "\n",
    "train_loader = DataLoader(dataset=tensor_ds(tensor_train), batch_size=math.floor(X_train.shape[0]/100), shuffle=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, math.floor(input_size/5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.floor(input_size/5), math.floor(input_size/10)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.floor(input_size/10), output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        logits = nn.Sigmoid()(logits)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(X_train.shape[1],2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the iteration number 0 - loss = 0.6602738499641418\n",
      "this is the iteration number 1 - loss = 0.675442636013031\n",
      "this is the iteration number 2 - loss = 0.6784647703170776\n",
      "this is the iteration number 3 - loss = 0.6661836504936218\n",
      "this is the iteration number 4 - loss = 0.6570139527320862\n",
      "this is the iteration number 5 - loss = 0.662989616394043\n",
      "this is the iteration number 6 - loss = 0.6629227995872498\n",
      "this is the iteration number 7 - loss = 0.6876126527786255\n",
      "this is the iteration number 8 - loss = 0.6596928834915161\n",
      "this is the iteration number 9 - loss = 0.7031499147415161\n",
      "this is the iteration number 10 - loss = 0.6564534902572632\n",
      "this is the iteration number 11 - loss = 0.6719925999641418\n",
      "this is the iteration number 12 - loss = 0.6469303965568542\n",
      "this is the iteration number 13 - loss = 0.6625171899795532\n",
      "this is the iteration number 14 - loss = 0.6561751961708069\n",
      "this is the iteration number 15 - loss = 0.6686921119689941\n",
      "this is the iteration number 16 - loss = 0.6939007043838501\n",
      "this is the iteration number 17 - loss = 0.6654413342475891\n",
      "this is the iteration number 18 - loss = 0.6717292666435242\n",
      "this is the iteration number 19 - loss = 0.6685041785240173\n",
      "this is the iteration number 20 - loss = 0.66529381275177\n",
      "this is the iteration number 21 - loss = 0.6843734979629517\n",
      "this is the iteration number 22 - loss = 0.6683909296989441\n",
      "this is the iteration number 23 - loss = 0.6811534762382507\n",
      "this is the iteration number 24 - loss = 0.6651030778884888\n",
      "this is the iteration number 25 - loss = 0.6650559306144714\n",
      "this is the iteration number 26 - loss = 0.6746669411659241\n",
      "this is the iteration number 27 - loss = 0.6844293475151062\n",
      "this is the iteration number 28 - loss = 0.6714206337928772\n",
      "this is the iteration number 29 - loss = 0.6681504249572754\n",
      "this is the iteration number 30 - loss = 0.6778016090393066\n",
      "this is the iteration number 31 - loss = 0.6582786440849304\n",
      "this is the iteration number 32 - loss = 0.6582179665565491\n",
      "this is the iteration number 33 - loss = 0.6647422909736633\n",
      "this is the iteration number 34 - loss = 0.6646298170089722\n",
      "this is the iteration number 35 - loss = 0.6711324453353882\n",
      "this is the iteration number 36 - loss = 0.6611226797103882\n",
      "this is the iteration number 37 - loss = 0.680930495262146\n",
      "this is the iteration number 38 - loss = 0.6678690910339355\n",
      "this is the iteration number 39 - loss = 0.6577605605125427\n",
      "this is the iteration number 40 - loss = 0.6510682702064514\n",
      "this is the iteration number 41 - loss = 0.6642618775367737\n",
      "this is the iteration number 42 - loss = 0.6808434128761292\n",
      "this is the iteration number 43 - loss = 0.6541479229927063\n",
      "this is the iteration number 44 - loss = 0.6808081865310669\n",
      "this is the iteration number 45 - loss = 0.664044201374054\n",
      "this is the iteration number 46 - loss = 0.6639910936355591\n",
      "this is the iteration number 47 - loss = 0.6673012375831604\n",
      "this is the iteration number 48 - loss = 0.6605125665664673\n",
      "this is the iteration number 49 - loss = 0.6705862283706665\n",
      "this is the iteration number 50 - loss = 0.6773189306259155\n",
      "this is the iteration number 51 - loss = 0.663602888584137\n",
      "this is the iteration number 52 - loss = 0.6670714616775513\n",
      "this is the iteration number 53 - loss = 0.6397690176963806\n",
      "this is the iteration number 54 - loss = 0.6635621190071106\n",
      "this is the iteration number 55 - loss = 0.6840527653694153\n",
      "this is the iteration number 56 - loss = 0.660021960735321\n",
      "this is the iteration number 57 - loss = 0.677147388458252\n",
      "this is the iteration number 58 - loss = 0.659902036190033\n",
      "this is the iteration number 59 - loss = 0.6494869589805603\n",
      "this is the iteration number 60 - loss = 0.6597784757614136\n",
      "this is the iteration number 61 - loss = 0.6389114260673523\n",
      "this is the iteration number 62 - loss = 0.6492184996604919\n",
      "this is the iteration number 63 - loss = 0.6700257658958435\n",
      "this is the iteration number 64 - loss = 0.6629969477653503\n",
      "this is the iteration number 65 - loss = 0.6734389066696167\n",
      "this is the iteration number 66 - loss = 0.6663880348205566\n",
      "this is the iteration number 67 - loss = 0.6944699287414551\n",
      "this is the iteration number 68 - loss = 0.6698194146156311\n",
      "this is the iteration number 69 - loss = 0.6486035585403442\n",
      "this is the iteration number 70 - loss = 0.6626749038696289\n",
      "this is the iteration number 71 - loss = 0.673252284526825\n",
      "this is the iteration number 72 - loss = 0.6554649472236633\n",
      "this is the iteration number 73 - loss = 0.6518389582633972\n",
      "this is the iteration number 74 - loss = 0.6731600165367126\n",
      "this is the iteration number 75 - loss = 0.6624082326889038\n",
      "this is the iteration number 76 - loss = 0.669517457485199\n",
      "this is the iteration number 77 - loss = 0.6514939069747925\n",
      "this is the iteration number 78 - loss = 0.6766325831413269\n",
      "this is the iteration number 79 - loss = 0.6802127957344055\n",
      "this is the iteration number 80 - loss = 0.6693698167800903\n",
      "this is the iteration number 81 - loss = 0.6584874987602234\n",
      "this is the iteration number 82 - loss = 0.6403178572654724\n",
      "this is the iteration number 83 - loss = 0.6439092755317688\n",
      "this is the iteration number 84 - loss = 0.6764979958534241\n",
      "this is the iteration number 85 - loss = 0.6582468152046204\n",
      "this is the iteration number 86 - loss = 0.6618384122848511\n",
      "this is the iteration number 87 - loss = 0.6689510941505432\n",
      "this is the iteration number 88 - loss = 0.6727360486984253\n",
      "this is the iteration number 89 - loss = 0.6579794883728027\n",
      "this is the iteration number 90 - loss = 0.6874061226844788\n",
      "this is the iteration number 91 - loss = 0.668945848941803\n",
      "this is the iteration number 92 - loss = 0.6578425765037537\n",
      "this is the iteration number 93 - loss = 0.676202118396759\n",
      "this is the iteration number 94 - loss = 0.6503207087516785\n",
      "this is the iteration number 95 - loss = 0.650252640247345\n",
      "this is the iteration number 96 - loss = 0.6948460936546326\n",
      "this is the iteration number 97 - loss = 0.6687434911727905\n",
      "this is the iteration number 98 - loss = 0.6724628806114197\n",
      "this is the iteration number 99 - loss = 0.6499954462051392\n",
      "this is the iteration number 100 - loss = 0.6686649918556213\n",
      "this is the iteration number 101 - loss = 0.694089949131012\n",
      "this is the iteration number 0 - loss = 0.6535693407058716\n",
      "this is the iteration number 1 - loss = 0.6648096442222595\n",
      "this is the iteration number 2 - loss = 0.6722796559333801\n",
      "this is the iteration number 3 - loss = 0.6683676838874817\n",
      "this is the iteration number 4 - loss = 0.6760860085487366\n",
      "this is the iteration number 5 - loss = 0.6798211932182312\n",
      "this is the iteration number 6 - loss = 0.6683100461959839\n",
      "this is the iteration number 7 - loss = 0.6798533201217651\n",
      "this is the iteration number 8 - loss = 0.6570205092430115\n",
      "this is the iteration number 9 - loss = 0.6835876107215881\n",
      "this is the iteration number 10 - loss = 0.6532546877861023\n",
      "this is the iteration number 11 - loss = 0.6493247747421265\n",
      "this is the iteration number 12 - loss = 0.6567922234535217\n",
      "this is the iteration number 13 - loss = 0.6491106152534485\n",
      "this is the iteration number 14 - loss = 0.6720353364944458\n",
      "this is the iteration number 15 - loss = 0.675861656665802\n",
      "this is the iteration number 16 - loss = 0.6642902493476868\n",
      "this is the iteration number 17 - loss = 0.6681103706359863\n",
      "this is the iteration number 18 - loss = 0.6603530645370483\n",
      "this is the iteration number 19 - loss = 0.6641789674758911\n",
      "this is the iteration number 20 - loss = 0.6563892960548401\n",
      "this is the iteration number 21 - loss = 0.6563164591789246\n",
      "this is the iteration number 22 - loss = 0.671840250492096\n",
      "this is the iteration number 23 - loss = 0.671798825263977\n",
      "this is the iteration number 24 - loss = 0.6717895865440369\n",
      "this is the iteration number 25 - loss = 0.6522242426872253\n",
      "this is the iteration number 26 - loss = 0.6560809016227722\n",
      "this is the iteration number 27 - loss = 0.6442635655403137\n",
      "this is the iteration number 28 - loss = 0.6638278961181641\n",
      "this is the iteration number 29 - loss = 0.6598500609397888\n",
      "this is the iteration number 30 - loss = 0.6795145869255066\n",
      "this is the iteration number 31 - loss = 0.6716485619544983\n",
      "this is the iteration number 32 - loss = 0.6597095727920532\n",
      "this is the iteration number 33 - loss = 0.6477766036987305\n",
      "this is the iteration number 34 - loss = 0.6278601288795471\n",
      "this is the iteration number 35 - loss = 0.6633805632591248\n",
      "this is the iteration number 36 - loss = 0.6475546956062317\n",
      "this is the iteration number 37 - loss = 0.6554620862007141\n",
      "this is the iteration number 38 - loss = 0.6513984799385071\n",
      "this is the iteration number 39 - loss = 0.6633533239364624\n",
      "this is the iteration number 40 - loss = 0.6271328926086426\n",
      "this is the iteration number 41 - loss = 0.6511794924736023\n",
      "this is the iteration number 42 - loss = 0.6632052659988403\n",
      "this is the iteration number 43 - loss = 0.655070424079895\n",
      "this is the iteration number 44 - loss = 0.671166718006134\n",
      "this is the iteration number 45 - loss = 0.6914738416671753\n",
      "this is the iteration number 46 - loss = 0.6670845746994019\n",
      "this is the iteration number 47 - loss = 0.65483158826828\n",
      "this is the iteration number 48 - loss = 0.6629369854927063\n",
      "this is the iteration number 49 - loss = 0.6710706949234009\n",
      "this is the iteration number 50 - loss = 0.6587899327278137\n",
      "this is the iteration number 51 - loss = 0.6669188141822815\n",
      "this is the iteration number 52 - loss = 0.6709944605827332\n",
      "this is the iteration number 53 - loss = 0.6915388107299805\n",
      "this is the iteration number 54 - loss = 0.6379942893981934\n",
      "this is the iteration number 55 - loss = 0.6750507354736328\n",
      "this is the iteration number 56 - loss = 0.6378498077392578\n",
      "this is the iteration number 57 - loss = 0.6584630012512207\n",
      "this is the iteration number 58 - loss = 0.6666126251220703\n",
      "this is the iteration number 59 - loss = 0.6500710248947144\n",
      "this is the iteration number 60 - loss = 0.6624714136123657\n",
      "this is the iteration number 61 - loss = 0.6624473333358765\n",
      "this is the iteration number 62 - loss = 0.6832669973373413\n",
      "this is the iteration number 63 - loss = 0.6328932046890259\n",
      "this is the iteration number 64 - loss = 0.674885630607605\n",
      "this is the iteration number 65 - loss = 0.6539158225059509\n",
      "this is the iteration number 66 - loss = 0.66645747423172\n",
      "this is the iteration number 67 - loss = 0.6411813497543335\n",
      "this is the iteration number 68 - loss = 0.6791101694107056\n",
      "this is the iteration number 69 - loss = 0.6494449973106384\n",
      "this is the iteration number 70 - loss = 0.6452111601829529\n",
      "this is the iteration number 71 - loss = 0.6789326667785645\n",
      "this is the iteration number 72 - loss = 0.670505940914154\n",
      "this is the iteration number 73 - loss = 0.6451021432876587\n",
      "this is the iteration number 74 - loss = 0.6577057242393494\n",
      "this is the iteration number 75 - loss = 0.6490935683250427\n",
      "this is the iteration number 76 - loss = 0.6702108979225159\n",
      "this is the iteration number 77 - loss = 0.6661402583122253\n",
      "this is the iteration number 78 - loss = 0.6789145469665527\n",
      "this is the iteration number 79 - loss = 0.6662792563438416\n",
      "this is the iteration number 80 - loss = 0.6660575866699219\n",
      "this is the iteration number 81 - loss = 0.6659980416297913\n",
      "this is the iteration number 82 - loss = 0.6659711003303528\n",
      "this is the iteration number 83 - loss = 0.6443568468093872\n",
      "this is the iteration number 84 - loss = 0.6744561791419983\n",
      "this is the iteration number 85 - loss = 0.6572504043579102\n",
      "this is the iteration number 86 - loss = 0.6659013032913208\n",
      "this is the iteration number 87 - loss = 0.6571159362792969\n",
      "this is the iteration number 88 - loss = 0.6571319699287415\n",
      "this is the iteration number 89 - loss = 0.6658612489700317\n",
      "this is the iteration number 90 - loss = 0.6657500863075256\n",
      "this is the iteration number 91 - loss = 0.6699743270874023\n",
      "this is the iteration number 92 - loss = 0.6787791848182678\n",
      "this is the iteration number 93 - loss = 0.6744137406349182\n",
      "this is the iteration number 94 - loss = 0.6612769365310669\n",
      "this is the iteration number 95 - loss = 0.6656244397163391\n",
      "this is the iteration number 96 - loss = 0.6479934453964233\n",
      "this is the iteration number 97 - loss = 0.6654796004295349\n",
      "this is the iteration number 98 - loss = 0.6743354797363281\n",
      "this is the iteration number 99 - loss = 0.6787199974060059\n",
      "this is the iteration number 100 - loss = 0.6390841603279114\n",
      "this is the iteration number 101 - loss = 0.6524428725242615\n",
      "this is the iteration number 0 - loss = 0.6565255522727966\n",
      "this is the iteration number 1 - loss = 0.6433209180831909\n",
      "this is the iteration number 2 - loss = 0.6476848721504211\n",
      "this is the iteration number 3 - loss = 0.6609305143356323\n",
      "this is the iteration number 4 - loss = 0.6518864631652832\n",
      "this is the iteration number 5 - loss = 0.6474327445030212\n",
      "this is the iteration number 6 - loss = 0.6652237772941589\n",
      "this is the iteration number 7 - loss = 0.6563190817832947\n",
      "this is the iteration number 8 - loss = 0.6739386320114136\n",
      "this is the iteration number 9 - loss = 0.6651806831359863\n",
      "this is the iteration number 10 - loss = 0.6561915278434753\n",
      "this is the iteration number 11 - loss = 0.6561499834060669\n",
      "this is the iteration number 12 - loss = 0.6875609159469604\n",
      "this is the iteration number 13 - loss = 0.6424837708473206\n",
      "this is the iteration number 14 - loss = 0.6468177437782288\n",
      "this is the iteration number 15 - loss = 0.6693477630615234\n",
      "this is the iteration number 16 - loss = 0.6559110283851624\n",
      "this is the iteration number 17 - loss = 0.6554775238037109\n",
      "this is the iteration number 18 - loss = 0.6331895589828491\n",
      "this is the iteration number 19 - loss = 0.6605858206748962\n",
      "this is the iteration number 20 - loss = 0.6556317210197449\n",
      "this is the iteration number 21 - loss = 0.6695709228515625\n",
      "this is the iteration number 22 - loss = 0.6831139922142029\n",
      "this is the iteration number 23 - loss = 0.6743178963661194\n",
      "this is the iteration number 24 - loss = 0.6739258766174316\n",
      "this is the iteration number 25 - loss = 0.6693529486656189\n",
      "this is the iteration number 26 - loss = 0.6876076459884644\n",
      "this is the iteration number 27 - loss = 0.7018255591392517\n",
      "this is the iteration number 28 - loss = 0.669496476650238\n",
      "this is the iteration number 29 - loss = 0.6599158644676208\n",
      "this is the iteration number 30 - loss = 0.6599095463752747\n",
      "this is the iteration number 31 - loss = 0.6508561372756958\n",
      "this is the iteration number 32 - loss = 0.6600430607795715\n",
      "this is the iteration number 33 - loss = 0.6599301099777222\n",
      "this is the iteration number 34 - loss = 0.6552980542182922\n",
      "this is the iteration number 35 - loss = 0.6460492014884949\n",
      "this is the iteration number 36 - loss = 0.6135300993919373\n",
      "this is the iteration number 37 - loss = 0.6413152813911438\n",
      "this is the iteration number 38 - loss = 0.6690856218338013\n",
      "this is the iteration number 39 - loss = 0.6458334922790527\n",
      "this is the iteration number 40 - loss = 0.6411413550376892\n",
      "this is the iteration number 41 - loss = 0.6457156538963318\n",
      "this is the iteration number 42 - loss = 0.6456537246704102\n",
      "this is the iteration number 43 - loss = 0.6642904281616211\n",
      "this is the iteration number 44 - loss = 0.6970342993736267\n",
      "this is the iteration number 45 - loss = 0.6689155697822571\n",
      "this is the iteration number 46 - loss = 0.6452473402023315\n",
      "this is the iteration number 47 - loss = 0.6782804131507874\n",
      "this is the iteration number 48 - loss = 0.664157509803772\n",
      "this is the iteration number 49 - loss = 0.6783887147903442\n",
      "this is the iteration number 50 - loss = 0.654606282711029\n",
      "this is the iteration number 51 - loss = 0.6546344757080078\n",
      "this is the iteration number 52 - loss = 0.6640568375587463\n",
      "this is the iteration number 53 - loss = 0.6545640826225281\n",
      "this is the iteration number 54 - loss = 0.6402830481529236\n",
      "this is the iteration number 55 - loss = 0.649743378162384\n",
      "this is the iteration number 56 - loss = 0.6495813131332397\n",
      "this is the iteration number 57 - loss = 0.6877220869064331\n",
      "this is the iteration number 58 - loss = 0.6591156721115112\n",
      "this is the iteration number 59 - loss = 0.6304839849472046\n",
      "this is the iteration number 60 - loss = 0.6638501882553101\n",
      "this is the iteration number 61 - loss = 0.6973057985305786\n",
      "this is the iteration number 62 - loss = 0.6685894131660461\n",
      "this is the iteration number 63 - loss = 0.6493978500366211\n",
      "this is the iteration number 64 - loss = 0.6445592641830444\n",
      "this is the iteration number 65 - loss = 0.6637130379676819\n",
      "this is the iteration number 66 - loss = 0.6444644927978516\n",
      "this is the iteration number 67 - loss = 0.6540480256080627\n",
      "this is the iteration number 68 - loss = 0.6491872072219849\n",
      "this is the iteration number 69 - loss = 0.687773585319519\n",
      "this is the iteration number 70 - loss = 0.6345978379249573\n",
      "this is the iteration number 71 - loss = 0.6393758654594421\n",
      "this is the iteration number 72 - loss = 0.6683987379074097\n",
      "this is the iteration number 73 - loss = 0.6683632731437683\n",
      "this is the iteration number 74 - loss = 0.6537814736366272\n",
      "this is the iteration number 75 - loss = 0.6537438631057739\n",
      "this is the iteration number 76 - loss = 0.639105498790741\n",
      "this is the iteration number 77 - loss = 0.6341533660888672\n",
      "this is the iteration number 78 - loss = 0.6731624603271484\n",
      "this is the iteration number 79 - loss = 0.6535820960998535\n",
      "this is the iteration number 80 - loss = 0.6633267998695374\n",
      "this is the iteration number 81 - loss = 0.6731201410293579\n",
      "this is the iteration number 82 - loss = 0.653465747833252\n",
      "this is the iteration number 83 - loss = 0.638641893863678\n",
      "this is the iteration number 84 - loss = 0.6435431838035583\n",
      "this is the iteration number 85 - loss = 0.6483026742935181\n",
      "this is the iteration number 86 - loss = 0.623688280582428\n",
      "this is the iteration number 87 - loss = 0.6730350852012634\n",
      "this is the iteration number 88 - loss = 0.6730203628540039\n",
      "this is the iteration number 89 - loss = 0.6630924940109253\n",
      "this is the iteration number 90 - loss = 0.623320996761322\n",
      "this is the iteration number 91 - loss = 0.6829187273979187\n",
      "this is the iteration number 92 - loss = 0.6829180717468262\n",
      "this is the iteration number 93 - loss = 0.6580115556716919\n",
      "this is the iteration number 94 - loss = 0.6776447892189026\n",
      "this is the iteration number 95 - loss = 0.657950758934021\n",
      "this is the iteration number 96 - loss = 0.6528509259223938\n",
      "this is the iteration number 97 - loss = 0.6478888392448425\n",
      "this is the iteration number 98 - loss = 0.6528581976890564\n",
      "this is the iteration number 99 - loss = 0.6478081941604614\n",
      "this is the iteration number 100 - loss = 0.6929554343223572\n",
      "this is the iteration number 101 - loss = 0.647948145866394\n",
      "this is the iteration number 0 - loss = 0.6829123497009277\n",
      "this is the iteration number 1 - loss = 0.6475396156311035\n",
      "this is the iteration number 2 - loss = 0.6526618599891663\n",
      "this is the iteration number 3 - loss = 0.657676637172699\n",
      "this is the iteration number 4 - loss = 0.6677468419075012\n",
      "this is the iteration number 5 - loss = 0.6319451332092285\n",
      "this is the iteration number 6 - loss = 0.6727839112281799\n",
      "this is the iteration number 7 - loss = 0.6727729439735413\n",
      "this is the iteration number 8 - loss = 0.6421655416488647\n",
      "this is the iteration number 9 - loss = 0.6371861100196838\n",
      "this is the iteration number 10 - loss = 0.6472173929214478\n",
      "this is the iteration number 11 - loss = 0.6625450849533081\n",
      "this is the iteration number 12 - loss = 0.6931415796279907\n",
      "this is the iteration number 13 - loss = 0.677912175655365\n",
      "this is the iteration number 14 - loss = 0.652210533618927\n",
      "this is the iteration number 15 - loss = 0.6266807913780212\n",
      "this is the iteration number 16 - loss = 0.6368532180786133\n",
      "this is the iteration number 17 - loss = 0.6728273034095764\n",
      "this is the iteration number 18 - loss = 0.6213614344596863\n",
      "this is the iteration number 19 - loss = 0.6723709106445312\n",
      "this is the iteration number 20 - loss = 0.6674844026565552\n",
      "this is the iteration number 21 - loss = 0.6468676924705505\n",
      "this is the iteration number 22 - loss = 0.6777552962303162\n",
      "this is the iteration number 23 - loss = 0.6777500510215759\n",
      "this is the iteration number 24 - loss = 0.6416023969650269\n",
      "this is the iteration number 25 - loss = 0.6622339487075806\n",
      "this is the iteration number 26 - loss = 0.6519657969474792\n",
      "this is the iteration number 27 - loss = 0.6414745450019836\n",
      "this is the iteration number 28 - loss = 0.6567831635475159\n",
      "this is the iteration number 29 - loss = 0.6727081537246704\n",
      "this is the iteration number 30 - loss = 0.6569291353225708\n",
      "this is the iteration number 31 - loss = 0.667576253414154\n",
      "this is the iteration number 32 - loss = 0.6517672538757324\n",
      "this is the iteration number 33 - loss = 0.6464270949363708\n",
      "this is the iteration number 34 - loss = 0.641189694404602\n",
      "this is the iteration number 35 - loss = 0.6620180010795593\n",
      "this is the iteration number 36 - loss = 0.6254333853721619\n",
      "this is the iteration number 37 - loss = 0.6302717328071594\n",
      "this is the iteration number 38 - loss = 0.6147662997245789\n",
      "this is the iteration number 39 - loss = 0.6725049614906311\n",
      "this is the iteration number 40 - loss = 0.6408624649047852\n",
      "this is the iteration number 41 - loss = 0.6618603467941284\n",
      "this is the iteration number 42 - loss = 0.6353836059570312\n",
      "this is the iteration number 43 - loss = 0.6776383519172668\n",
      "this is the iteration number 44 - loss = 0.6776323318481445\n",
      "this is the iteration number 45 - loss = 0.6671691536903381\n",
      "this is the iteration number 46 - loss = 0.6193618774414062\n",
      "this is the iteration number 47 - loss = 0.6564203500747681\n",
      "this is the iteration number 48 - loss = 0.6565262675285339\n",
      "this is the iteration number 49 - loss = 0.656348705291748\n",
      "this is the iteration number 50 - loss = 0.6722801327705383\n",
      "this is the iteration number 51 - loss = 0.6616173982620239\n",
      "this is the iteration number 52 - loss = 0.6775908470153809\n",
      "this is the iteration number 53 - loss = 0.6294421553611755\n",
      "this is the iteration number 54 - loss = 0.6615546941757202\n",
      "this is the iteration number 55 - loss = 0.6830262541770935\n",
      "this is the iteration number 56 - loss = 0.618386447429657\n",
      "this is the iteration number 57 - loss = 0.6666699647903442\n",
      "this is the iteration number 58 - loss = 0.677571177482605\n",
      "this is the iteration number 59 - loss = 0.66145259141922\n",
      "this is the iteration number 60 - loss = 0.650685727596283\n",
      "this is the iteration number 61 - loss = 0.6452308297157288\n",
      "this is the iteration number 62 - loss = 0.6288198232650757\n",
      "this is the iteration number 63 - loss = 0.6935375928878784\n",
      "this is the iteration number 64 - loss = 0.6668411493301392\n",
      "this is the iteration number 65 - loss = 0.6667237281799316\n",
      "this is the iteration number 66 - loss = 0.6341633200645447\n",
      "this is the iteration number 67 - loss = 0.6503201723098755\n",
      "this is the iteration number 68 - loss = 0.6232251524925232\n",
      "this is the iteration number 69 - loss = 0.6667501330375671\n",
      "this is the iteration number 70 - loss = 0.6558070182800293\n",
      "this is the iteration number 71 - loss = 0.6448911428451538\n",
      "this is the iteration number 72 - loss = 0.6611990332603455\n",
      "this is the iteration number 73 - loss = 0.6883775591850281\n",
      "this is the iteration number 74 - loss = 0.6609708666801453\n",
      "this is the iteration number 75 - loss = 0.6392016410827637\n",
      "this is the iteration number 76 - loss = 0.633702278137207\n",
      "this is the iteration number 77 - loss = 0.6775184869766235\n",
      "this is the iteration number 78 - loss = 0.6446446180343628\n",
      "this is the iteration number 79 - loss = 0.683340847492218\n",
      "this is the iteration number 80 - loss = 0.6500193476676941\n",
      "this is the iteration number 81 - loss = 0.6502771377563477\n",
      "this is the iteration number 82 - loss = 0.6335495710372925\n",
      "this is the iteration number 83 - loss = 0.671967089176178\n",
      "this is the iteration number 84 - loss = 0.6717525720596313\n",
      "this is the iteration number 85 - loss = 0.6496792435646057\n",
      "this is the iteration number 86 - loss = 0.6497138142585754\n",
      "this is the iteration number 87 - loss = 0.6661953330039978\n",
      "this is the iteration number 88 - loss = 0.6383414268493652\n",
      "this is the iteration number 89 - loss = 0.6276012659072876\n",
      "this is the iteration number 90 - loss = 0.6495150327682495\n",
      "this is the iteration number 91 - loss = 0.6830040812492371\n",
      "this is the iteration number 92 - loss = 0.6719192266464233\n",
      "this is the iteration number 93 - loss = 0.6219066977500916\n",
      "this is the iteration number 94 - loss = 0.6440950632095337\n",
      "this is the iteration number 95 - loss = 0.6440516710281372\n",
      "this is the iteration number 96 - loss = 0.6661826968193054\n",
      "this is the iteration number 97 - loss = 0.6384268403053284\n",
      "this is the iteration number 98 - loss = 0.6662840843200684\n",
      "this is the iteration number 99 - loss = 0.6663666367530823\n",
      "this is the iteration number 100 - loss = 0.6660338044166565\n",
      "this is the iteration number 101 - loss = 0.6713176369667053\n",
      "this is the iteration number 0 - loss = 0.6382154822349548\n",
      "this is the iteration number 1 - loss = 0.6493812799453735\n",
      "this is the iteration number 2 - loss = 0.676784873008728\n",
      "this is the iteration number 3 - loss = 0.6324900388717651\n",
      "this is the iteration number 4 - loss = 0.6656160950660706\n",
      "this is the iteration number 5 - loss = 0.6380232572555542\n",
      "this is the iteration number 6 - loss = 0.6604911684989929\n",
      "this is the iteration number 7 - loss = 0.643575131893158\n",
      "this is the iteration number 8 - loss = 0.6153501868247986\n",
      "this is the iteration number 9 - loss = 0.688665509223938\n",
      "this is the iteration number 10 - loss = 0.6547637581825256\n",
      "this is the iteration number 11 - loss = 0.6206231117248535\n",
      "this is the iteration number 12 - loss = 0.6490582227706909\n",
      "this is the iteration number 13 - loss = 0.6656799912452698\n",
      "this is the iteration number 14 - loss = 0.6768251657485962\n",
      "this is the iteration number 15 - loss = 0.6319810152053833\n",
      "this is the iteration number 16 - loss = 0.6773903965950012\n",
      "this is the iteration number 17 - loss = 0.6431657075881958\n",
      "this is the iteration number 18 - loss = 0.6602894067764282\n",
      "this is the iteration number 19 - loss = 0.6424373388290405\n",
      "this is the iteration number 20 - loss = 0.6256847381591797\n",
      "this is the iteration number 21 - loss = 0.6830725073814392\n",
      "this is the iteration number 22 - loss = 0.6310080289840698\n",
      "this is the iteration number 23 - loss = 0.6717313528060913\n",
      "this is the iteration number 24 - loss = 0.6716309189796448\n",
      "this is the iteration number 25 - loss = 0.6600379347801208\n",
      "this is the iteration number 26 - loss = 0.6542394757270813\n",
      "this is the iteration number 27 - loss = 0.6257055997848511\n",
      "this is the iteration number 28 - loss = 0.6774917244911194\n",
      "this is the iteration number 29 - loss = 0.6715510487556458\n",
      "this is the iteration number 30 - loss = 0.6829155683517456\n",
      "this is the iteration number 31 - loss = 0.6140086054801941\n",
      "this is the iteration number 32 - loss = 0.6712657809257507\n",
      "this is the iteration number 33 - loss = 0.6831137537956238\n",
      "this is the iteration number 34 - loss = 0.6131736040115356\n",
      "this is the iteration number 35 - loss = 0.6483981013298035\n",
      "this is the iteration number 36 - loss = 0.6649957299232483\n",
      "this is the iteration number 37 - loss = 0.6657072901725769\n",
      "this is the iteration number 38 - loss = 0.6423022150993347\n",
      "this is the iteration number 39 - loss = 0.6369505524635315\n",
      "this is the iteration number 40 - loss = 0.6304047703742981\n",
      "this is the iteration number 41 - loss = 0.6538836359977722\n",
      "this is the iteration number 42 - loss = 0.6597670912742615\n",
      "this is the iteration number 43 - loss = 0.6428408026695251\n",
      "this is the iteration number 44 - loss = 0.6419979929924011\n",
      "this is the iteration number 45 - loss = 0.6359286308288574\n",
      "this is the iteration number 46 - loss = 0.6536529660224915\n",
      "this is the iteration number 47 - loss = 0.6476048231124878\n",
      "this is the iteration number 48 - loss = 0.6531381011009216\n",
      "this is the iteration number 49 - loss = 0.6409577131271362\n",
      "this is the iteration number 50 - loss = 0.665167510509491\n",
      "this is the iteration number 51 - loss = 0.6879943013191223\n",
      "this is the iteration number 52 - loss = 0.6305108070373535\n",
      "this is the iteration number 53 - loss = 0.6656545400619507\n",
      "this is the iteration number 54 - loss = 0.6299362182617188\n",
      "this is the iteration number 55 - loss = 0.6957291960716248\n",
      "this is the iteration number 56 - loss = 0.6644383072853088\n",
      "this is the iteration number 57 - loss = 0.6528485417366028\n",
      "this is the iteration number 58 - loss = 0.6586834788322449\n",
      "this is the iteration number 59 - loss = 0.6701253056526184\n",
      "this is the iteration number 60 - loss = 0.6769424676895142\n",
      "this is the iteration number 61 - loss = 0.678067147731781\n",
      "this is the iteration number 62 - loss = 0.6226584315299988\n",
      "this is the iteration number 63 - loss = 0.6410383582115173\n",
      "this is the iteration number 64 - loss = 0.676114022731781\n",
      "this is the iteration number 65 - loss = 0.6398688554763794\n",
      "this is the iteration number 66 - loss = 0.6943346261978149\n",
      "this is the iteration number 67 - loss = 0.6508313417434692\n",
      "this is the iteration number 68 - loss = 0.6647587418556213\n",
      "this is the iteration number 69 - loss = 0.6636084318161011\n",
      "this is the iteration number 70 - loss = 0.663708508014679\n",
      "this is the iteration number 71 - loss = 0.6389040350914001\n",
      "this is the iteration number 72 - loss = 0.6405141949653625\n",
      "this is the iteration number 73 - loss = 0.6515825986862183\n",
      "this is the iteration number 74 - loss = 0.6400014162063599\n",
      "this is the iteration number 75 - loss = 0.6446661353111267\n",
      "this is the iteration number 76 - loss = 0.6131830811500549\n",
      "this is the iteration number 77 - loss = 0.6553030610084534\n",
      "this is the iteration number 78 - loss = 0.5952455401420593\n",
      "this is the iteration number 79 - loss = 0.6336403489112854\n",
      "this is the iteration number 80 - loss = 0.6550601124763489\n",
      "this is the iteration number 81 - loss = 0.6287074685096741\n",
      "this is the iteration number 82 - loss = 0.6676069498062134\n",
      "this is the iteration number 83 - loss = 0.6275700926780701\n",
      "this is the iteration number 84 - loss = 0.6324909925460815\n",
      "this is the iteration number 85 - loss = 0.6563764214515686\n",
      "this is the iteration number 86 - loss = 0.6686069369316101\n",
      "this is the iteration number 87 - loss = 0.6385358572006226\n",
      "this is the iteration number 88 - loss = 0.6263155341148376\n",
      "this is the iteration number 89 - loss = 0.6253235936164856\n",
      "this is the iteration number 90 - loss = 0.6520726084709167\n",
      "this is the iteration number 91 - loss = 0.5791231393814087\n",
      "this is the iteration number 92 - loss = 0.5791621208190918\n",
      "this is the iteration number 93 - loss = 0.6256069540977478\n",
      "this is the iteration number 94 - loss = 0.6897119879722595\n",
      "this is the iteration number 95 - loss = 0.6643406748771667\n",
      "this is the iteration number 96 - loss = 0.6482662558555603\n",
      "this is the iteration number 97 - loss = 0.6428728699684143\n",
      "this is the iteration number 98 - loss = 0.611410915851593\n",
      "this is the iteration number 99 - loss = 0.6407473683357239\n",
      "this is the iteration number 100 - loss = 0.6098321676254272\n",
      "this is the iteration number 101 - loss = 0.6491802334785461\n",
      "this is the iteration number 0 - loss = 0.5983564257621765\n",
      "this is the iteration number 1 - loss = 0.6068239808082581\n",
      "this is the iteration number 2 - loss = 0.6532161831855774\n",
      "this is the iteration number 3 - loss = 0.6389272809028625\n",
      "this is the iteration number 4 - loss = 0.661973774433136\n",
      "this is the iteration number 5 - loss = 0.6226686239242554\n",
      "this is the iteration number 6 - loss = 0.6075906753540039\n",
      "this is the iteration number 7 - loss = 0.5791040658950806\n",
      "this is the iteration number 8 - loss = 0.6069554090499878\n",
      "this is the iteration number 9 - loss = 0.5758253931999207\n",
      "this is the iteration number 10 - loss = 0.6309754252433777\n",
      "this is the iteration number 11 - loss = 0.6264476180076599\n",
      "this is the iteration number 12 - loss = 0.6173243522644043\n",
      "this is the iteration number 13 - loss = 0.6449821591377258\n",
      "this is the iteration number 14 - loss = 0.6444784998893738\n",
      "this is the iteration number 15 - loss = 0.6224413514137268\n",
      "this is the iteration number 16 - loss = 0.6125454902648926\n",
      "this is the iteration number 17 - loss = 0.5839471220970154\n",
      "this is the iteration number 18 - loss = 0.6251385807991028\n",
      "this is the iteration number 19 - loss = 0.5940337777137756\n",
      "this is the iteration number 20 - loss = 0.6540060043334961\n",
      "this is the iteration number 21 - loss = 0.6004042029380798\n",
      "this is the iteration number 22 - loss = 0.6546474099159241\n",
      "this is the iteration number 23 - loss = 0.5982159376144409\n",
      "this is the iteration number 24 - loss = 0.6639689803123474\n",
      "this is the iteration number 25 - loss = 0.5545483231544495\n",
      "this is the iteration number 26 - loss = 0.5738745927810669\n",
      "this is the iteration number 27 - loss = 0.6125629544258118\n",
      "this is the iteration number 28 - loss = 0.6104326248168945\n",
      "this is the iteration number 29 - loss = 0.5950251221656799\n",
      "this is the iteration number 30 - loss = 0.5737449526786804\n",
      "this is the iteration number 31 - loss = 0.6489987969398499\n",
      "this is the iteration number 32 - loss = 0.5936265587806702\n",
      "this is the iteration number 33 - loss = 0.6493254899978638\n",
      "this is the iteration number 34 - loss = 0.6313344240188599\n",
      "this is the iteration number 35 - loss = 0.6591276526451111\n",
      "this is the iteration number 36 - loss = 0.6452038884162903\n",
      "this is the iteration number 37 - loss = 0.5979625582695007\n",
      "this is the iteration number 38 - loss = 0.6328936815261841\n",
      "this is the iteration number 39 - loss = 0.6070783734321594\n",
      "this is the iteration number 40 - loss = 0.6351904273033142\n",
      "this is the iteration number 41 - loss = 0.5585014224052429\n",
      "this is the iteration number 42 - loss = 0.538388192653656\n",
      "this is the iteration number 43 - loss = 0.6320339441299438\n",
      "this is the iteration number 44 - loss = 0.6619002223014832\n",
      "this is the iteration number 45 - loss = 0.6110391616821289\n",
      "this is the iteration number 46 - loss = 0.5983533263206482\n",
      "this is the iteration number 47 - loss = 0.5716894865036011\n",
      "this is the iteration number 48 - loss = 0.6144354939460754\n",
      "this is the iteration number 49 - loss = 0.6126362681388855\n",
      "this is the iteration number 50 - loss = 0.658121645450592\n",
      "this is the iteration number 51 - loss = 0.674956738948822\n",
      "this is the iteration number 52 - loss = 0.6424068808555603\n",
      "this is the iteration number 53 - loss = 0.5569764375686646\n",
      "this is the iteration number 54 - loss = 0.6111602187156677\n",
      "this is the iteration number 55 - loss = 0.5637047290802002\n",
      "this is the iteration number 56 - loss = 0.6028738617897034\n",
      "this is the iteration number 57 - loss = 0.5881128907203674\n",
      "this is the iteration number 58 - loss = 0.6195045113563538\n",
      "this is the iteration number 59 - loss = 0.6061253547668457\n",
      "this is the iteration number 60 - loss = 0.6386200785636902\n",
      "this is the iteration number 61 - loss = 0.5769307017326355\n",
      "this is the iteration number 62 - loss = 0.6597223877906799\n",
      "this is the iteration number 63 - loss = 0.6370847821235657\n",
      "this is the iteration number 64 - loss = 0.6586548686027527\n",
      "this is the iteration number 65 - loss = 0.5982646942138672\n",
      "this is the iteration number 66 - loss = 0.6349852681159973\n",
      "this is the iteration number 67 - loss = 0.5452759265899658\n",
      "this is the iteration number 68 - loss = 0.5124756097793579\n",
      "this is the iteration number 69 - loss = 0.6262925267219543\n",
      "this is the iteration number 70 - loss = 0.571501612663269\n",
      "this is the iteration number 71 - loss = 0.6032995581626892\n",
      "this is the iteration number 72 - loss = 0.6548134088516235\n",
      "this is the iteration number 73 - loss = 0.5910552740097046\n",
      "this is the iteration number 74 - loss = 0.5989397168159485\n",
      "this is the iteration number 75 - loss = 0.6075579524040222\n",
      "this is the iteration number 76 - loss = 0.6467732787132263\n",
      "this is the iteration number 77 - loss = 0.6336652040481567\n",
      "this is the iteration number 78 - loss = 0.6229170560836792\n",
      "this is the iteration number 79 - loss = 0.5426723957061768\n",
      "this is the iteration number 80 - loss = 0.607686460018158\n",
      "this is the iteration number 81 - loss = 0.5626464486122131\n",
      "this is the iteration number 82 - loss = 0.592212975025177\n",
      "this is the iteration number 83 - loss = 0.5711692571640015\n",
      "this is the iteration number 84 - loss = 0.6053003668785095\n",
      "this is the iteration number 85 - loss = 0.63788241147995\n",
      "this is the iteration number 86 - loss = 0.6062518358230591\n",
      "this is the iteration number 87 - loss = 0.5890016555786133\n",
      "this is the iteration number 88 - loss = 0.6239544153213501\n",
      "this is the iteration number 89 - loss = 0.607594907283783\n",
      "this is the iteration number 90 - loss = 0.5913398861885071\n",
      "this is the iteration number 91 - loss = 0.5925321578979492\n",
      "this is the iteration number 92 - loss = 0.6071787476539612\n",
      "this is the iteration number 93 - loss = 0.5808035731315613\n",
      "this is the iteration number 94 - loss = 0.6508785486221313\n",
      "this is the iteration number 95 - loss = 0.560107409954071\n",
      "this is the iteration number 96 - loss = 0.6399518251419067\n",
      "this is the iteration number 97 - loss = 0.5912695527076721\n",
      "this is the iteration number 98 - loss = 0.569046139717102\n",
      "this is the iteration number 99 - loss = 0.5894085764884949\n",
      "this is the iteration number 100 - loss = 0.5977945327758789\n",
      "this is the iteration number 101 - loss = 0.5553674101829529\n",
      "this is the iteration number 0 - loss = 0.5895801782608032\n",
      "this is the iteration number 1 - loss = 0.6787990927696228\n",
      "this is the iteration number 2 - loss = 0.5926804542541504\n",
      "this is the iteration number 3 - loss = 0.5478798747062683\n",
      "this is the iteration number 4 - loss = 0.6819345355033875\n",
      "this is the iteration number 5 - loss = 0.5432671904563904\n",
      "this is the iteration number 6 - loss = 0.5348178744316101\n",
      "this is the iteration number 7 - loss = 0.5875858664512634\n",
      "this is the iteration number 8 - loss = 0.584668755531311\n",
      "this is the iteration number 9 - loss = 0.5225993394851685\n",
      "this is the iteration number 10 - loss = 0.5999189615249634\n",
      "this is the iteration number 11 - loss = 0.59683758020401\n",
      "this is the iteration number 12 - loss = 0.6307452321052551\n",
      "this is the iteration number 13 - loss = 0.584227442741394\n",
      "this is the iteration number 14 - loss = 0.5598804950714111\n",
      "this is the iteration number 15 - loss = 0.6113690137863159\n",
      "this is the iteration number 16 - loss = 0.6291924118995667\n",
      "this is the iteration number 17 - loss = 0.6386341452598572\n",
      "this is the iteration number 18 - loss = 0.5940770506858826\n",
      "this is the iteration number 19 - loss = 0.6804200410842896\n",
      "this is the iteration number 20 - loss = 0.6644039154052734\n",
      "this is the iteration number 21 - loss = 0.6471113562583923\n",
      "this is the iteration number 22 - loss = 0.5817036628723145\n",
      "this is the iteration number 23 - loss = 0.6083086133003235\n",
      "this is the iteration number 24 - loss = 0.5660902857780457\n",
      "this is the iteration number 25 - loss = 0.5922127366065979\n",
      "this is the iteration number 26 - loss = 0.6599993109703064\n",
      "this is the iteration number 27 - loss = 0.5715433955192566\n",
      "this is the iteration number 28 - loss = 0.6222977638244629\n",
      "this is the iteration number 29 - loss = 0.5440200567245483\n",
      "this is the iteration number 30 - loss = 0.6044159531593323\n",
      "this is the iteration number 31 - loss = 0.5713133811950684\n",
      "this is the iteration number 32 - loss = 0.5899125337600708\n",
      "this is the iteration number 33 - loss = 0.6146014332771301\n",
      "this is the iteration number 34 - loss = 0.5912184715270996\n",
      "this is the iteration number 35 - loss = 0.5697286128997803\n",
      "this is the iteration number 36 - loss = 0.5820760726928711\n",
      "this is the iteration number 37 - loss = 0.6199111342430115\n",
      "this is the iteration number 38 - loss = 0.610393226146698\n",
      "this is the iteration number 39 - loss = 0.6267386078834534\n",
      "this is the iteration number 40 - loss = 0.6201024055480957\n",
      "this is the iteration number 41 - loss = 0.6184716820716858\n",
      "this is the iteration number 42 - loss = 0.56931471824646\n",
      "this is the iteration number 43 - loss = 0.5245451331138611\n",
      "this is the iteration number 44 - loss = 0.5550609827041626\n",
      "this is the iteration number 45 - loss = 0.517102062702179\n",
      "this is the iteration number 46 - loss = 0.5095654129981995\n",
      "this is the iteration number 47 - loss = 0.5729003548622131\n",
      "this is the iteration number 48 - loss = 0.6217390894889832\n",
      "this is the iteration number 49 - loss = 0.6107860803604126\n",
      "this is the iteration number 50 - loss = 0.6242678761482239\n",
      "this is the iteration number 51 - loss = 0.6036490201950073\n",
      "this is the iteration number 52 - loss = 0.5994333624839783\n",
      "this is the iteration number 53 - loss = 0.5577260255813599\n",
      "this is the iteration number 54 - loss = 0.6139872670173645\n",
      "this is the iteration number 55 - loss = 0.5839583277702332\n",
      "this is the iteration number 56 - loss = 0.5286818146705627\n",
      "this is the iteration number 57 - loss = 0.5728958249092102\n",
      "this is the iteration number 58 - loss = 0.6034836173057556\n",
      "this is the iteration number 59 - loss = 0.6119316816329956\n",
      "this is the iteration number 60 - loss = 0.5920621752738953\n",
      "this is the iteration number 61 - loss = 0.6220737099647522\n",
      "this is the iteration number 62 - loss = 0.5828357338905334\n",
      "this is the iteration number 63 - loss = 0.6158857941627502\n",
      "this is the iteration number 64 - loss = 0.5920111536979675\n",
      "this is the iteration number 65 - loss = 0.6291051506996155\n",
      "this is the iteration number 66 - loss = 0.6141200661659241\n",
      "this is the iteration number 67 - loss = 0.5700860023498535\n",
      "this is the iteration number 68 - loss = 0.5479530096054077\n",
      "this is the iteration number 69 - loss = 0.5406169295310974\n",
      "this is the iteration number 70 - loss = 0.5628100633621216\n",
      "this is the iteration number 71 - loss = 0.6079067587852478\n",
      "this is the iteration number 72 - loss = 0.5934581756591797\n",
      "this is the iteration number 73 - loss = 0.5828536152839661\n",
      "this is the iteration number 74 - loss = 0.5463297367095947\n",
      "this is the iteration number 75 - loss = 0.6212485432624817\n",
      "this is the iteration number 76 - loss = 0.6361831426620483\n",
      "this is the iteration number 77 - loss = 0.5748510360717773\n",
      "this is the iteration number 78 - loss = 0.6224629282951355\n",
      "this is the iteration number 79 - loss = 0.6108710169792175\n",
      "this is the iteration number 80 - loss = 0.6553770899772644\n",
      "this is the iteration number 81 - loss = 0.5849353075027466\n",
      "this is the iteration number 82 - loss = 0.5920265316963196\n",
      "this is the iteration number 83 - loss = 0.6052311062812805\n",
      "this is the iteration number 84 - loss = 0.5517260432243347\n",
      "this is the iteration number 85 - loss = 0.5848912000656128\n",
      "this is the iteration number 86 - loss = 0.5999345779418945\n",
      "this is the iteration number 87 - loss = 0.5788121819496155\n",
      "this is the iteration number 88 - loss = 0.5502864718437195\n",
      "this is the iteration number 89 - loss = 0.5261285901069641\n",
      "this is the iteration number 90 - loss = 0.5867832899093628\n",
      "this is the iteration number 91 - loss = 0.5250915884971619\n",
      "this is the iteration number 92 - loss = 0.556756854057312\n",
      "this is the iteration number 93 - loss = 0.6159768104553223\n",
      "this is the iteration number 94 - loss = 0.49130895733833313\n",
      "this is the iteration number 95 - loss = 0.6059367060661316\n",
      "this is the iteration number 96 - loss = 0.5762767791748047\n",
      "this is the iteration number 97 - loss = 0.5933138728141785\n",
      "this is the iteration number 98 - loss = 0.5750002264976501\n",
      "this is the iteration number 99 - loss = 0.6408962607383728\n",
      "this is the iteration number 100 - loss = 0.5386205911636353\n",
      "this is the iteration number 101 - loss = 0.5479190945625305\n",
      "this is the iteration number 0 - loss = 0.5802842378616333\n",
      "this is the iteration number 1 - loss = 0.5747017860412598\n",
      "this is the iteration number 2 - loss = 0.5772184133529663\n",
      "this is the iteration number 3 - loss = 0.5522477030754089\n",
      "this is the iteration number 4 - loss = 0.5701135396957397\n",
      "this is the iteration number 5 - loss = 0.5854314565658569\n",
      "this is the iteration number 6 - loss = 0.5970037579536438\n",
      "this is the iteration number 7 - loss = 0.6271560788154602\n",
      "this is the iteration number 8 - loss = 0.5480152368545532\n",
      "this is the iteration number 9 - loss = 0.6259669065475464\n",
      "this is the iteration number 10 - loss = 0.5469840168952942\n",
      "this is the iteration number 11 - loss = 0.5966159701347351\n",
      "this is the iteration number 12 - loss = 0.5277416110038757\n",
      "this is the iteration number 13 - loss = 0.5897101163864136\n",
      "this is the iteration number 14 - loss = 0.5745270848274231\n",
      "this is the iteration number 15 - loss = 0.6269568800926208\n",
      "this is the iteration number 16 - loss = 0.6141616702079773\n",
      "this is the iteration number 17 - loss = 0.5594471096992493\n",
      "this is the iteration number 18 - loss = 0.5818870663642883\n",
      "this is the iteration number 19 - loss = 0.5641742944717407\n",
      "this is the iteration number 20 - loss = 0.552558422088623\n",
      "this is the iteration number 21 - loss = 0.6073509454727173\n",
      "this is the iteration number 22 - loss = 0.5959259867668152\n",
      "this is the iteration number 23 - loss = 0.6073121428489685\n",
      "this is the iteration number 24 - loss = 0.5699732899665833\n",
      "this is the iteration number 25 - loss = 0.61397784948349\n",
      "this is the iteration number 26 - loss = 0.5807743072509766\n",
      "this is the iteration number 27 - loss = 0.6095673441886902\n",
      "this is the iteration number 28 - loss = 0.5969781279563904\n",
      "this is the iteration number 29 - loss = 0.5836807489395142\n",
      "this is the iteration number 30 - loss = 0.581104576587677\n",
      "this is the iteration number 31 - loss = 0.5516318678855896\n",
      "this is the iteration number 32 - loss = 0.5708471536636353\n",
      "this is the iteration number 33 - loss = 0.5552650690078735\n",
      "this is the iteration number 34 - loss = 0.5502907037734985\n",
      "this is the iteration number 35 - loss = 0.5513563752174377\n",
      "this is the iteration number 36 - loss = 0.5344855189323425\n",
      "this is the iteration number 37 - loss = 0.5774780511856079\n",
      "this is the iteration number 38 - loss = 0.5739393830299377\n",
      "this is the iteration number 39 - loss = 0.6176192164421082\n",
      "this is the iteration number 40 - loss = 0.612480103969574\n",
      "this is the iteration number 41 - loss = 0.5329082608222961\n",
      "this is the iteration number 42 - loss = 0.5938348770141602\n",
      "this is the iteration number 43 - loss = 0.5652790665626526\n",
      "this is the iteration number 44 - loss = 0.6198061108589172\n",
      "this is the iteration number 45 - loss = 0.6115254163742065\n",
      "this is the iteration number 46 - loss = 0.5811490416526794\n",
      "this is the iteration number 47 - loss = 0.5437923073768616\n",
      "this is the iteration number 48 - loss = 0.6081148386001587\n",
      "this is the iteration number 49 - loss = 0.5950900316238403\n",
      "this is the iteration number 50 - loss = 0.5382073521614075\n",
      "this is the iteration number 51 - loss = 0.5807327628135681\n",
      "this is the iteration number 52 - loss = 0.605577290058136\n",
      "this is the iteration number 53 - loss = 0.5772241950035095\n",
      "this is the iteration number 54 - loss = 0.5782739520072937\n",
      "this is the iteration number 55 - loss = 0.5490437150001526\n",
      "this is the iteration number 56 - loss = 0.630626380443573\n",
      "this is the iteration number 57 - loss = 0.5567082762718201\n",
      "this is the iteration number 58 - loss = 0.5763093829154968\n",
      "this is the iteration number 59 - loss = 0.5768094062805176\n",
      "this is the iteration number 60 - loss = 0.6023489832878113\n",
      "this is the iteration number 61 - loss = 0.577893078327179\n",
      "this is the iteration number 62 - loss = 0.5688212513923645\n",
      "this is the iteration number 63 - loss = 0.5859008431434631\n",
      "this is the iteration number 64 - loss = 0.5276100039482117\n",
      "this is the iteration number 65 - loss = 0.5455240607261658\n",
      "this is the iteration number 66 - loss = 0.6338604092597961\n",
      "this is the iteration number 67 - loss = 0.5831997990608215\n",
      "this is the iteration number 68 - loss = 0.5510308742523193\n",
      "this is the iteration number 69 - loss = 0.5228620767593384\n",
      "this is the iteration number 70 - loss = 0.5610238909721375\n",
      "this is the iteration number 71 - loss = 0.5811521410942078\n",
      "this is the iteration number 72 - loss = 0.5458370447158813\n",
      "this is the iteration number 73 - loss = 0.6166409850120544\n",
      "this is the iteration number 74 - loss = 0.5991311073303223\n",
      "this is the iteration number 75 - loss = 0.5548593401908875\n",
      "this is the iteration number 76 - loss = 0.6367131471633911\n",
      "this is the iteration number 77 - loss = 0.579334557056427\n",
      "this is the iteration number 78 - loss = 0.6054700613021851\n",
      "this is the iteration number 79 - loss = 0.5960161089897156\n",
      "this is the iteration number 80 - loss = 0.6036268472671509\n",
      "this is the iteration number 81 - loss = 0.6144556999206543\n",
      "this is the iteration number 82 - loss = 0.5886406898498535\n",
      "this is the iteration number 83 - loss = 0.5260893106460571\n",
      "this is the iteration number 84 - loss = 0.5831460952758789\n",
      "this is the iteration number 85 - loss = 0.5321099162101746\n",
      "this is the iteration number 86 - loss = 0.45796164870262146\n",
      "this is the iteration number 87 - loss = 0.5429700613021851\n",
      "this is the iteration number 88 - loss = 0.5634524822235107\n",
      "this is the iteration number 89 - loss = 0.5952168703079224\n",
      "this is the iteration number 90 - loss = 0.6023042798042297\n",
      "this is the iteration number 91 - loss = 0.5963841676712036\n",
      "this is the iteration number 92 - loss = 0.555576741695404\n",
      "this is the iteration number 93 - loss = 0.6309053301811218\n",
      "this is the iteration number 94 - loss = 0.5174435377120972\n",
      "this is the iteration number 95 - loss = 0.6130329966545105\n",
      "this is the iteration number 96 - loss = 0.5827446579933167\n",
      "this is the iteration number 97 - loss = 0.5822668671607971\n",
      "this is the iteration number 98 - loss = 0.5830758810043335\n",
      "this is the iteration number 99 - loss = 0.5751826167106628\n",
      "this is the iteration number 100 - loss = 0.5910234451293945\n",
      "this is the iteration number 101 - loss = 0.6067569851875305\n",
      "this is the iteration number 0 - loss = 0.5908045768737793\n",
      "this is the iteration number 1 - loss = 0.5506659150123596\n",
      "this is the iteration number 2 - loss = 0.5907960534095764\n",
      "this is the iteration number 3 - loss = 0.5476323366165161\n",
      "this is the iteration number 4 - loss = 0.4909893572330475\n",
      "this is the iteration number 5 - loss = 0.5656715631484985\n",
      "this is the iteration number 6 - loss = 0.6194428205490112\n",
      "this is the iteration number 7 - loss = 0.637265682220459\n",
      "this is the iteration number 8 - loss = 0.5673199892044067\n",
      "this is the iteration number 9 - loss = 0.5988993048667908\n",
      "this is the iteration number 10 - loss = 0.4933081567287445\n",
      "this is the iteration number 11 - loss = 0.5347555875778198\n",
      "this is the iteration number 12 - loss = 0.5735698938369751\n",
      "this is the iteration number 13 - loss = 0.6077156662940979\n",
      "this is the iteration number 14 - loss = 0.6162465214729309\n",
      "this is the iteration number 15 - loss = 0.5936626195907593\n",
      "this is the iteration number 16 - loss = 0.5705570578575134\n",
      "this is the iteration number 17 - loss = 0.5688153505325317\n",
      "this is the iteration number 18 - loss = 0.5285307168960571\n",
      "this is the iteration number 19 - loss = 0.6149182915687561\n",
      "this is the iteration number 20 - loss = 0.579500138759613\n",
      "this is the iteration number 21 - loss = 0.5792598724365234\n",
      "this is the iteration number 22 - loss = 0.5256754159927368\n",
      "this is the iteration number 23 - loss = 0.47809961438179016\n",
      "this is the iteration number 24 - loss = 0.5648847222328186\n",
      "this is the iteration number 25 - loss = 0.5617954730987549\n",
      "this is the iteration number 26 - loss = 0.6430491805076599\n",
      "this is the iteration number 27 - loss = 0.5993102192878723\n",
      "this is the iteration number 28 - loss = 0.5375691652297974\n",
      "this is the iteration number 29 - loss = 0.5234479904174805\n",
      "this is the iteration number 30 - loss = 0.5130624771118164\n",
      "this is the iteration number 31 - loss = 0.5941463112831116\n",
      "this is the iteration number 32 - loss = 0.5747427344322205\n",
      "this is the iteration number 33 - loss = 0.5482905507087708\n",
      "this is the iteration number 34 - loss = 0.553558886051178\n",
      "this is the iteration number 35 - loss = 0.5547784566879272\n",
      "this is the iteration number 36 - loss = 0.5612815022468567\n",
      "this is the iteration number 37 - loss = 0.5604325532913208\n",
      "this is the iteration number 38 - loss = 0.5187244415283203\n",
      "this is the iteration number 39 - loss = 0.609993040561676\n",
      "this is the iteration number 40 - loss = 0.6318005323410034\n",
      "this is the iteration number 41 - loss = 0.5125407576560974\n",
      "this is the iteration number 42 - loss = 0.5887724161148071\n",
      "this is the iteration number 43 - loss = 0.5193881988525391\n",
      "this is the iteration number 44 - loss = 0.582938551902771\n",
      "this is the iteration number 45 - loss = 0.5947200655937195\n",
      "this is the iteration number 46 - loss = 0.5749044418334961\n",
      "this is the iteration number 47 - loss = 0.5120118856430054\n",
      "this is the iteration number 48 - loss = 0.6446376442909241\n",
      "this is the iteration number 49 - loss = 0.6475745439529419\n",
      "this is the iteration number 50 - loss = 0.5651001334190369\n",
      "this is the iteration number 51 - loss = 0.5762709975242615\n",
      "this is the iteration number 52 - loss = 0.5823079347610474\n",
      "this is the iteration number 53 - loss = 0.5887442827224731\n",
      "this is the iteration number 54 - loss = 0.5245720148086548\n",
      "this is the iteration number 55 - loss = 0.6138688921928406\n",
      "this is the iteration number 56 - loss = 0.6051235795021057\n",
      "this is the iteration number 57 - loss = 0.5895361304283142\n",
      "this is the iteration number 58 - loss = 0.6051540970802307\n",
      "this is the iteration number 59 - loss = 0.5332432985305786\n",
      "this is the iteration number 60 - loss = 0.584269106388092\n",
      "this is the iteration number 61 - loss = 0.569546103477478\n",
      "this is the iteration number 62 - loss = 0.5802564024925232\n",
      "this is the iteration number 63 - loss = 0.6135619878768921\n",
      "this is the iteration number 64 - loss = 0.5395243763923645\n",
      "this is the iteration number 65 - loss = 0.6216818690299988\n",
      "this is the iteration number 66 - loss = 0.549227774143219\n",
      "this is the iteration number 67 - loss = 0.5377814769744873\n",
      "this is the iteration number 68 - loss = 0.6257928013801575\n",
      "this is the iteration number 69 - loss = 0.6191721558570862\n",
      "this is the iteration number 70 - loss = 0.5731037259101868\n",
      "this is the iteration number 71 - loss = 0.6108437180519104\n",
      "this is the iteration number 72 - loss = 0.5654069185256958\n",
      "this is the iteration number 73 - loss = 0.5278131365776062\n",
      "this is the iteration number 74 - loss = 0.6000433564186096\n",
      "this is the iteration number 75 - loss = 0.5764903426170349\n",
      "this is the iteration number 76 - loss = 0.6122792959213257\n",
      "this is the iteration number 77 - loss = 0.6036883592605591\n",
      "this is the iteration number 78 - loss = 0.5289275050163269\n",
      "this is the iteration number 79 - loss = 0.5786250233650208\n",
      "this is the iteration number 80 - loss = 0.5322681069374084\n",
      "this is the iteration number 81 - loss = 0.5763684511184692\n",
      "this is the iteration number 82 - loss = 0.5766733884811401\n",
      "this is the iteration number 83 - loss = 0.5738385319709778\n",
      "this is the iteration number 84 - loss = 0.5481182932853699\n",
      "this is the iteration number 85 - loss = 0.5085896849632263\n",
      "this is the iteration number 86 - loss = 0.5381104350090027\n",
      "this is the iteration number 87 - loss = 0.5355934500694275\n",
      "this is the iteration number 88 - loss = 0.5766662359237671\n",
      "this is the iteration number 89 - loss = 0.5823284387588501\n",
      "this is the iteration number 90 - loss = 0.544852077960968\n",
      "this is the iteration number 91 - loss = 0.5071517825126648\n",
      "this is the iteration number 92 - loss = 0.513313889503479\n",
      "this is the iteration number 93 - loss = 0.5842973589897156\n",
      "this is the iteration number 94 - loss = 0.5687726736068726\n",
      "this is the iteration number 95 - loss = 0.5807386040687561\n",
      "this is the iteration number 96 - loss = 0.5821210741996765\n",
      "this is the iteration number 97 - loss = 0.5758318901062012\n",
      "this is the iteration number 98 - loss = 0.5291906595230103\n",
      "this is the iteration number 99 - loss = 0.5966026186943054\n",
      "this is the iteration number 100 - loss = 0.5630673766136169\n",
      "this is the iteration number 101 - loss = 0.6295869946479797\n",
      "this is the iteration number 0 - loss = 0.5869094729423523\n",
      "this is the iteration number 1 - loss = 0.5805960893630981\n",
      "this is the iteration number 2 - loss = 0.5736244320869446\n",
      "this is the iteration number 3 - loss = 0.5654278993606567\n",
      "this is the iteration number 4 - loss = 0.5983831286430359\n",
      "this is the iteration number 5 - loss = 0.5337596535682678\n",
      "this is the iteration number 6 - loss = 0.5429307222366333\n",
      "this is the iteration number 7 - loss = 0.6065334677696228\n",
      "this is the iteration number 8 - loss = 0.5590347051620483\n",
      "this is the iteration number 9 - loss = 0.6219452619552612\n",
      "this is the iteration number 10 - loss = 0.5896506309509277\n",
      "this is the iteration number 11 - loss = 0.5019615888595581\n",
      "this is the iteration number 12 - loss = 0.5729398727416992\n",
      "this is the iteration number 13 - loss = 0.5132706165313721\n",
      "this is the iteration number 14 - loss = 0.5277217030525208\n",
      "this is the iteration number 15 - loss = 0.5059340596199036\n",
      "this is the iteration number 16 - loss = 0.5757314562797546\n",
      "this is the iteration number 17 - loss = 0.5516270995140076\n",
      "this is the iteration number 18 - loss = 0.5743727684020996\n",
      "this is the iteration number 19 - loss = 0.5509073138237\n",
      "this is the iteration number 20 - loss = 0.5098428130149841\n",
      "this is the iteration number 21 - loss = 0.5479236245155334\n",
      "this is the iteration number 22 - loss = 0.531745433807373\n",
      "this is the iteration number 23 - loss = 0.6165016293525696\n",
      "this is the iteration number 24 - loss = 0.5819594264030457\n",
      "this is the iteration number 25 - loss = 0.582279622554779\n",
      "this is the iteration number 26 - loss = 0.6010190844535828\n",
      "this is the iteration number 27 - loss = 0.5419505834579468\n",
      "this is the iteration number 28 - loss = 0.5505596995353699\n",
      "this is the iteration number 29 - loss = 0.5598196387290955\n",
      "this is the iteration number 30 - loss = 0.6391273140907288\n",
      "this is the iteration number 31 - loss = 0.5945348739624023\n",
      "this is the iteration number 32 - loss = 0.5508899092674255\n",
      "this is the iteration number 33 - loss = 0.5990225076675415\n",
      "this is the iteration number 34 - loss = 0.5315513014793396\n",
      "this is the iteration number 35 - loss = 0.49508628249168396\n",
      "this is the iteration number 36 - loss = 0.5414963960647583\n",
      "this is the iteration number 37 - loss = 0.5726991891860962\n",
      "this is the iteration number 38 - loss = 0.6085155606269836\n",
      "this is the iteration number 39 - loss = 0.5802642703056335\n",
      "this is the iteration number 40 - loss = 0.5689061284065247\n",
      "this is the iteration number 41 - loss = 0.580326497554779\n",
      "this is the iteration number 42 - loss = 0.5306368470191956\n",
      "this is the iteration number 43 - loss = 0.550709068775177\n",
      "this is the iteration number 44 - loss = 0.5915173292160034\n",
      "this is the iteration number 45 - loss = 0.5974878072738647\n",
      "this is the iteration number 46 - loss = 0.5381469130516052\n",
      "this is the iteration number 47 - loss = 0.4976087212562561\n",
      "this is the iteration number 48 - loss = 0.5612090826034546\n",
      "this is the iteration number 49 - loss = 0.5365353226661682\n",
      "this is the iteration number 50 - loss = 0.5438688397407532\n",
      "this is the iteration number 51 - loss = 0.5487409830093384\n",
      "this is the iteration number 52 - loss = 0.5692108273506165\n",
      "this is the iteration number 53 - loss = 0.5089980959892273\n",
      "this is the iteration number 54 - loss = 0.5943365097045898\n",
      "this is the iteration number 55 - loss = 0.5895628929138184\n",
      "this is the iteration number 56 - loss = 0.5834042429924011\n",
      "this is the iteration number 57 - loss = 0.5138443112373352\n",
      "this is the iteration number 58 - loss = 0.5209788680076599\n",
      "this is the iteration number 59 - loss = 0.5688509345054626\n",
      "this is the iteration number 60 - loss = 0.4895433485507965\n",
      "this is the iteration number 61 - loss = 0.5486939549446106\n",
      "this is the iteration number 62 - loss = 0.5423349142074585\n",
      "this is the iteration number 63 - loss = 0.5651890635490417\n",
      "this is the iteration number 64 - loss = 0.5781568288803101\n",
      "this is the iteration number 65 - loss = 0.5435043573379517\n",
      "this is the iteration number 66 - loss = 0.5928419828414917\n",
      "this is the iteration number 67 - loss = 0.4884919226169586\n",
      "this is the iteration number 68 - loss = 0.5576862692832947\n",
      "this is the iteration number 69 - loss = 0.5955298542976379\n",
      "this is the iteration number 70 - loss = 0.5617828965187073\n",
      "this is the iteration number 71 - loss = 0.588080108165741\n",
      "this is the iteration number 72 - loss = 0.5345228910446167\n",
      "this is the iteration number 73 - loss = 0.5582682490348816\n",
      "this is the iteration number 74 - loss = 0.5898906588554382\n",
      "this is the iteration number 75 - loss = 0.5554860830307007\n",
      "this is the iteration number 76 - loss = 0.5504167675971985\n",
      "this is the iteration number 77 - loss = 0.5809411406517029\n",
      "this is the iteration number 78 - loss = 0.5782637596130371\n",
      "this is the iteration number 79 - loss = 0.6046608686447144\n",
      "this is the iteration number 80 - loss = 0.5653405785560608\n",
      "this is the iteration number 81 - loss = 0.6063889265060425\n",
      "this is the iteration number 82 - loss = 0.6090785264968872\n",
      "this is the iteration number 83 - loss = 0.5465951561927795\n",
      "this is the iteration number 84 - loss = 0.6107903718948364\n",
      "this is the iteration number 85 - loss = 0.5111629366874695\n",
      "this is the iteration number 86 - loss = 0.6011704206466675\n",
      "this is the iteration number 87 - loss = 0.5774565935134888\n",
      "this is the iteration number 88 - loss = 0.5369642376899719\n",
      "this is the iteration number 89 - loss = 0.6042913198471069\n",
      "this is the iteration number 90 - loss = 0.5656158924102783\n",
      "this is the iteration number 91 - loss = 0.5847617983818054\n",
      "this is the iteration number 92 - loss = 0.5545305609703064\n",
      "this is the iteration number 93 - loss = 0.5442082285881042\n",
      "this is the iteration number 94 - loss = 0.5414506196975708\n",
      "this is the iteration number 95 - loss = 0.5812104940414429\n",
      "this is the iteration number 96 - loss = 0.4926033020019531\n",
      "this is the iteration number 97 - loss = 0.6526150703430176\n",
      "this is the iteration number 98 - loss = 0.5429129004478455\n",
      "this is the iteration number 99 - loss = 0.5632602572441101\n",
      "this is the iteration number 100 - loss = 0.5934424996376038\n",
      "this is the iteration number 101 - loss = 0.5918582081794739\n",
      "this is the iteration number 0 - loss = 0.5614427328109741\n",
      "this is the iteration number 1 - loss = 0.5741416215896606\n",
      "this is the iteration number 2 - loss = 0.5692464113235474\n",
      "this is the iteration number 3 - loss = 0.5246492624282837\n",
      "this is the iteration number 4 - loss = 0.604590117931366\n",
      "this is the iteration number 5 - loss = 0.4890808165073395\n",
      "this is the iteration number 6 - loss = 0.5551316142082214\n",
      "this is the iteration number 7 - loss = 0.588380753993988\n",
      "this is the iteration number 8 - loss = 0.5476545691490173\n",
      "this is the iteration number 9 - loss = 0.5264055132865906\n",
      "this is the iteration number 10 - loss = 0.5894024968147278\n",
      "this is the iteration number 11 - loss = 0.5780076384544373\n",
      "this is the iteration number 12 - loss = 0.5126566886901855\n",
      "this is the iteration number 13 - loss = 0.5335103273391724\n",
      "this is the iteration number 14 - loss = 0.5499314665794373\n",
      "this is the iteration number 15 - loss = 0.5842567086219788\n",
      "this is the iteration number 16 - loss = 0.635757565498352\n",
      "this is the iteration number 17 - loss = 0.5322735905647278\n",
      "this is the iteration number 18 - loss = 0.5920031666755676\n",
      "this is the iteration number 19 - loss = 0.5588753819465637\n",
      "this is the iteration number 20 - loss = 0.5941857695579529\n",
      "this is the iteration number 21 - loss = 0.5323420763015747\n",
      "this is the iteration number 22 - loss = 0.5214856266975403\n",
      "this is the iteration number 23 - loss = 0.5635290741920471\n",
      "this is the iteration number 24 - loss = 0.5577115416526794\n",
      "this is the iteration number 25 - loss = 0.5999934077262878\n",
      "this is the iteration number 26 - loss = 0.5598474740982056\n",
      "this is the iteration number 27 - loss = 0.6132439374923706\n",
      "this is the iteration number 28 - loss = 0.5371432900428772\n",
      "this is the iteration number 29 - loss = 0.5260093212127686\n",
      "this is the iteration number 30 - loss = 0.5733180642127991\n",
      "this is the iteration number 31 - loss = 0.56067955493927\n",
      "this is the iteration number 32 - loss = 0.5259596705436707\n",
      "this is the iteration number 33 - loss = 0.6046774983406067\n",
      "this is the iteration number 34 - loss = 0.5813743472099304\n",
      "this is the iteration number 35 - loss = 0.5606087446212769\n",
      "this is the iteration number 36 - loss = 0.5786868929862976\n",
      "this is the iteration number 37 - loss = 0.5731333494186401\n",
      "this is the iteration number 38 - loss = 0.5799669623374939\n",
      "this is the iteration number 39 - loss = 0.5788848996162415\n",
      "this is the iteration number 40 - loss = 0.5155640244483948\n",
      "this is the iteration number 41 - loss = 0.5691916942596436\n",
      "this is the iteration number 42 - loss = 0.5395094156265259\n",
      "this is the iteration number 43 - loss = 0.4947529137134552\n",
      "this is the iteration number 44 - loss = 0.5170894265174866\n",
      "this is the iteration number 45 - loss = 0.5561084151268005\n",
      "this is the iteration number 46 - loss = 0.5909005999565125\n",
      "this is the iteration number 47 - loss = 0.5803218483924866\n",
      "this is the iteration number 48 - loss = 0.5135489106178284\n",
      "this is the iteration number 49 - loss = 0.5849462151527405\n",
      "this is the iteration number 50 - loss = 0.5445188283920288\n",
      "this is the iteration number 51 - loss = 0.5238209962844849\n",
      "this is the iteration number 52 - loss = 0.5619840025901794\n",
      "this is the iteration number 53 - loss = 0.5762563943862915\n",
      "this is the iteration number 54 - loss = 0.6337870359420776\n",
      "this is the iteration number 55 - loss = 0.535693347454071\n",
      "this is the iteration number 56 - loss = 0.5762544870376587\n",
      "this is the iteration number 57 - loss = 0.5016064047813416\n",
      "this is the iteration number 58 - loss = 0.6165526509284973\n",
      "this is the iteration number 59 - loss = 0.5813570618629456\n",
      "this is the iteration number 60 - loss = 0.5792250633239746\n",
      "this is the iteration number 61 - loss = 0.5304055213928223\n",
      "this is the iteration number 62 - loss = 0.5355029702186584\n",
      "this is the iteration number 63 - loss = 0.47551479935646057\n",
      "this is the iteration number 64 - loss = 0.524386465549469\n",
      "this is the iteration number 65 - loss = 0.5705992579460144\n",
      "this is the iteration number 66 - loss = 0.5805123448371887\n",
      "this is the iteration number 67 - loss = 0.6144996881484985\n",
      "this is the iteration number 68 - loss = 0.49507808685302734\n",
      "this is the iteration number 69 - loss = 0.5031258463859558\n",
      "this is the iteration number 70 - loss = 0.5843909978866577\n",
      "this is the iteration number 71 - loss = 0.5799134373664856\n",
      "this is the iteration number 72 - loss = 0.47872963547706604\n",
      "this is the iteration number 73 - loss = 0.5444432497024536\n",
      "this is the iteration number 74 - loss = 0.5140306353569031\n",
      "this is the iteration number 75 - loss = 0.557210385799408\n",
      "this is the iteration number 76 - loss = 0.5025026202201843\n",
      "this is the iteration number 77 - loss = 0.5476180911064148\n",
      "this is the iteration number 78 - loss = 0.5714868307113647\n",
      "this is the iteration number 79 - loss = 0.5215606093406677\n",
      "this is the iteration number 80 - loss = 0.5776100158691406\n",
      "this is the iteration number 81 - loss = 0.6285297274589539\n",
      "this is the iteration number 82 - loss = 0.5586406588554382\n",
      "this is the iteration number 83 - loss = 0.542273759841919\n",
      "this is the iteration number 84 - loss = 0.5841888785362244\n",
      "this is the iteration number 85 - loss = 0.557420015335083\n",
      "this is the iteration number 86 - loss = 0.5559517741203308\n",
      "this is the iteration number 87 - loss = 0.5144549608230591\n",
      "this is the iteration number 88 - loss = 0.5726605653762817\n",
      "this is the iteration number 89 - loss = 0.5516906976699829\n",
      "this is the iteration number 90 - loss = 0.6062533259391785\n",
      "this is the iteration number 91 - loss = 0.522181510925293\n",
      "this is the iteration number 92 - loss = 0.5619276165962219\n",
      "this is the iteration number 93 - loss = 0.583422839641571\n",
      "this is the iteration number 94 - loss = 0.5905091166496277\n",
      "this is the iteration number 95 - loss = 0.6031150817871094\n",
      "this is the iteration number 96 - loss = 0.5145789384841919\n",
      "this is the iteration number 97 - loss = 0.5232958197593689\n",
      "this is the iteration number 98 - loss = 0.5622193217277527\n",
      "this is the iteration number 99 - loss = 0.5211192965507507\n",
      "this is the iteration number 100 - loss = 0.5155553221702576\n",
      "this is the iteration number 101 - loss = 0.606560230255127\n",
      "this is the iteration number 0 - loss = 0.5624583959579468\n",
      "this is the iteration number 1 - loss = 0.5820469260215759\n",
      "this is the iteration number 2 - loss = 0.5115407705307007\n",
      "this is the iteration number 3 - loss = 0.4910455048084259\n",
      "this is the iteration number 4 - loss = 0.5231261253356934\n",
      "this is the iteration number 5 - loss = 0.6049893498420715\n",
      "this is the iteration number 6 - loss = 0.5231300592422485\n",
      "this is the iteration number 7 - loss = 0.5752217173576355\n",
      "this is the iteration number 8 - loss = 0.5880774259567261\n",
      "this is the iteration number 9 - loss = 0.5149008631706238\n",
      "this is the iteration number 10 - loss = 0.627082884311676\n",
      "this is the iteration number 11 - loss = 0.5317842364311218\n",
      "this is the iteration number 12 - loss = 0.54643315076828\n",
      "this is the iteration number 13 - loss = 0.5604220032691956\n",
      "this is the iteration number 14 - loss = 0.5072857737541199\n",
      "this is the iteration number 15 - loss = 0.5224077105522156\n",
      "this is the iteration number 16 - loss = 0.527455747127533\n",
      "this is the iteration number 17 - loss = 0.5965632200241089\n",
      "this is the iteration number 18 - loss = 0.4972650110721588\n",
      "this is the iteration number 19 - loss = 0.534622848033905\n",
      "this is the iteration number 20 - loss = 0.5026954412460327\n",
      "this is the iteration number 21 - loss = 0.6507430076599121\n",
      "this is the iteration number 22 - loss = 0.4994789958000183\n",
      "this is the iteration number 23 - loss = 0.5393006205558777\n",
      "this is the iteration number 24 - loss = 0.5512601733207703\n",
      "this is the iteration number 25 - loss = 0.529938817024231\n",
      "this is the iteration number 26 - loss = 0.5505354404449463\n",
      "this is the iteration number 27 - loss = 0.5783033967018127\n",
      "this is the iteration number 28 - loss = 0.5676437616348267\n",
      "this is the iteration number 29 - loss = 0.4887341558933258\n",
      "this is the iteration number 30 - loss = 0.5681303143501282\n",
      "this is the iteration number 31 - loss = 0.5767726898193359\n",
      "this is the iteration number 32 - loss = 0.5867434144020081\n",
      "this is the iteration number 33 - loss = 0.5208027362823486\n",
      "this is the iteration number 34 - loss = 0.643635630607605\n",
      "this is the iteration number 35 - loss = 0.5414064526557922\n",
      "this is the iteration number 36 - loss = 0.5132431387901306\n",
      "this is the iteration number 37 - loss = 0.6180511713027954\n",
      "this is the iteration number 38 - loss = 0.5032879114151001\n",
      "this is the iteration number 39 - loss = 0.5955299735069275\n",
      "this is the iteration number 40 - loss = 0.5527198910713196\n",
      "this is the iteration number 41 - loss = 0.5579465627670288\n",
      "this is the iteration number 42 - loss = 0.6048112511634827\n",
      "this is the iteration number 43 - loss = 0.5321573615074158\n",
      "this is the iteration number 44 - loss = 0.5594735145568848\n",
      "this is the iteration number 45 - loss = 0.5899500846862793\n",
      "this is the iteration number 46 - loss = 0.5319756865501404\n",
      "this is the iteration number 47 - loss = 0.45493245124816895\n",
      "this is the iteration number 48 - loss = 0.5250754952430725\n",
      "this is the iteration number 49 - loss = 0.5576087832450867\n",
      "this is the iteration number 50 - loss = 0.5145428776741028\n",
      "this is the iteration number 51 - loss = 0.5424969792366028\n",
      "this is the iteration number 52 - loss = 0.5665724277496338\n",
      "this is the iteration number 53 - loss = 0.5622748136520386\n",
      "this is the iteration number 54 - loss = 0.5894538164138794\n",
      "this is the iteration number 55 - loss = 0.5436493754386902\n",
      "this is the iteration number 56 - loss = 0.49362844228744507\n",
      "this is the iteration number 57 - loss = 0.5470806956291199\n",
      "this is the iteration number 58 - loss = 0.5257752537727356\n",
      "this is the iteration number 59 - loss = 0.5105097889900208\n",
      "this is the iteration number 60 - loss = 0.5877016186714172\n",
      "this is the iteration number 61 - loss = 0.5303558707237244\n",
      "this is the iteration number 62 - loss = 0.5414878129959106\n",
      "this is the iteration number 63 - loss = 0.47665396332740784\n",
      "this is the iteration number 64 - loss = 0.5794879794120789\n",
      "this is the iteration number 65 - loss = 0.5705644488334656\n",
      "this is the iteration number 66 - loss = 0.5788058638572693\n",
      "this is the iteration number 67 - loss = 0.5229682922363281\n",
      "this is the iteration number 68 - loss = 0.505983829498291\n",
      "this is the iteration number 69 - loss = 0.5240896344184875\n",
      "this is the iteration number 70 - loss = 0.49382850527763367\n",
      "this is the iteration number 71 - loss = 0.5457602143287659\n",
      "this is the iteration number 72 - loss = 0.5599921345710754\n",
      "this is the iteration number 73 - loss = 0.5466601252555847\n",
      "this is the iteration number 74 - loss = 0.5631395578384399\n",
      "this is the iteration number 75 - loss = 0.5320519208908081\n",
      "this is the iteration number 76 - loss = 0.5366736054420471\n",
      "this is the iteration number 77 - loss = 0.5548387169837952\n",
      "this is the iteration number 78 - loss = 0.5770593881607056\n",
      "this is the iteration number 79 - loss = 0.5617615580558777\n",
      "this is the iteration number 80 - loss = 0.5533163547515869\n",
      "this is the iteration number 81 - loss = 0.5967589020729065\n",
      "this is the iteration number 82 - loss = 0.569247305393219\n",
      "this is the iteration number 83 - loss = 0.6007829308509827\n",
      "this is the iteration number 84 - loss = 0.5952399969100952\n",
      "this is the iteration number 85 - loss = 0.5360609889030457\n",
      "this is the iteration number 86 - loss = 0.6027864813804626\n",
      "this is the iteration number 87 - loss = 0.4890815317630768\n",
      "this is the iteration number 88 - loss = 0.5354169607162476\n",
      "this is the iteration number 89 - loss = 0.6077799797058105\n",
      "this is the iteration number 90 - loss = 0.5406695008277893\n",
      "this is the iteration number 91 - loss = 0.5269508361816406\n",
      "this is the iteration number 92 - loss = 0.5675828456878662\n",
      "this is the iteration number 93 - loss = 0.6038267016410828\n",
      "this is the iteration number 94 - loss = 0.5839440226554871\n",
      "this is the iteration number 95 - loss = 0.5717889070510864\n",
      "this is the iteration number 96 - loss = 0.5861933827400208\n",
      "this is the iteration number 97 - loss = 0.5810309052467346\n",
      "this is the iteration number 98 - loss = 0.5168198943138123\n",
      "this is the iteration number 99 - loss = 0.5644308924674988\n",
      "this is the iteration number 100 - loss = 0.5111171007156372\n",
      "this is the iteration number 101 - loss = 0.5381448864936829\n",
      "this is the iteration number 0 - loss = 0.620068371295929\n",
      "this is the iteration number 1 - loss = 0.5131679773330688\n",
      "this is the iteration number 2 - loss = 0.5129491686820984\n",
      "this is the iteration number 3 - loss = 0.5420366525650024\n",
      "this is the iteration number 4 - loss = 0.5787011384963989\n",
      "this is the iteration number 5 - loss = 0.6048819422721863\n",
      "this is the iteration number 6 - loss = 0.5737795829772949\n",
      "this is the iteration number 7 - loss = 0.5550140142440796\n",
      "this is the iteration number 8 - loss = 0.5948575139045715\n",
      "this is the iteration number 9 - loss = 0.5744510889053345\n",
      "this is the iteration number 10 - loss = 0.5348670482635498\n",
      "this is the iteration number 11 - loss = 0.5506452918052673\n",
      "this is the iteration number 12 - loss = 0.5361199378967285\n",
      "this is the iteration number 13 - loss = 0.5365030765533447\n",
      "this is the iteration number 14 - loss = 0.5923829674720764\n",
      "this is the iteration number 15 - loss = 0.5865349173545837\n",
      "this is the iteration number 16 - loss = 0.5226503014564514\n",
      "this is the iteration number 17 - loss = 0.5554487705230713\n",
      "this is the iteration number 18 - loss = 0.5238335132598877\n",
      "this is the iteration number 19 - loss = 0.513034999370575\n",
      "this is the iteration number 20 - loss = 0.5927528738975525\n",
      "this is the iteration number 21 - loss = 0.5247877240180969\n",
      "this is the iteration number 22 - loss = 0.5093992948532104\n",
      "this is the iteration number 23 - loss = 0.5429625511169434\n",
      "this is the iteration number 24 - loss = 0.4991735517978668\n",
      "this is the iteration number 25 - loss = 0.49894604086875916\n",
      "this is the iteration number 26 - loss = 0.5748666524887085\n",
      "this is the iteration number 27 - loss = 0.5678185820579529\n",
      "this is the iteration number 28 - loss = 0.5284265875816345\n",
      "this is the iteration number 29 - loss = 0.5625866055488586\n",
      "this is the iteration number 30 - loss = 0.5959678888320923\n",
      "this is the iteration number 31 - loss = 0.5839051008224487\n",
      "this is the iteration number 32 - loss = 0.5142963528633118\n",
      "this is the iteration number 33 - loss = 0.5407108068466187\n",
      "this is the iteration number 34 - loss = 0.5051246285438538\n",
      "this is the iteration number 35 - loss = 0.5392974615097046\n",
      "this is the iteration number 36 - loss = 0.5047529339790344\n",
      "this is the iteration number 37 - loss = 0.5495554804801941\n",
      "this is the iteration number 38 - loss = 0.540761411190033\n",
      "this is the iteration number 39 - loss = 0.6125952005386353\n",
      "this is the iteration number 40 - loss = 0.46448636054992676\n",
      "this is the iteration number 41 - loss = 0.447278767824173\n",
      "this is the iteration number 42 - loss = 0.5553618669509888\n",
      "this is the iteration number 43 - loss = 0.48761382699012756\n",
      "this is the iteration number 44 - loss = 0.5030723214149475\n",
      "this is the iteration number 45 - loss = 0.5489025712013245\n",
      "this is the iteration number 46 - loss = 0.6174231171607971\n",
      "this is the iteration number 47 - loss = 0.5560633540153503\n",
      "this is the iteration number 48 - loss = 0.5872053503990173\n",
      "this is the iteration number 49 - loss = 0.5021430850028992\n",
      "this is the iteration number 50 - loss = 0.5343889594078064\n",
      "this is the iteration number 51 - loss = 0.5412031412124634\n",
      "this is the iteration number 52 - loss = 0.5595690608024597\n",
      "this is the iteration number 53 - loss = 0.5305653214454651\n",
      "this is the iteration number 54 - loss = 0.46167781949043274\n",
      "this is the iteration number 55 - loss = 0.5552356839179993\n",
      "this is the iteration number 56 - loss = 0.5888814926147461\n",
      "this is the iteration number 57 - loss = 0.5194931626319885\n",
      "this is the iteration number 58 - loss = 0.564720094203949\n",
      "this is the iteration number 59 - loss = 0.5865898132324219\n",
      "this is the iteration number 60 - loss = 0.5887309908866882\n",
      "this is the iteration number 61 - loss = 0.5706228613853455\n",
      "this is the iteration number 62 - loss = 0.5270554423332214\n",
      "this is the iteration number 63 - loss = 0.545458972454071\n",
      "this is the iteration number 64 - loss = 0.5571340322494507\n",
      "this is the iteration number 65 - loss = 0.5526204705238342\n",
      "this is the iteration number 66 - loss = 0.5612509846687317\n",
      "this is the iteration number 67 - loss = 0.6040894389152527\n",
      "this is the iteration number 68 - loss = 0.5308562517166138\n",
      "this is the iteration number 69 - loss = 0.506719172000885\n",
      "this is the iteration number 70 - loss = 0.5426915287971497\n",
      "this is the iteration number 71 - loss = 0.5587412118911743\n",
      "this is the iteration number 72 - loss = 0.5406782031059265\n",
      "this is the iteration number 73 - loss = 0.5992565155029297\n",
      "this is the iteration number 74 - loss = 0.5532580018043518\n",
      "this is the iteration number 75 - loss = 0.5821534395217896\n",
      "this is the iteration number 76 - loss = 0.5611820816993713\n",
      "this is the iteration number 77 - loss = 0.5479243993759155\n",
      "this is the iteration number 78 - loss = 0.5451194047927856\n",
      "this is the iteration number 79 - loss = 0.5789218544960022\n",
      "this is the iteration number 80 - loss = 0.5580502152442932\n",
      "this is the iteration number 81 - loss = 0.5085230469703674\n",
      "this is the iteration number 82 - loss = 0.5369077324867249\n",
      "this is the iteration number 83 - loss = 0.5370254516601562\n",
      "this is the iteration number 84 - loss = 0.5074161887168884\n",
      "this is the iteration number 85 - loss = 0.5044220089912415\n",
      "this is the iteration number 86 - loss = 0.5538901090621948\n",
      "this is the iteration number 87 - loss = 0.5477169156074524\n",
      "this is the iteration number 88 - loss = 0.6276096105575562\n",
      "this is the iteration number 89 - loss = 0.5743861198425293\n",
      "this is the iteration number 90 - loss = 0.5534665584564209\n",
      "this is the iteration number 91 - loss = 0.5555446743965149\n",
      "this is the iteration number 92 - loss = 0.5022140741348267\n",
      "this is the iteration number 93 - loss = 0.5266080498695374\n",
      "this is the iteration number 94 - loss = 0.5347918272018433\n",
      "this is the iteration number 95 - loss = 0.49992066621780396\n",
      "this is the iteration number 96 - loss = 0.5419992804527283\n",
      "this is the iteration number 97 - loss = 0.5081544518470764\n",
      "this is the iteration number 98 - loss = 0.5151692628860474\n",
      "this is the iteration number 99 - loss = 0.488663911819458\n",
      "this is the iteration number 100 - loss = 0.5462550520896912\n",
      "this is the iteration number 101 - loss = 0.5937070250511169\n",
      "this is the iteration number 0 - loss = 0.5531417727470398\n",
      "this is the iteration number 1 - loss = 0.5231667160987854\n",
      "this is the iteration number 2 - loss = 0.5366052389144897\n",
      "this is the iteration number 3 - loss = 0.5567708015441895\n",
      "this is the iteration number 4 - loss = 0.5272626876831055\n",
      "this is the iteration number 5 - loss = 0.5558823943138123\n",
      "this is the iteration number 6 - loss = 0.5161131024360657\n",
      "this is the iteration number 7 - loss = 0.5474334359169006\n",
      "this is the iteration number 8 - loss = 0.550362765789032\n",
      "this is the iteration number 9 - loss = 0.5342830419540405\n",
      "this is the iteration number 10 - loss = 0.5900264978408813\n",
      "this is the iteration number 11 - loss = 0.5128033757209778\n",
      "this is the iteration number 12 - loss = 0.5182749629020691\n",
      "this is the iteration number 13 - loss = 0.5386050939559937\n",
      "this is the iteration number 14 - loss = 0.547465443611145\n",
      "this is the iteration number 15 - loss = 0.5360985398292542\n",
      "this is the iteration number 16 - loss = 0.46718350052833557\n",
      "this is the iteration number 17 - loss = 0.6009112596511841\n",
      "this is the iteration number 18 - loss = 0.4903118908405304\n",
      "this is the iteration number 19 - loss = 0.5350062251091003\n",
      "this is the iteration number 20 - loss = 0.5231118202209473\n",
      "this is the iteration number 21 - loss = 0.5284738540649414\n",
      "this is the iteration number 22 - loss = 0.5306209325790405\n",
      "this is the iteration number 23 - loss = 0.5432543158531189\n",
      "this is the iteration number 24 - loss = 0.5424774885177612\n",
      "this is the iteration number 25 - loss = 0.5821537375450134\n",
      "this is the iteration number 26 - loss = 0.5726460218429565\n",
      "this is the iteration number 27 - loss = 0.5480206608772278\n",
      "this is the iteration number 28 - loss = 0.5811777114868164\n",
      "this is the iteration number 29 - loss = 0.5164748430252075\n",
      "this is the iteration number 30 - loss = 0.5468007922172546\n",
      "this is the iteration number 31 - loss = 0.5147174596786499\n",
      "this is the iteration number 32 - loss = 0.5217261910438538\n",
      "this is the iteration number 33 - loss = 0.5110015869140625\n",
      "this is the iteration number 34 - loss = 0.5913137197494507\n",
      "this is the iteration number 35 - loss = 0.5084551572799683\n",
      "this is the iteration number 36 - loss = 0.5567023158073425\n",
      "this is the iteration number 37 - loss = 0.5360320210456848\n",
      "this is the iteration number 38 - loss = 0.5513812899589539\n",
      "this is the iteration number 39 - loss = 0.5752571821212769\n",
      "this is the iteration number 40 - loss = 0.5282920002937317\n",
      "this is the iteration number 41 - loss = 0.5582659244537354\n",
      "this is the iteration number 42 - loss = 0.5761064291000366\n",
      "this is the iteration number 43 - loss = 0.5359708070755005\n",
      "this is the iteration number 44 - loss = 0.5607279539108276\n",
      "this is the iteration number 45 - loss = 0.5345216393470764\n",
      "this is the iteration number 46 - loss = 0.5893564224243164\n",
      "this is the iteration number 47 - loss = 0.4988079071044922\n",
      "this is the iteration number 48 - loss = 0.5527244806289673\n",
      "this is the iteration number 49 - loss = 0.6252871155738831\n",
      "this is the iteration number 50 - loss = 0.5435286164283752\n",
      "this is the iteration number 51 - loss = 0.4988754093647003\n",
      "this is the iteration number 52 - loss = 0.5955756306648254\n",
      "this is the iteration number 53 - loss = 0.5609505772590637\n",
      "this is the iteration number 54 - loss = 0.5673314332962036\n",
      "this is the iteration number 55 - loss = 0.505008339881897\n",
      "this is the iteration number 56 - loss = 0.5678483843803406\n",
      "this is the iteration number 57 - loss = 0.5845932960510254\n",
      "this is the iteration number 58 - loss = 0.5445116758346558\n",
      "this is the iteration number 59 - loss = 0.5234119296073914\n",
      "this is the iteration number 60 - loss = 0.5283854603767395\n",
      "this is the iteration number 61 - loss = 0.5519254803657532\n",
      "this is the iteration number 62 - loss = 0.5432350635528564\n",
      "this is the iteration number 63 - loss = 0.48538443446159363\n",
      "this is the iteration number 64 - loss = 0.5761327743530273\n",
      "this is the iteration number 65 - loss = 0.5524519085884094\n",
      "this is the iteration number 66 - loss = 0.4707692563533783\n",
      "this is the iteration number 67 - loss = 0.5424694418907166\n",
      "this is the iteration number 68 - loss = 0.4998501241207123\n",
      "this is the iteration number 69 - loss = 0.5644040703773499\n",
      "this is the iteration number 70 - loss = 0.6185024380683899\n",
      "this is the iteration number 71 - loss = 0.5723870992660522\n",
      "this is the iteration number 72 - loss = 0.5286166667938232\n",
      "this is the iteration number 73 - loss = 0.5367154479026794\n",
      "this is the iteration number 74 - loss = 0.5826814770698547\n",
      "this is the iteration number 75 - loss = 0.5102553367614746\n",
      "this is the iteration number 76 - loss = 0.481039434671402\n",
      "this is the iteration number 77 - loss = 0.5524638295173645\n",
      "this is the iteration number 78 - loss = 0.5582507252693176\n",
      "this is the iteration number 79 - loss = 0.5543108582496643\n",
      "this is the iteration number 80 - loss = 0.5084661841392517\n",
      "this is the iteration number 81 - loss = 0.5500438809394836\n",
      "this is the iteration number 82 - loss = 0.4890916645526886\n",
      "this is the iteration number 83 - loss = 0.5539119839668274\n",
      "this is the iteration number 84 - loss = 0.47137904167175293\n",
      "this is the iteration number 85 - loss = 0.5088713765144348\n",
      "this is the iteration number 86 - loss = 0.5361648797988892\n",
      "this is the iteration number 87 - loss = 0.5396254658699036\n",
      "this is the iteration number 88 - loss = 0.4844682514667511\n",
      "this is the iteration number 89 - loss = 0.6022224426269531\n",
      "this is the iteration number 90 - loss = 0.5540931224822998\n",
      "this is the iteration number 91 - loss = 0.5779803991317749\n",
      "this is the iteration number 92 - loss = 0.5309730172157288\n",
      "this is the iteration number 93 - loss = 0.5008519291877747\n",
      "this is the iteration number 94 - loss = 0.5066379904747009\n",
      "this is the iteration number 95 - loss = 0.5200235247612\n",
      "this is the iteration number 96 - loss = 0.5328117609024048\n",
      "this is the iteration number 97 - loss = 0.5311171412467957\n",
      "this is the iteration number 98 - loss = 0.5687119364738464\n",
      "this is the iteration number 99 - loss = 0.5323091745376587\n",
      "this is the iteration number 100 - loss = 0.5964668989181519\n",
      "this is the iteration number 101 - loss = 0.4976297914981842\n",
      "this is the iteration number 0 - loss = 0.5684475898742676\n",
      "this is the iteration number 1 - loss = 0.5425857901573181\n",
      "this is the iteration number 2 - loss = 0.541621744632721\n",
      "this is the iteration number 3 - loss = 0.5340461134910583\n",
      "this is the iteration number 4 - loss = 0.5300982594490051\n",
      "this is the iteration number 5 - loss = 0.565666139125824\n",
      "this is the iteration number 6 - loss = 0.5201309323310852\n",
      "this is the iteration number 7 - loss = 0.5522713661193848\n",
      "this is the iteration number 8 - loss = 0.4875825047492981\n",
      "this is the iteration number 9 - loss = 0.5212642550468445\n",
      "this is the iteration number 10 - loss = 0.5834223628044128\n",
      "this is the iteration number 11 - loss = 0.537370502948761\n",
      "this is the iteration number 12 - loss = 0.5292676091194153\n",
      "this is the iteration number 13 - loss = 0.484861820936203\n",
      "this is the iteration number 14 - loss = 0.5536787509918213\n",
      "this is the iteration number 15 - loss = 0.5480550527572632\n",
      "this is the iteration number 16 - loss = 0.4969203472137451\n",
      "this is the iteration number 17 - loss = 0.49261370301246643\n",
      "this is the iteration number 18 - loss = 0.5696994662284851\n",
      "this is the iteration number 19 - loss = 0.5338358283042908\n",
      "this is the iteration number 20 - loss = 0.5016528367996216\n",
      "this is the iteration number 21 - loss = 0.5313083529472351\n",
      "this is the iteration number 22 - loss = 0.49380403757095337\n",
      "this is the iteration number 23 - loss = 0.5447230935096741\n",
      "this is the iteration number 24 - loss = 0.5256849527359009\n",
      "this is the iteration number 25 - loss = 0.48872312903404236\n",
      "this is the iteration number 26 - loss = 0.50914466381073\n",
      "this is the iteration number 27 - loss = 0.48912662267684937\n",
      "this is the iteration number 28 - loss = 0.49231547117233276\n",
      "this is the iteration number 29 - loss = 0.50584477186203\n",
      "this is the iteration number 30 - loss = 0.5437516570091248\n",
      "this is the iteration number 31 - loss = 0.5338298082351685\n",
      "this is the iteration number 32 - loss = 0.5750681757926941\n",
      "this is the iteration number 33 - loss = 0.5913103818893433\n",
      "this is the iteration number 34 - loss = 0.5822024345397949\n",
      "this is the iteration number 35 - loss = 0.49404045939445496\n",
      "this is the iteration number 36 - loss = 0.5440805554389954\n",
      "this is the iteration number 37 - loss = 0.5855064988136292\n",
      "this is the iteration number 38 - loss = 0.5531641840934753\n",
      "this is the iteration number 39 - loss = 0.5392381548881531\n",
      "this is the iteration number 40 - loss = 0.5015788674354553\n",
      "this is the iteration number 41 - loss = 0.5648468136787415\n",
      "this is the iteration number 42 - loss = 0.5536255240440369\n",
      "this is the iteration number 43 - loss = 0.564868152141571\n",
      "this is the iteration number 44 - loss = 0.5807119607925415\n",
      "this is the iteration number 45 - loss = 0.5626123547554016\n",
      "this is the iteration number 46 - loss = 0.55820232629776\n",
      "this is the iteration number 47 - loss = 0.5297555327415466\n",
      "this is the iteration number 48 - loss = 0.5392301082611084\n",
      "this is the iteration number 49 - loss = 0.5387941598892212\n",
      "this is the iteration number 50 - loss = 0.5593668818473816\n",
      "this is the iteration number 51 - loss = 0.5199366211891174\n",
      "this is the iteration number 52 - loss = 0.5672742128372192\n",
      "this is the iteration number 53 - loss = 0.5539892911911011\n",
      "this is the iteration number 54 - loss = 0.48826906085014343\n",
      "this is the iteration number 55 - loss = 0.5281150937080383\n",
      "this is the iteration number 56 - loss = 0.5147340893745422\n",
      "this is the iteration number 57 - loss = 0.5869770646095276\n",
      "this is the iteration number 58 - loss = 0.5523481965065002\n",
      "this is the iteration number 59 - loss = 0.519169807434082\n",
      "this is the iteration number 60 - loss = 0.5826119184494019\n",
      "this is the iteration number 61 - loss = 0.5281294584274292\n",
      "this is the iteration number 62 - loss = 0.5128527283668518\n",
      "this is the iteration number 63 - loss = 0.5388444066047668\n",
      "this is the iteration number 64 - loss = 0.5344433784484863\n",
      "this is the iteration number 65 - loss = 0.5445165038108826\n",
      "this is the iteration number 66 - loss = 0.5300451517105103\n",
      "this is the iteration number 67 - loss = 0.5045527815818787\n",
      "this is the iteration number 68 - loss = 0.48781993985176086\n",
      "this is the iteration number 69 - loss = 0.5609874725341797\n",
      "this is the iteration number 70 - loss = 0.5286136269569397\n",
      "this is the iteration number 71 - loss = 0.5772953033447266\n",
      "this is the iteration number 72 - loss = 0.5080662965774536\n",
      "this is the iteration number 73 - loss = 0.5204707980155945\n",
      "this is the iteration number 74 - loss = 0.5314200520515442\n",
      "this is the iteration number 75 - loss = 0.5570626258850098\n",
      "this is the iteration number 76 - loss = 0.5344117283821106\n",
      "this is the iteration number 77 - loss = 0.5193712115287781\n",
      "this is the iteration number 78 - loss = 0.5290471315383911\n",
      "this is the iteration number 79 - loss = 0.5516265034675598\n",
      "this is the iteration number 80 - loss = 0.5705252885818481\n",
      "this is the iteration number 81 - loss = 0.6353750824928284\n",
      "this is the iteration number 82 - loss = 0.4958674907684326\n",
      "this is the iteration number 83 - loss = 0.5042902231216431\n",
      "this is the iteration number 84 - loss = 0.5005708932876587\n",
      "this is the iteration number 85 - loss = 0.545282244682312\n",
      "this is the iteration number 86 - loss = 0.5366121530532837\n",
      "this is the iteration number 87 - loss = 0.5142979025840759\n",
      "this is the iteration number 88 - loss = 0.5467199683189392\n",
      "this is the iteration number 89 - loss = 0.5984330177307129\n",
      "this is the iteration number 90 - loss = 0.5494744181632996\n",
      "this is the iteration number 91 - loss = 0.5318354964256287\n",
      "this is the iteration number 92 - loss = 0.4927051067352295\n",
      "this is the iteration number 93 - loss = 0.5427975058555603\n",
      "this is the iteration number 94 - loss = 0.5259720087051392\n",
      "this is the iteration number 95 - loss = 0.6300970911979675\n",
      "this is the iteration number 96 - loss = 0.4756341576576233\n",
      "this is the iteration number 97 - loss = 0.5322809815406799\n",
      "this is the iteration number 98 - loss = 0.5178588032722473\n",
      "this is the iteration number 99 - loss = 0.4860322177410126\n",
      "this is the iteration number 100 - loss = 0.5500443577766418\n",
      "this is the iteration number 101 - loss = 0.6298426985740662\n",
      "this is the iteration number 0 - loss = 0.48475024104118347\n",
      "this is the iteration number 1 - loss = 0.46524786949157715\n",
      "this is the iteration number 2 - loss = 0.5114035606384277\n",
      "this is the iteration number 3 - loss = 0.5378636717796326\n",
      "this is the iteration number 4 - loss = 0.5355082750320435\n",
      "this is the iteration number 5 - loss = 0.533352255821228\n",
      "this is the iteration number 6 - loss = 0.5538155436515808\n",
      "this is the iteration number 7 - loss = 0.588508665561676\n",
      "this is the iteration number 8 - loss = 0.5507535338401794\n",
      "this is the iteration number 9 - loss = 0.5788302421569824\n",
      "this is the iteration number 10 - loss = 0.4659465253353119\n",
      "this is the iteration number 11 - loss = 0.4790551960468292\n",
      "this is the iteration number 12 - loss = 0.5561675429344177\n",
      "this is the iteration number 13 - loss = 0.5373424291610718\n",
      "this is the iteration number 14 - loss = 0.5140243768692017\n",
      "this is the iteration number 15 - loss = 0.5545759201049805\n",
      "this is the iteration number 16 - loss = 0.535920262336731\n",
      "this is the iteration number 17 - loss = 0.5898771286010742\n",
      "this is the iteration number 18 - loss = 0.5720018744468689\n",
      "this is the iteration number 19 - loss = 0.5525069832801819\n",
      "this is the iteration number 20 - loss = 0.5175517201423645\n",
      "this is the iteration number 21 - loss = 0.4953380525112152\n",
      "this is the iteration number 22 - loss = 0.5388277173042297\n",
      "this is the iteration number 23 - loss = 0.5470327138900757\n",
      "this is the iteration number 24 - loss = 0.5062505006790161\n",
      "this is the iteration number 25 - loss = 0.5572144389152527\n",
      "this is the iteration number 26 - loss = 0.5368961095809937\n",
      "this is the iteration number 27 - loss = 0.5604652762413025\n",
      "this is the iteration number 28 - loss = 0.5224974155426025\n",
      "this is the iteration number 29 - loss = 0.533294141292572\n",
      "this is the iteration number 30 - loss = 0.5105113387107849\n",
      "this is the iteration number 31 - loss = 0.5385977029800415\n",
      "this is the iteration number 32 - loss = 0.5039113163948059\n",
      "this is the iteration number 33 - loss = 0.5359665751457214\n",
      "this is the iteration number 34 - loss = 0.546563446521759\n",
      "this is the iteration number 35 - loss = 0.47945070266723633\n",
      "this is the iteration number 36 - loss = 0.5223061442375183\n",
      "this is the iteration number 37 - loss = 0.5065622925758362\n",
      "this is the iteration number 38 - loss = 0.5436557531356812\n",
      "this is the iteration number 39 - loss = 0.5250629782676697\n",
      "this is the iteration number 40 - loss = 0.49805861711502075\n",
      "this is the iteration number 41 - loss = 0.4991820156574249\n",
      "this is the iteration number 42 - loss = 0.5631612539291382\n",
      "this is the iteration number 43 - loss = 0.4799969494342804\n",
      "this is the iteration number 44 - loss = 0.5320338606834412\n",
      "this is the iteration number 45 - loss = 0.6118783950805664\n",
      "this is the iteration number 46 - loss = 0.5219274163246155\n",
      "this is the iteration number 47 - loss = 0.4858027398586273\n",
      "this is the iteration number 48 - loss = 0.5504317879676819\n",
      "this is the iteration number 49 - loss = 0.5461792349815369\n",
      "this is the iteration number 50 - loss = 0.5700486898422241\n",
      "this is the iteration number 51 - loss = 0.5875152945518494\n",
      "this is the iteration number 52 - loss = 0.5626787543296814\n",
      "this is the iteration number 53 - loss = 0.5228215456008911\n",
      "this is the iteration number 54 - loss = 0.5588000416755676\n",
      "this is the iteration number 55 - loss = 0.5665283799171448\n",
      "this is the iteration number 56 - loss = 0.5477670431137085\n",
      "this is the iteration number 57 - loss = 0.6072918772697449\n",
      "this is the iteration number 58 - loss = 0.5369757413864136\n",
      "this is the iteration number 59 - loss = 0.5534135103225708\n",
      "this is the iteration number 60 - loss = 0.5163692831993103\n",
      "this is the iteration number 61 - loss = 0.538917064666748\n",
      "this is the iteration number 62 - loss = 0.4933529794216156\n",
      "this is the iteration number 63 - loss = 0.5546336770057678\n",
      "this is the iteration number 64 - loss = 0.530517578125\n",
      "this is the iteration number 65 - loss = 0.5140520334243774\n",
      "this is the iteration number 66 - loss = 0.544565737247467\n",
      "this is the iteration number 67 - loss = 0.49216359853744507\n",
      "this is the iteration number 68 - loss = 0.5011064410209656\n",
      "this is the iteration number 69 - loss = 0.481579065322876\n",
      "this is the iteration number 70 - loss = 0.5023980736732483\n",
      "this is the iteration number 71 - loss = 0.5711873769760132\n",
      "this is the iteration number 72 - loss = 0.5565819144248962\n",
      "this is the iteration number 73 - loss = 0.5483716130256653\n",
      "this is the iteration number 74 - loss = 0.4963667690753937\n",
      "this is the iteration number 75 - loss = 0.5358594059944153\n",
      "this is the iteration number 76 - loss = 0.520072340965271\n",
      "this is the iteration number 77 - loss = 0.499225378036499\n",
      "this is the iteration number 78 - loss = 0.5130628943443298\n",
      "this is the iteration number 79 - loss = 0.5049666166305542\n",
      "this is the iteration number 80 - loss = 0.556050181388855\n",
      "this is the iteration number 81 - loss = 0.5640968084335327\n",
      "this is the iteration number 82 - loss = 0.5031096339225769\n",
      "this is the iteration number 83 - loss = 0.5718353390693665\n",
      "this is the iteration number 84 - loss = 0.5873686671257019\n",
      "this is the iteration number 85 - loss = 0.5110464096069336\n",
      "this is the iteration number 86 - loss = 0.5259315371513367\n",
      "this is the iteration number 87 - loss = 0.52167147397995\n",
      "this is the iteration number 88 - loss = 0.528271496295929\n",
      "this is the iteration number 89 - loss = 0.5193355679512024\n",
      "this is the iteration number 90 - loss = 0.5789541006088257\n",
      "this is the iteration number 91 - loss = 0.5611494183540344\n",
      "this is the iteration number 92 - loss = 0.4896194040775299\n",
      "this is the iteration number 93 - loss = 0.5303899645805359\n",
      "this is the iteration number 94 - loss = 0.5175707340240479\n",
      "this is the iteration number 95 - loss = 0.5007968544960022\n",
      "this is the iteration number 96 - loss = 0.5069058537483215\n",
      "this is the iteration number 97 - loss = 0.5595611333847046\n",
      "this is the iteration number 98 - loss = 0.5656172633171082\n",
      "this is the iteration number 99 - loss = 0.5296562910079956\n",
      "this is the iteration number 100 - loss = 0.5137122273445129\n",
      "this is the iteration number 101 - loss = 0.5421404838562012\n",
      "this is the iteration number 0 - loss = 0.5257183909416199\n",
      "this is the iteration number 1 - loss = 0.5422957539558411\n",
      "this is the iteration number 2 - loss = 0.5032140016555786\n",
      "this is the iteration number 3 - loss = 0.5756931304931641\n",
      "this is the iteration number 4 - loss = 0.5487794876098633\n",
      "this is the iteration number 5 - loss = 0.5578228235244751\n",
      "this is the iteration number 6 - loss = 0.5291704535484314\n",
      "this is the iteration number 7 - loss = 0.5142087936401367\n",
      "this is the iteration number 8 - loss = 0.4915383458137512\n",
      "this is the iteration number 9 - loss = 0.5083799958229065\n",
      "this is the iteration number 10 - loss = 0.5091789364814758\n",
      "this is the iteration number 11 - loss = 0.5343142747879028\n",
      "this is the iteration number 12 - loss = 0.52247154712677\n",
      "this is the iteration number 13 - loss = 0.5012077689170837\n",
      "this is the iteration number 14 - loss = 0.5624197125434875\n",
      "this is the iteration number 15 - loss = 0.5795911550521851\n",
      "this is the iteration number 16 - loss = 0.4690991938114166\n",
      "this is the iteration number 17 - loss = 0.5611594915390015\n",
      "this is the iteration number 18 - loss = 0.5162343978881836\n",
      "this is the iteration number 19 - loss = 0.5175684690475464\n",
      "this is the iteration number 20 - loss = 0.5226884484291077\n",
      "this is the iteration number 21 - loss = 0.5568994879722595\n",
      "this is the iteration number 22 - loss = 0.5465340614318848\n",
      "this is the iteration number 23 - loss = 0.558957040309906\n",
      "this is the iteration number 24 - loss = 0.5900232195854187\n",
      "this is the iteration number 25 - loss = 0.5138445496559143\n",
      "this is the iteration number 26 - loss = 0.48392871022224426\n",
      "this is the iteration number 27 - loss = 0.5451339483261108\n",
      "this is the iteration number 28 - loss = 0.5074253082275391\n",
      "this is the iteration number 29 - loss = 0.5042878985404968\n",
      "this is the iteration number 30 - loss = 0.5039596557617188\n",
      "this is the iteration number 31 - loss = 0.5353545546531677\n",
      "this is the iteration number 32 - loss = 0.4667292535305023\n",
      "this is the iteration number 33 - loss = 0.5387229919433594\n",
      "this is the iteration number 34 - loss = 0.49174341559410095\n",
      "this is the iteration number 35 - loss = 0.5189794898033142\n",
      "this is the iteration number 36 - loss = 0.4482934772968292\n",
      "this is the iteration number 37 - loss = 0.5254439115524292\n",
      "this is the iteration number 38 - loss = 0.5549394488334656\n",
      "this is the iteration number 39 - loss = 0.5302519202232361\n",
      "this is the iteration number 40 - loss = 0.5047715306282043\n",
      "this is the iteration number 41 - loss = 0.5094730257987976\n",
      "this is the iteration number 42 - loss = 0.559561014175415\n",
      "this is the iteration number 43 - loss = 0.5395469665527344\n",
      "this is the iteration number 44 - loss = 0.5944388508796692\n",
      "this is the iteration number 45 - loss = 0.543485164642334\n",
      "this is the iteration number 46 - loss = 0.5348766446113586\n",
      "this is the iteration number 47 - loss = 0.5337711572647095\n",
      "this is the iteration number 48 - loss = 0.5214911103248596\n",
      "this is the iteration number 49 - loss = 0.5316117405891418\n",
      "this is the iteration number 50 - loss = 0.49000003933906555\n",
      "this is the iteration number 51 - loss = 0.5233877301216125\n",
      "this is the iteration number 52 - loss = 0.5261113047599792\n",
      "this is the iteration number 53 - loss = 0.5289777517318726\n",
      "this is the iteration number 54 - loss = 0.564399003982544\n",
      "this is the iteration number 55 - loss = 0.5313028693199158\n",
      "this is the iteration number 56 - loss = 0.5207551717758179\n",
      "this is the iteration number 57 - loss = 0.560363233089447\n",
      "this is the iteration number 58 - loss = 0.5032590627670288\n",
      "this is the iteration number 59 - loss = 0.5702958703041077\n",
      "this is the iteration number 60 - loss = 0.5103102326393127\n",
      "this is the iteration number 61 - loss = 0.5573399662971497\n",
      "this is the iteration number 62 - loss = 0.5286025404930115\n",
      "this is the iteration number 63 - loss = 0.5071224570274353\n",
      "this is the iteration number 64 - loss = 0.5098552107810974\n",
      "this is the iteration number 65 - loss = 0.48949235677719116\n",
      "this is the iteration number 66 - loss = 0.5498430728912354\n",
      "this is the iteration number 67 - loss = 0.5450109839439392\n",
      "this is the iteration number 68 - loss = 0.4666955769062042\n",
      "this is the iteration number 69 - loss = 0.48645153641700745\n",
      "this is the iteration number 70 - loss = 0.48994678258895874\n",
      "this is the iteration number 71 - loss = 0.5851078033447266\n",
      "this is the iteration number 72 - loss = 0.5316106677055359\n",
      "this is the iteration number 73 - loss = 0.5680153965950012\n",
      "this is the iteration number 74 - loss = 0.4872371256351471\n",
      "this is the iteration number 75 - loss = 0.5365253686904907\n",
      "this is the iteration number 76 - loss = 0.5212441086769104\n",
      "this is the iteration number 77 - loss = 0.510586678981781\n",
      "this is the iteration number 78 - loss = 0.5208550691604614\n",
      "this is the iteration number 79 - loss = 0.5235092043876648\n",
      "this is the iteration number 80 - loss = 0.49265193939208984\n",
      "this is the iteration number 81 - loss = 0.5303316712379456\n",
      "this is the iteration number 82 - loss = 0.5567206144332886\n",
      "this is the iteration number 83 - loss = 0.5485443472862244\n",
      "this is the iteration number 84 - loss = 0.5875239968299866\n",
      "this is the iteration number 85 - loss = 0.46916016936302185\n",
      "this is the iteration number 86 - loss = 0.5205121636390686\n",
      "this is the iteration number 87 - loss = 0.5314164757728577\n",
      "this is the iteration number 88 - loss = 0.5816822052001953\n",
      "this is the iteration number 89 - loss = 0.5569295287132263\n",
      "this is the iteration number 90 - loss = 0.5635704398155212\n",
      "this is the iteration number 91 - loss = 0.5895070433616638\n",
      "this is the iteration number 92 - loss = 0.5678948760032654\n",
      "this is the iteration number 93 - loss = 0.550348162651062\n",
      "this is the iteration number 94 - loss = 0.472655713558197\n",
      "this is the iteration number 95 - loss = 0.5329288244247437\n",
      "this is the iteration number 96 - loss = 0.4997892677783966\n",
      "this is the iteration number 97 - loss = 0.5440533757209778\n",
      "this is the iteration number 98 - loss = 0.5554665327072144\n",
      "this is the iteration number 99 - loss = 0.49894315004348755\n",
      "this is the iteration number 100 - loss = 0.5377763509750366\n",
      "this is the iteration number 101 - loss = 0.5657584071159363\n",
      "this is the iteration number 0 - loss = 0.4994437098503113\n",
      "this is the iteration number 1 - loss = 0.5170519948005676\n",
      "this is the iteration number 2 - loss = 0.528997004032135\n",
      "this is the iteration number 3 - loss = 0.6245710253715515\n",
      "this is the iteration number 4 - loss = 0.5397592782974243\n",
      "this is the iteration number 5 - loss = 0.5335926413536072\n",
      "this is the iteration number 6 - loss = 0.5420861840248108\n",
      "this is the iteration number 7 - loss = 0.5096036195755005\n",
      "this is the iteration number 8 - loss = 0.48149505257606506\n",
      "this is the iteration number 9 - loss = 0.5117629766464233\n",
      "this is the iteration number 10 - loss = 0.5061037540435791\n",
      "this is the iteration number 11 - loss = 0.47688809037208557\n",
      "this is the iteration number 12 - loss = 0.5146228671073914\n",
      "this is the iteration number 13 - loss = 0.5577338337898254\n",
      "this is the iteration number 14 - loss = 0.49275487661361694\n",
      "this is the iteration number 15 - loss = 0.538016676902771\n",
      "this is the iteration number 16 - loss = 0.5630130171775818\n",
      "this is the iteration number 17 - loss = 0.5638748407363892\n",
      "this is the iteration number 18 - loss = 0.49017319083213806\n",
      "this is the iteration number 19 - loss = 0.5191178917884827\n",
      "this is the iteration number 20 - loss = 0.5445944666862488\n",
      "this is the iteration number 21 - loss = 0.5322386026382446\n",
      "this is the iteration number 22 - loss = 0.4926982522010803\n",
      "this is the iteration number 23 - loss = 0.5492526292800903\n",
      "this is the iteration number 24 - loss = 0.5302128791809082\n",
      "this is the iteration number 25 - loss = 0.487628698348999\n",
      "this is the iteration number 26 - loss = 0.5496976971626282\n",
      "this is the iteration number 27 - loss = 0.5215060114860535\n",
      "this is the iteration number 28 - loss = 0.5798274874687195\n",
      "this is the iteration number 29 - loss = 0.5632845163345337\n",
      "this is the iteration number 30 - loss = 0.4906966984272003\n",
      "this is the iteration number 31 - loss = 0.5851430892944336\n",
      "this is the iteration number 32 - loss = 0.5296086668968201\n",
      "this is the iteration number 33 - loss = 0.4771821200847626\n",
      "this is the iteration number 34 - loss = 0.5170899629592896\n",
      "this is the iteration number 35 - loss = 0.4802119731903076\n",
      "this is the iteration number 36 - loss = 0.5337945222854614\n",
      "this is the iteration number 37 - loss = 0.4832594394683838\n",
      "this is the iteration number 38 - loss = 0.5922508239746094\n",
      "this is the iteration number 39 - loss = 0.5115426778793335\n",
      "this is the iteration number 40 - loss = 0.5319514274597168\n",
      "this is the iteration number 41 - loss = 0.46938183903694153\n",
      "this is the iteration number 42 - loss = 0.4676420986652374\n",
      "this is the iteration number 43 - loss = 0.5174404978752136\n",
      "this is the iteration number 44 - loss = 0.5699034333229065\n",
      "this is the iteration number 45 - loss = 0.5186949372291565\n",
      "this is the iteration number 46 - loss = 0.5093214511871338\n",
      "this is the iteration number 47 - loss = 0.5397015810012817\n",
      "this is the iteration number 48 - loss = 0.5368434190750122\n",
      "this is the iteration number 49 - loss = 0.5228165984153748\n",
      "this is the iteration number 50 - loss = 0.5731890797615051\n",
      "this is the iteration number 51 - loss = 0.5329390168190002\n",
      "this is the iteration number 52 - loss = 0.5676526427268982\n",
      "this is the iteration number 53 - loss = 0.5482162237167358\n",
      "this is the iteration number 54 - loss = 0.5202675461769104\n",
      "this is the iteration number 55 - loss = 0.48271408677101135\n",
      "this is the iteration number 56 - loss = 0.5281001329421997\n",
      "this is the iteration number 57 - loss = 0.5960111021995544\n",
      "this is the iteration number 58 - loss = 0.5209187269210815\n",
      "this is the iteration number 59 - loss = 0.5154610872268677\n",
      "this is the iteration number 60 - loss = 0.5267831683158875\n",
      "this is the iteration number 61 - loss = 0.4817960560321808\n",
      "this is the iteration number 62 - loss = 0.5302294492721558\n",
      "this is the iteration number 63 - loss = 0.5052417516708374\n",
      "this is the iteration number 64 - loss = 0.5293297171592712\n",
      "this is the iteration number 65 - loss = 0.5547159314155579\n",
      "this is the iteration number 66 - loss = 0.5343591570854187\n",
      "this is the iteration number 67 - loss = 0.4570299983024597\n",
      "this is the iteration number 68 - loss = 0.5211026668548584\n",
      "this is the iteration number 69 - loss = 0.5749163627624512\n",
      "this is the iteration number 70 - loss = 0.5529607534408569\n",
      "this is the iteration number 71 - loss = 0.5488437414169312\n",
      "this is the iteration number 72 - loss = 0.5017088651657104\n",
      "this is the iteration number 73 - loss = 0.5095896124839783\n",
      "this is the iteration number 74 - loss = 0.5377683043479919\n",
      "this is the iteration number 75 - loss = 0.5165120959281921\n",
      "this is the iteration number 76 - loss = 0.5405661463737488\n",
      "this is the iteration number 77 - loss = 0.501814067363739\n",
      "this is the iteration number 78 - loss = 0.5223442316055298\n",
      "this is the iteration number 79 - loss = 0.5105227828025818\n",
      "this is the iteration number 80 - loss = 0.5221267342567444\n",
      "this is the iteration number 81 - loss = 0.48732662200927734\n",
      "this is the iteration number 82 - loss = 0.5187987089157104\n",
      "this is the iteration number 83 - loss = 0.5147648453712463\n",
      "this is the iteration number 84 - loss = 0.49854305386543274\n",
      "this is the iteration number 85 - loss = 0.5074952840805054\n",
      "this is the iteration number 86 - loss = 0.5948597192764282\n",
      "this is the iteration number 87 - loss = 0.49672776460647583\n",
      "this is the iteration number 88 - loss = 0.5384116768836975\n",
      "this is the iteration number 89 - loss = 0.5749144554138184\n",
      "this is the iteration number 90 - loss = 0.5892764329910278\n",
      "this is the iteration number 91 - loss = 0.5339392423629761\n",
      "this is the iteration number 92 - loss = 0.5490903258323669\n",
      "this is the iteration number 93 - loss = 0.46230289340019226\n",
      "this is the iteration number 94 - loss = 0.5120550990104675\n",
      "this is the iteration number 95 - loss = 0.5676363706588745\n",
      "this is the iteration number 96 - loss = 0.4807216227054596\n",
      "this is the iteration number 97 - loss = 0.5283817052841187\n",
      "this is the iteration number 98 - loss = 0.5359664559364319\n",
      "this is the iteration number 99 - loss = 0.5091825127601624\n",
      "this is the iteration number 100 - loss = 0.4731333553791046\n",
      "this is the iteration number 101 - loss = 0.4740845263004303\n",
      "this is the iteration number 0 - loss = 0.5272586941719055\n",
      "this is the iteration number 1 - loss = 0.5537272095680237\n",
      "this is the iteration number 2 - loss = 0.522810161113739\n",
      "this is the iteration number 3 - loss = 0.5471946597099304\n",
      "this is the iteration number 4 - loss = 0.5737133622169495\n",
      "this is the iteration number 5 - loss = 0.5260070562362671\n",
      "this is the iteration number 6 - loss = 0.5441386699676514\n",
      "this is the iteration number 7 - loss = 0.5949090719223022\n",
      "this is the iteration number 8 - loss = 0.5544306635856628\n",
      "this is the iteration number 9 - loss = 0.49352845549583435\n",
      "this is the iteration number 10 - loss = 0.5436107516288757\n",
      "this is the iteration number 11 - loss = 0.515151858329773\n",
      "this is the iteration number 12 - loss = 0.5003615021705627\n",
      "this is the iteration number 13 - loss = 0.5036336779594421\n",
      "this is the iteration number 14 - loss = 0.48163825273513794\n",
      "this is the iteration number 15 - loss = 0.5379371047019958\n",
      "this is the iteration number 16 - loss = 0.4723961651325226\n",
      "this is the iteration number 17 - loss = 0.5840076804161072\n",
      "this is the iteration number 18 - loss = 0.4768148958683014\n",
      "this is the iteration number 19 - loss = 0.5188158750534058\n",
      "this is the iteration number 20 - loss = 0.5141025185585022\n",
      "this is the iteration number 21 - loss = 0.4966690242290497\n",
      "this is the iteration number 22 - loss = 0.5220775604248047\n",
      "this is the iteration number 23 - loss = 0.5076185464859009\n",
      "this is the iteration number 24 - loss = 0.5554159283638\n",
      "this is the iteration number 25 - loss = 0.563219428062439\n",
      "this is the iteration number 26 - loss = 0.5492752194404602\n",
      "this is the iteration number 27 - loss = 0.48792406916618347\n",
      "this is the iteration number 28 - loss = 0.5030008554458618\n",
      "this is the iteration number 29 - loss = 0.5219417214393616\n",
      "this is the iteration number 30 - loss = 0.47550153732299805\n",
      "this is the iteration number 31 - loss = 0.5047570466995239\n",
      "this is the iteration number 32 - loss = 0.4982045590877533\n",
      "this is the iteration number 33 - loss = 0.5445847511291504\n",
      "this is the iteration number 34 - loss = 0.46499744057655334\n",
      "this is the iteration number 35 - loss = 0.4868044853210449\n",
      "this is the iteration number 36 - loss = 0.5406664609909058\n",
      "this is the iteration number 37 - loss = 0.5235864520072937\n",
      "this is the iteration number 38 - loss = 0.5319746136665344\n",
      "this is the iteration number 39 - loss = 0.4680660665035248\n",
      "this is the iteration number 40 - loss = 0.5954131484031677\n",
      "this is the iteration number 41 - loss = 0.5851116180419922\n",
      "this is the iteration number 42 - loss = 0.4926075041294098\n",
      "this is the iteration number 43 - loss = 0.5245974063873291\n",
      "this is the iteration number 44 - loss = 0.5272204279899597\n",
      "this is the iteration number 45 - loss = 0.5121268033981323\n",
      "this is the iteration number 46 - loss = 0.5311650037765503\n",
      "this is the iteration number 47 - loss = 0.5701618790626526\n",
      "this is the iteration number 48 - loss = 0.5635133981704712\n",
      "this is the iteration number 49 - loss = 0.4945942759513855\n",
      "this is the iteration number 50 - loss = 0.5017195343971252\n",
      "this is the iteration number 51 - loss = 0.5644053816795349\n",
      "this is the iteration number 52 - loss = 0.5923986434936523\n",
      "this is the iteration number 53 - loss = 0.4668659269809723\n",
      "this is the iteration number 54 - loss = 0.5383565425872803\n",
      "this is the iteration number 55 - loss = 0.5915402173995972\n",
      "this is the iteration number 56 - loss = 0.5072382092475891\n",
      "this is the iteration number 57 - loss = 0.49303218722343445\n",
      "this is the iteration number 58 - loss = 0.5454253554344177\n",
      "this is the iteration number 59 - loss = 0.5498923063278198\n",
      "this is the iteration number 60 - loss = 0.4587101340293884\n",
      "this is the iteration number 61 - loss = 0.489994615316391\n",
      "this is the iteration number 62 - loss = 0.4792041778564453\n",
      "this is the iteration number 63 - loss = 0.49053525924682617\n",
      "this is the iteration number 64 - loss = 0.5355363488197327\n",
      "this is the iteration number 65 - loss = 0.4716797173023224\n",
      "this is the iteration number 66 - loss = 0.5417091250419617\n",
      "this is the iteration number 67 - loss = 0.5393795371055603\n",
      "this is the iteration number 68 - loss = 0.5369657874107361\n",
      "this is the iteration number 69 - loss = 0.5285125970840454\n",
      "this is the iteration number 70 - loss = 0.5260722637176514\n",
      "this is the iteration number 71 - loss = 0.5371469259262085\n",
      "this is the iteration number 72 - loss = 0.559687077999115\n",
      "this is the iteration number 73 - loss = 0.5777250528335571\n",
      "this is the iteration number 74 - loss = 0.5063567757606506\n",
      "this is the iteration number 75 - loss = 0.5553126931190491\n",
      "this is the iteration number 76 - loss = 0.5247858762741089\n",
      "this is the iteration number 77 - loss = 0.502873420715332\n",
      "this is the iteration number 78 - loss = 0.5169875025749207\n",
      "this is the iteration number 79 - loss = 0.5229427218437195\n",
      "this is the iteration number 80 - loss = 0.44300708174705505\n",
      "this is the iteration number 81 - loss = 0.49956631660461426\n",
      "this is the iteration number 82 - loss = 0.5587511658668518\n",
      "this is the iteration number 83 - loss = 0.5275509357452393\n",
      "this is the iteration number 84 - loss = 0.5227155685424805\n",
      "this is the iteration number 85 - loss = 0.5270584225654602\n",
      "this is the iteration number 86 - loss = 0.501758873462677\n",
      "this is the iteration number 87 - loss = 0.5412997007369995\n",
      "this is the iteration number 88 - loss = 0.5434605479240417\n",
      "this is the iteration number 89 - loss = 0.5022670030593872\n",
      "this is the iteration number 90 - loss = 0.5154882669448853\n",
      "this is the iteration number 91 - loss = 0.4865110516548157\n",
      "this is the iteration number 92 - loss = 0.5152638554573059\n",
      "this is the iteration number 93 - loss = 0.4954838454723358\n",
      "this is the iteration number 94 - loss = 0.5003609657287598\n",
      "this is the iteration number 95 - loss = 0.5172906517982483\n",
      "this is the iteration number 96 - loss = 0.5231769680976868\n",
      "this is the iteration number 97 - loss = 0.5283275246620178\n",
      "this is the iteration number 98 - loss = 0.5283753275871277\n",
      "this is the iteration number 99 - loss = 0.5464258790016174\n",
      "this is the iteration number 100 - loss = 0.4864085018634796\n",
      "this is the iteration number 101 - loss = 0.44800376892089844\n",
      "this is the iteration number 0 - loss = 0.5339409708976746\n",
      "this is the iteration number 1 - loss = 0.5171587467193604\n",
      "this is the iteration number 2 - loss = 0.5675597786903381\n",
      "this is the iteration number 3 - loss = 0.5303434729576111\n",
      "this is the iteration number 4 - loss = 0.5024308562278748\n",
      "this is the iteration number 5 - loss = 0.5179954171180725\n",
      "this is the iteration number 6 - loss = 0.513078510761261\n",
      "this is the iteration number 7 - loss = 0.6127568483352661\n",
      "this is the iteration number 8 - loss = 0.5513057112693787\n",
      "this is the iteration number 9 - loss = 0.5399604439735413\n",
      "this is the iteration number 10 - loss = 0.5376085638999939\n",
      "this is the iteration number 11 - loss = 0.49310046434402466\n",
      "this is the iteration number 12 - loss = 0.49500182271003723\n",
      "this is the iteration number 13 - loss = 0.5127934217453003\n",
      "this is the iteration number 14 - loss = 0.5177634358406067\n",
      "this is the iteration number 15 - loss = 0.5641413927078247\n",
      "this is the iteration number 16 - loss = 0.5255371332168579\n",
      "this is the iteration number 17 - loss = 0.47198376059532166\n",
      "this is the iteration number 18 - loss = 0.5167313814163208\n",
      "this is the iteration number 19 - loss = 0.5644240975379944\n",
      "this is the iteration number 20 - loss = 0.4944384694099426\n",
      "this is the iteration number 21 - loss = 0.48998790979385376\n",
      "this is the iteration number 22 - loss = 0.4939122796058655\n",
      "this is the iteration number 23 - loss = 0.5502611994743347\n",
      "this is the iteration number 24 - loss = 0.5576856732368469\n",
      "this is the iteration number 25 - loss = 0.4947376251220703\n",
      "this is the iteration number 26 - loss = 0.47080203890800476\n",
      "this is the iteration number 27 - loss = 0.5437853932380676\n",
      "this is the iteration number 28 - loss = 0.5630874037742615\n",
      "this is the iteration number 29 - loss = 0.489401638507843\n",
      "this is the iteration number 30 - loss = 0.5115331411361694\n",
      "this is the iteration number 31 - loss = 0.47787338495254517\n",
      "this is the iteration number 32 - loss = 0.6177192330360413\n",
      "this is the iteration number 33 - loss = 0.5149908065795898\n",
      "this is the iteration number 34 - loss = 0.5319485068321228\n",
      "this is the iteration number 35 - loss = 0.5949039459228516\n",
      "this is the iteration number 36 - loss = 0.449664831161499\n",
      "this is the iteration number 37 - loss = 0.560222864151001\n",
      "this is the iteration number 38 - loss = 0.5099260807037354\n",
      "this is the iteration number 39 - loss = 0.5524920225143433\n",
      "this is the iteration number 40 - loss = 0.4770520329475403\n",
      "this is the iteration number 41 - loss = 0.5246030688285828\n",
      "this is the iteration number 42 - loss = 0.49288228154182434\n",
      "this is the iteration number 43 - loss = 0.48766615986824036\n",
      "this is the iteration number 44 - loss = 0.5064197182655334\n",
      "this is the iteration number 45 - loss = 0.5352869033813477\n",
      "this is the iteration number 46 - loss = 0.4941496253013611\n",
      "this is the iteration number 47 - loss = 0.48716121912002563\n",
      "this is the iteration number 48 - loss = 0.5085550546646118\n",
      "this is the iteration number 49 - loss = 0.5212408900260925\n",
      "this is the iteration number 50 - loss = 0.5464891195297241\n",
      "this is the iteration number 51 - loss = 0.48840585350990295\n",
      "this is the iteration number 52 - loss = 0.5715122222900391\n",
      "this is the iteration number 53 - loss = 0.5236517786979675\n",
      "this is the iteration number 54 - loss = 0.5462276339530945\n",
      "this is the iteration number 55 - loss = 0.5211580395698547\n",
      "this is the iteration number 56 - loss = 0.47199326753616333\n",
      "this is the iteration number 57 - loss = 0.5210229158401489\n",
      "this is the iteration number 58 - loss = 0.4832558333873749\n",
      "this is the iteration number 59 - loss = 0.5236010551452637\n",
      "this is the iteration number 60 - loss = 0.5108866095542908\n",
      "this is the iteration number 61 - loss = 0.4750395119190216\n",
      "this is the iteration number 62 - loss = 0.5323682427406311\n",
      "this is the iteration number 63 - loss = 0.5043281316757202\n",
      "this is the iteration number 64 - loss = 0.5133064389228821\n",
      "this is the iteration number 65 - loss = 0.4606377184391022\n",
      "this is the iteration number 66 - loss = 0.5219249725341797\n",
      "this is the iteration number 67 - loss = 0.5388092994689941\n",
      "this is the iteration number 68 - loss = 0.5110144019126892\n",
      "this is the iteration number 69 - loss = 0.5681551098823547\n",
      "this is the iteration number 70 - loss = 0.5548087358474731\n",
      "this is the iteration number 71 - loss = 0.5464022755622864\n",
      "this is the iteration number 72 - loss = 0.5426563620567322\n",
      "this is the iteration number 73 - loss = 0.5352048277854919\n",
      "this is the iteration number 74 - loss = 0.5461110472679138\n",
      "this is the iteration number 75 - loss = 0.4619769752025604\n",
      "this is the iteration number 76 - loss = 0.5551174283027649\n",
      "this is the iteration number 77 - loss = 0.5387238264083862\n",
      "this is the iteration number 78 - loss = 0.50179523229599\n",
      "this is the iteration number 79 - loss = 0.4634769856929779\n",
      "this is the iteration number 80 - loss = 0.45253175497055054\n",
      "this is the iteration number 81 - loss = 0.5193437337875366\n",
      "this is the iteration number 82 - loss = 0.5223624110221863\n",
      "this is the iteration number 83 - loss = 0.5190567374229431\n",
      "this is the iteration number 84 - loss = 0.492733895778656\n",
      "this is the iteration number 85 - loss = 0.5008000731468201\n",
      "this is the iteration number 86 - loss = 0.5599879622459412\n",
      "this is the iteration number 87 - loss = 0.5210863947868347\n",
      "this is the iteration number 88 - loss = 0.492475301027298\n",
      "this is the iteration number 89 - loss = 0.5552127957344055\n",
      "this is the iteration number 90 - loss = 0.4957078993320465\n",
      "this is the iteration number 91 - loss = 0.571454644203186\n",
      "this is the iteration number 92 - loss = 0.5418740510940552\n",
      "this is the iteration number 93 - loss = 0.4810159206390381\n",
      "this is the iteration number 94 - loss = 0.5010266304016113\n",
      "this is the iteration number 95 - loss = 0.5265797972679138\n",
      "this is the iteration number 96 - loss = 0.515670657157898\n",
      "this is the iteration number 97 - loss = 0.53682941198349\n",
      "this is the iteration number 98 - loss = 0.4943084716796875\n",
      "this is the iteration number 99 - loss = 0.5237911939620972\n",
      "this is the iteration number 100 - loss = 0.443132609128952\n",
      "this is the iteration number 101 - loss = 0.5511093735694885\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(20):\n",
    "    for index, (X,y) in enumerate(train_loader):\n",
    "        \n",
    "        prediction = model(X)\n",
    "\n",
    "        loss = criterion(prediction,y.type(torch.long))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'this is the iteration number {index} - loss = {loss}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.max(prediction,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0]),\n",
       " tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.max(model(X_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098591549295775"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([(v == y_test[i]).numpy() for i,v  in enumerate(indices)])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_test = torch.concat((X_test, y_test.unsqueeze(1)), dim=1)\n",
    "\n",
    "testloader = DataLoader(dataset=tensor_ds(tensor_train), batch_size=math.floor(X_train.shape[0]/100), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in ['no_avc','avc']}\n",
    "total_pred = {classname: 0 for classname in ['no_avc','avc']}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dc_claas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19b3c190b9d69770ce2ddeaf9d52a9dde852f18a5bf9768f2dbe8da33de81e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
