{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_433347/2393603853.py:17: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X = pd.concat([X[['age','hypertension','heart_disease','avg_glucose_level','bmi']],pd.get_dummies(data=X[['gender','work_type','ever_married','smoking_status','Residence_type']])],1)\n",
      "/home/pedro/anaconda3/envs/dc_claas/lib/python3.9/site-packages/imblearn/utils/_validation.py:586: FutureWarning: Pass sampling_strategy=0.5 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Lambda, ToTensor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "dataset = pd.read_csv('/home/pedro/Documentos/Kaggle_DSs/full_data.csv')\n",
    "\n",
    "y = dataset.iloc[:,-1]\n",
    "X = dataset.iloc[:,:-1] \n",
    "from imblearn import under_sampling, over_sampling\n",
    "\n",
    "X = pd.concat([X[['age','hypertension','heart_disease','avg_glucose_level','bmi']],pd.get_dummies(data=X[['gender','work_type','ever_married','smoking_status','Residence_type']])],1)\n",
    "X[['age','avg_glucose_level','bmi']] = RobustScaler().fit_transform(X[['age','avg_glucose_level','bmi']])\n",
    "X, y = over_sampling.SMOTE(0.5).fit_resample(X=X,y=y)\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.values.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.values.astype(np.float32))\n",
    "y_train = torch.from_numpy(np.array(y_train))\n",
    "y_test = torch.from_numpy(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn, optim\n",
    "\n",
    "class tensor_ds(object):\n",
    "    def __init__(self,tensor:torch.Tensor):\n",
    "        self.X = tensor[:,:-1]\n",
    "        self.y = tensor[:,-1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,values):\n",
    "        return self.X[values], self.y[values]\n",
    "\n",
    "tensor_train = torch.concat((X_train, y_train.unsqueeze(1)), dim=1)\n",
    "\n",
    "train_loader = DataLoader(dataset=tensor_ds(tensor_train), batch_size=math.floor(X_train.shape[0]/100), shuffle=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, math.floor(input_size/5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.floor(input_size/5), math.floor(input_size/10)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.floor(input_size/10), output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        logits = nn.Sigmoid()(logits)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(X_train.shape[1],2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the iteration number 0 - loss = 0.718582034111023\n",
      "this is the iteration number 1 - loss = 0.7184553742408752\n",
      "this is the iteration number 2 - loss = 0.7239313721656799\n",
      "this is the iteration number 3 - loss = 0.7264008522033691\n",
      "this is the iteration number 4 - loss = 0.7179931998252869\n",
      "this is the iteration number 5 - loss = 0.7207323908805847\n",
      "this is the iteration number 6 - loss = 0.7178671956062317\n",
      "this is the iteration number 7 - loss = 0.7176427841186523\n",
      "this is the iteration number 8 - loss = 0.7149031758308411\n",
      "this is the iteration number 9 - loss = 0.7118441462516785\n",
      "this is the iteration number 10 - loss = 0.7172747254371643\n",
      "this is the iteration number 11 - loss = 0.717075526714325\n",
      "this is the iteration number 12 - loss = 0.7193430066108704\n",
      "this is the iteration number 13 - loss = 0.7115493416786194\n",
      "this is the iteration number 14 - loss = 0.7298771739006042\n",
      "this is the iteration number 15 - loss = 0.7269917130470276\n",
      "this is the iteration number 16 - loss = 0.7191433310508728\n",
      "this is the iteration number 17 - loss = 0.7211000323295593\n",
      "this is the iteration number 18 - loss = 0.7133684158325195\n",
      "this is the iteration number 19 - loss = 0.7187777757644653\n",
      "this is the iteration number 20 - loss = 0.7154998183250427\n",
      "this is the iteration number 21 - loss = 0.7156199812889099\n",
      "this is the iteration number 22 - loss = 0.7130116820335388\n",
      "this is the iteration number 23 - loss = 0.7054868936538696\n",
      "this is the iteration number 24 - loss = 0.7003490328788757\n",
      "this is the iteration number 25 - loss = 0.7175129652023315\n",
      "this is the iteration number 26 - loss = 0.732570230960846\n",
      "this is the iteration number 27 - loss = 0.7221700549125671\n",
      "this is the iteration number 28 - loss = 0.7219218015670776\n",
      "this is the iteration number 29 - loss = 0.723873496055603\n",
      "this is the iteration number 30 - loss = 0.7239178419113159\n",
      "this is the iteration number 31 - loss = 0.7305307984352112\n",
      "this is the iteration number 32 - loss = 0.7071827054023743\n",
      "this is the iteration number 33 - loss = 0.7092697024345398\n",
      "this is the iteration number 34 - loss = 0.7136354446411133\n",
      "this is the iteration number 35 - loss = 0.711207389831543\n",
      "this is the iteration number 36 - loss = 0.713064968585968\n",
      "this is the iteration number 37 - loss = 0.7113500237464905\n",
      "this is the iteration number 38 - loss = 0.712685763835907\n",
      "this is the iteration number 39 - loss = 0.7149186134338379\n",
      "this is the iteration number 40 - loss = 0.7173441648483276\n",
      "this is the iteration number 41 - loss = 0.7146259546279907\n",
      "this is the iteration number 42 - loss = 0.7122778296470642\n",
      "this is the iteration number 43 - loss = 0.7231334447860718\n",
      "this is the iteration number 44 - loss = 0.7160402536392212\n",
      "this is the iteration number 45 - loss = 0.7166324853897095\n",
      "this is the iteration number 46 - loss = 0.7119871377944946\n",
      "this is the iteration number 47 - loss = 0.7114982604980469\n",
      "this is the iteration number 48 - loss = 0.7215492129325867\n",
      "this is the iteration number 49 - loss = 0.7132652401924133\n",
      "this is the iteration number 50 - loss = 0.7089935541152954\n",
      "this is the iteration number 51 - loss = 0.7188100814819336\n",
      "this is the iteration number 52 - loss = 0.7165802121162415\n",
      "this is the iteration number 53 - loss = 0.6922239065170288\n",
      "this is the iteration number 54 - loss = 0.6996859908103943\n",
      "this is the iteration number 55 - loss = 0.7219585180282593\n",
      "this is the iteration number 56 - loss = 0.7117280960083008\n",
      "this is the iteration number 57 - loss = 0.7095392942428589\n",
      "this is the iteration number 58 - loss = 0.7075985670089722\n",
      "this is the iteration number 59 - loss = 0.7135294675827026\n",
      "this is the iteration number 60 - loss = 0.7074663043022156\n",
      "this is the iteration number 61 - loss = 0.7204662561416626\n",
      "this is the iteration number 62 - loss = 0.7111178636550903\n",
      "this is the iteration number 63 - loss = 0.7098236083984375\n",
      "this is the iteration number 64 - loss = 0.7212062478065491\n",
      "this is the iteration number 65 - loss = 0.7085880041122437\n",
      "this is the iteration number 66 - loss = 0.7150365114212036\n",
      "this is the iteration number 67 - loss = 0.7023472189903259\n",
      "this is the iteration number 68 - loss = 0.7143864631652832\n",
      "this is the iteration number 69 - loss = 0.7086135745048523\n",
      "this is the iteration number 70 - loss = 0.7089009284973145\n",
      "this is the iteration number 71 - loss = 0.7082638144493103\n",
      "this is the iteration number 72 - loss = 0.713010311126709\n",
      "this is the iteration number 73 - loss = 0.7081173658370972\n",
      "this is the iteration number 74 - loss = 0.7023860216140747\n",
      "this is the iteration number 75 - loss = 0.7044252157211304\n",
      "this is the iteration number 76 - loss = 0.7038717865943909\n",
      "this is the iteration number 77 - loss = 0.7129674553871155\n",
      "this is the iteration number 78 - loss = 0.7112542390823364\n",
      "this is the iteration number 79 - loss = 0.7085615396499634\n",
      "this is the iteration number 80 - loss = 0.7072501182556152\n",
      "this is the iteration number 81 - loss = 0.7112069725990295\n",
      "this is the iteration number 82 - loss = 0.7025905251502991\n",
      "this is the iteration number 83 - loss = 0.7105939984321594\n",
      "this is the iteration number 84 - loss = 0.7033360600471497\n",
      "this is the iteration number 85 - loss = 0.7080391049385071\n",
      "this is the iteration number 86 - loss = 0.7043174505233765\n",
      "this is the iteration number 87 - loss = 0.708179771900177\n",
      "this is the iteration number 88 - loss = 0.7119894027709961\n",
      "this is the iteration number 89 - loss = 0.709966242313385\n",
      "this is the iteration number 90 - loss = 0.7022309899330139\n",
      "this is the iteration number 91 - loss = 0.7047163248062134\n",
      "this is the iteration number 92 - loss = 0.7026878595352173\n",
      "this is the iteration number 93 - loss = 0.7072895169258118\n",
      "this is the iteration number 94 - loss = 0.7064474821090698\n",
      "this is the iteration number 95 - loss = 0.7030013203620911\n",
      "this is the iteration number 96 - loss = 0.6977035403251648\n",
      "this is the iteration number 97 - loss = 0.6998805403709412\n",
      "this is the iteration number 98 - loss = 0.6927915215492249\n",
      "this is the iteration number 99 - loss = 0.703002393245697\n",
      "this is the iteration number 100 - loss = 0.7031683325767517\n",
      "this is the iteration number 101 - loss = 0.6990718841552734\n",
      "this is the iteration number 0 - loss = 0.7036284804344177\n",
      "this is the iteration number 1 - loss = 0.6990789175033569\n",
      "this is the iteration number 2 - loss = 0.7022298574447632\n",
      "this is the iteration number 3 - loss = 0.6980356574058533\n",
      "this is the iteration number 4 - loss = 0.7004418969154358\n",
      "this is the iteration number 5 - loss = 0.6939112544059753\n",
      "this is the iteration number 6 - loss = 0.6978803873062134\n",
      "this is the iteration number 7 - loss = 0.6967529058456421\n",
      "this is the iteration number 8 - loss = 0.6957539319992065\n",
      "this is the iteration number 9 - loss = 0.6980591416358948\n",
      "this is the iteration number 10 - loss = 0.6985291838645935\n",
      "this is the iteration number 11 - loss = 0.7020267248153687\n",
      "this is the iteration number 12 - loss = 0.6960095167160034\n",
      "this is the iteration number 13 - loss = 0.6956639885902405\n",
      "this is the iteration number 14 - loss = 0.6933494210243225\n",
      "this is the iteration number 15 - loss = 0.6949313879013062\n",
      "this is the iteration number 16 - loss = 0.696269690990448\n",
      "this is the iteration number 17 - loss = 0.6952961683273315\n",
      "this is the iteration number 18 - loss = 0.6952183842658997\n",
      "this is the iteration number 19 - loss = 0.6926636695861816\n",
      "this is the iteration number 20 - loss = 0.6940957307815552\n",
      "this is the iteration number 21 - loss = 0.6920327544212341\n",
      "this is the iteration number 22 - loss = 0.6918732523918152\n",
      "this is the iteration number 23 - loss = 0.6925299763679504\n",
      "this is the iteration number 24 - loss = 0.6916283369064331\n",
      "this is the iteration number 25 - loss = 0.6912817358970642\n",
      "this is the iteration number 26 - loss = 0.6918342709541321\n",
      "this is the iteration number 27 - loss = 0.6915809512138367\n",
      "this is the iteration number 28 - loss = 0.6933748126029968\n",
      "this is the iteration number 29 - loss = 0.6917601227760315\n",
      "this is the iteration number 30 - loss = 0.6896858215332031\n",
      "this is the iteration number 31 - loss = 0.6895290017127991\n",
      "this is the iteration number 32 - loss = 0.6890234351158142\n",
      "this is the iteration number 33 - loss = 0.6893376708030701\n",
      "this is the iteration number 34 - loss = 0.6884156465530396\n",
      "this is the iteration number 35 - loss = 0.6890565156936646\n",
      "this is the iteration number 36 - loss = 0.6873258948326111\n",
      "this is the iteration number 37 - loss = 0.6885074973106384\n",
      "this is the iteration number 38 - loss = 0.6882184147834778\n",
      "this is the iteration number 39 - loss = 0.6868897676467896\n",
      "this is the iteration number 40 - loss = 0.686164379119873\n",
      "this is the iteration number 41 - loss = 0.6869202256202698\n",
      "this is the iteration number 42 - loss = 0.6855258941650391\n",
      "this is the iteration number 43 - loss = 0.6853974461555481\n",
      "this is the iteration number 44 - loss = 0.6864243745803833\n",
      "this is the iteration number 45 - loss = 0.6848878264427185\n",
      "this is the iteration number 46 - loss = 0.6854059100151062\n",
      "this is the iteration number 47 - loss = 0.6846379637718201\n",
      "this is the iteration number 48 - loss = 0.6874966621398926\n",
      "this is the iteration number 49 - loss = 0.6865044236183167\n",
      "this is the iteration number 50 - loss = 0.6853082776069641\n",
      "this is the iteration number 51 - loss = 0.6869277954101562\n",
      "this is the iteration number 52 - loss = 0.6826906800270081\n",
      "this is the iteration number 53 - loss = 0.6840409636497498\n",
      "this is the iteration number 54 - loss = 0.6851146817207336\n",
      "this is the iteration number 55 - loss = 0.6823001503944397\n",
      "this is the iteration number 56 - loss = 0.6831614375114441\n",
      "this is the iteration number 57 - loss = 0.6830257773399353\n",
      "this is the iteration number 58 - loss = 0.6807492971420288\n",
      "this is the iteration number 59 - loss = 0.6806469559669495\n",
      "this is the iteration number 60 - loss = 0.6824786067008972\n",
      "this is the iteration number 61 - loss = 0.6804908514022827\n",
      "this is the iteration number 62 - loss = 0.682523250579834\n",
      "this is the iteration number 63 - loss = 0.6814252734184265\n",
      "this is the iteration number 64 - loss = 0.6806026697158813\n",
      "this is the iteration number 65 - loss = 0.6865749359130859\n",
      "this is the iteration number 66 - loss = 0.6795541644096375\n",
      "this is the iteration number 67 - loss = 0.6809934973716736\n",
      "this is the iteration number 68 - loss = 0.6782868504524231\n",
      "this is the iteration number 69 - loss = 0.6809397339820862\n",
      "this is the iteration number 70 - loss = 0.6775380373001099\n",
      "this is the iteration number 71 - loss = 0.6793124079704285\n",
      "this is the iteration number 72 - loss = 0.6776262521743774\n",
      "this is the iteration number 73 - loss = 0.6788259744644165\n",
      "this is the iteration number 74 - loss = 0.6812582015991211\n",
      "this is the iteration number 75 - loss = 0.6782602071762085\n",
      "this is the iteration number 76 - loss = 0.67509925365448\n",
      "this is the iteration number 77 - loss = 0.6786131262779236\n",
      "this is the iteration number 78 - loss = 0.6801177859306335\n",
      "this is the iteration number 79 - loss = 0.6772270202636719\n",
      "this is the iteration number 80 - loss = 0.6876441836357117\n",
      "this is the iteration number 81 - loss = 0.6803489327430725\n",
      "this is the iteration number 82 - loss = 0.678117573261261\n",
      "this is the iteration number 83 - loss = 0.6746406555175781\n",
      "this is the iteration number 84 - loss = 0.6740184426307678\n",
      "this is the iteration number 85 - loss = 0.6804335713386536\n",
      "this is the iteration number 86 - loss = 0.6764918565750122\n",
      "this is the iteration number 87 - loss = 0.6743806600570679\n",
      "this is the iteration number 88 - loss = 0.6787261366844177\n",
      "this is the iteration number 89 - loss = 0.6728484034538269\n",
      "this is the iteration number 90 - loss = 0.6770232319831848\n",
      "this is the iteration number 91 - loss = 0.676371157169342\n",
      "this is the iteration number 92 - loss = 0.6787922978401184\n",
      "this is the iteration number 93 - loss = 0.673111081123352\n",
      "this is the iteration number 94 - loss = 0.6739863753318787\n",
      "this is the iteration number 95 - loss = 0.668371319770813\n",
      "this is the iteration number 96 - loss = 0.6779596209526062\n",
      "this is the iteration number 97 - loss = 0.6783459782600403\n",
      "this is the iteration number 98 - loss = 0.676038920879364\n",
      "this is the iteration number 99 - loss = 0.6753444075584412\n",
      "this is the iteration number 100 - loss = 0.6816439628601074\n",
      "this is the iteration number 101 - loss = 0.6773644089698792\n",
      "this is the iteration number 0 - loss = 0.6733897924423218\n",
      "this is the iteration number 1 - loss = 0.6671498417854309\n",
      "this is the iteration number 2 - loss = 0.6676443815231323\n",
      "this is the iteration number 3 - loss = 0.6727274060249329\n",
      "this is the iteration number 4 - loss = 0.6666903495788574\n",
      "this is the iteration number 5 - loss = 0.6809521913528442\n",
      "this is the iteration number 6 - loss = 0.6660093069076538\n",
      "this is the iteration number 7 - loss = 0.6740297675132751\n",
      "this is the iteration number 8 - loss = 0.6791776418685913\n",
      "this is the iteration number 9 - loss = 0.6667082905769348\n",
      "this is the iteration number 10 - loss = 0.6672833561897278\n",
      "this is the iteration number 11 - loss = 0.6716753840446472\n",
      "this is the iteration number 12 - loss = 0.6799169778823853\n",
      "this is the iteration number 13 - loss = 0.6661500334739685\n",
      "this is the iteration number 14 - loss = 0.6692395210266113\n",
      "this is the iteration number 15 - loss = 0.6638370752334595\n",
      "this is the iteration number 16 - loss = 0.6702095866203308\n",
      "this is the iteration number 17 - loss = 0.6640694737434387\n",
      "this is the iteration number 18 - loss = 0.6763362288475037\n",
      "this is the iteration number 19 - loss = 0.6754344701766968\n",
      "this is the iteration number 20 - loss = 0.6676051020622253\n",
      "this is the iteration number 21 - loss = 0.6650168299674988\n",
      "this is the iteration number 22 - loss = 0.6741912961006165\n",
      "this is the iteration number 23 - loss = 0.6761507391929626\n",
      "this is the iteration number 24 - loss = 0.6721770167350769\n",
      "this is the iteration number 25 - loss = 0.6787862777709961\n",
      "this is the iteration number 26 - loss = 0.6704162955284119\n",
      "this is the iteration number 27 - loss = 0.6619533896446228\n",
      "this is the iteration number 28 - loss = 0.6644071936607361\n",
      "this is the iteration number 29 - loss = 0.6774204969406128\n",
      "this is the iteration number 30 - loss = 0.6688152551651001\n",
      "this is the iteration number 31 - loss = 0.6679962873458862\n",
      "this is the iteration number 32 - loss = 0.6709778904914856\n",
      "this is the iteration number 33 - loss = 0.6664068102836609\n",
      "this is the iteration number 34 - loss = 0.6777125597000122\n",
      "this is the iteration number 35 - loss = 0.6732354760169983\n",
      "this is the iteration number 36 - loss = 0.6822722554206848\n",
      "this is the iteration number 37 - loss = 0.668714165687561\n",
      "this is the iteration number 38 - loss = 0.6798936724662781\n",
      "this is the iteration number 39 - loss = 0.6684255599975586\n",
      "this is the iteration number 40 - loss = 0.6557396054267883\n",
      "this is the iteration number 41 - loss = 0.6698680520057678\n",
      "this is the iteration number 42 - loss = 0.6817641854286194\n",
      "this is the iteration number 43 - loss = 0.660476803779602\n",
      "this is the iteration number 44 - loss = 0.6618487238883972\n",
      "this is the iteration number 45 - loss = 0.6661780476570129\n",
      "this is the iteration number 46 - loss = 0.6675611734390259\n",
      "this is the iteration number 47 - loss = 0.6580342650413513\n",
      "this is the iteration number 48 - loss = 0.668400764465332\n",
      "this is the iteration number 49 - loss = 0.6658344268798828\n",
      "this is the iteration number 50 - loss = 0.6501980423927307\n",
      "this is the iteration number 51 - loss = 0.6577118635177612\n",
      "this is the iteration number 52 - loss = 0.6609598398208618\n",
      "this is the iteration number 53 - loss = 0.6661900281906128\n",
      "this is the iteration number 54 - loss = 0.6575366258621216\n",
      "this is the iteration number 55 - loss = 0.6648793816566467\n",
      "this is the iteration number 56 - loss = 0.6571865081787109\n",
      "this is the iteration number 57 - loss = 0.6658077239990234\n",
      "this is the iteration number 58 - loss = 0.6566816568374634\n",
      "this is the iteration number 59 - loss = 0.6626322865486145\n",
      "this is the iteration number 60 - loss = 0.6595486402511597\n",
      "this is the iteration number 61 - loss = 0.6626645922660828\n",
      "this is the iteration number 62 - loss = 0.6578996777534485\n",
      "this is the iteration number 63 - loss = 0.6593738198280334\n",
      "this is the iteration number 64 - loss = 0.6654400825500488\n",
      "this is the iteration number 65 - loss = 0.6573247909545898\n",
      "this is the iteration number 66 - loss = 0.669610321521759\n",
      "this is the iteration number 67 - loss = 0.668103039264679\n",
      "this is the iteration number 68 - loss = 0.6629390716552734\n",
      "this is the iteration number 69 - loss = 0.6662586331367493\n",
      "this is the iteration number 70 - loss = 0.6674751043319702\n",
      "this is the iteration number 71 - loss = 0.6764888763427734\n",
      "this is the iteration number 72 - loss = 0.6622186303138733\n",
      "this is the iteration number 73 - loss = 0.6651427149772644\n",
      "this is the iteration number 74 - loss = 0.6478625535964966\n",
      "this is the iteration number 75 - loss = 0.659467339515686\n",
      "this is the iteration number 76 - loss = 0.6695788502693176\n",
      "this is the iteration number 77 - loss = 0.6720848679542542\n",
      "this is the iteration number 78 - loss = 0.6573219895362854\n",
      "this is the iteration number 79 - loss = 0.6643458008766174\n",
      "this is the iteration number 80 - loss = 0.6736775636672974\n",
      "this is the iteration number 81 - loss = 0.6721282005310059\n",
      "this is the iteration number 82 - loss = 0.6676670908927917\n",
      "this is the iteration number 83 - loss = 0.656914234161377\n",
      "this is the iteration number 84 - loss = 0.6584110856056213\n",
      "this is the iteration number 85 - loss = 0.668051540851593\n",
      "this is the iteration number 86 - loss = 0.6751298904418945\n",
      "this is the iteration number 87 - loss = 0.6776178479194641\n",
      "this is the iteration number 88 - loss = 0.6597131490707397\n",
      "this is the iteration number 89 - loss = 0.6601032614707947\n",
      "this is the iteration number 90 - loss = 0.6512203216552734\n",
      "this is the iteration number 91 - loss = 0.6659408807754517\n",
      "this is the iteration number 92 - loss = 0.6580856442451477\n",
      "this is the iteration number 93 - loss = 0.6628212928771973\n",
      "this is the iteration number 94 - loss = 0.6580700278282166\n",
      "this is the iteration number 95 - loss = 0.6539149284362793\n",
      "this is the iteration number 96 - loss = 0.6528171896934509\n",
      "this is the iteration number 97 - loss = 0.6672343015670776\n",
      "this is the iteration number 98 - loss = 0.6690073013305664\n",
      "this is the iteration number 99 - loss = 0.6652826070785522\n",
      "this is the iteration number 100 - loss = 0.6665455102920532\n",
      "this is the iteration number 101 - loss = 0.654581606388092\n",
      "this is the iteration number 0 - loss = 0.6429692506790161\n",
      "this is the iteration number 1 - loss = 0.6553483009338379\n",
      "this is the iteration number 2 - loss = 0.6548461318016052\n",
      "this is the iteration number 3 - loss = 0.6688138246536255\n",
      "this is the iteration number 4 - loss = 0.6562567353248596\n",
      "this is the iteration number 5 - loss = 0.6582566499710083\n",
      "this is the iteration number 6 - loss = 0.6460201144218445\n",
      "this is the iteration number 7 - loss = 0.6625561714172363\n",
      "this is the iteration number 8 - loss = 0.6645444631576538\n",
      "this is the iteration number 9 - loss = 0.6607791781425476\n",
      "this is the iteration number 10 - loss = 0.6447616815567017\n",
      "this is the iteration number 11 - loss = 0.658150851726532\n",
      "this is the iteration number 12 - loss = 0.6569738388061523\n",
      "this is the iteration number 13 - loss = 0.6514387130737305\n",
      "this is the iteration number 14 - loss = 0.6516500115394592\n",
      "this is the iteration number 15 - loss = 0.6288400292396545\n",
      "this is the iteration number 16 - loss = 0.6546759009361267\n",
      "this is the iteration number 17 - loss = 0.6635650396347046\n",
      "this is the iteration number 18 - loss = 0.6676263809204102\n",
      "this is the iteration number 19 - loss = 0.6762228608131409\n",
      "this is the iteration number 20 - loss = 0.6542477607727051\n",
      "this is the iteration number 21 - loss = 0.6554622054100037\n",
      "this is the iteration number 22 - loss = 0.6555781364440918\n",
      "this is the iteration number 23 - loss = 0.6687813401222229\n",
      "this is the iteration number 24 - loss = 0.6443174481391907\n",
      "this is the iteration number 25 - loss = 0.6255987882614136\n",
      "this is the iteration number 26 - loss = 0.6811476945877075\n",
      "this is the iteration number 27 - loss = 0.675558865070343\n",
      "this is the iteration number 28 - loss = 0.6515783071517944\n",
      "this is the iteration number 29 - loss = 0.6484848260879517\n",
      "this is the iteration number 30 - loss = 0.6460851430892944\n",
      "this is the iteration number 31 - loss = 0.6505150198936462\n",
      "this is the iteration number 32 - loss = 0.6407909989356995\n",
      "this is the iteration number 33 - loss = 0.6592720150947571\n",
      "this is the iteration number 34 - loss = 0.6419663429260254\n",
      "this is the iteration number 35 - loss = 0.6371310353279114\n",
      "this is the iteration number 36 - loss = 0.6484407186508179\n",
      "this is the iteration number 37 - loss = 0.6515824198722839\n",
      "this is the iteration number 38 - loss = 0.6316354870796204\n",
      "this is the iteration number 39 - loss = 0.6380871534347534\n",
      "this is the iteration number 40 - loss = 0.651140570640564\n",
      "this is the iteration number 41 - loss = 0.6317632794380188\n",
      "this is the iteration number 42 - loss = 0.6343296766281128\n",
      "this is the iteration number 43 - loss = 0.6571512222290039\n",
      "this is the iteration number 44 - loss = 0.6491602063179016\n",
      "this is the iteration number 45 - loss = 0.6523460149765015\n",
      "this is the iteration number 46 - loss = 0.641936182975769\n",
      "this is the iteration number 47 - loss = 0.638959527015686\n",
      "this is the iteration number 48 - loss = 0.6537483930587769\n",
      "this is the iteration number 49 - loss = 0.6637459993362427\n",
      "this is the iteration number 50 - loss = 0.6446889638900757\n",
      "this is the iteration number 51 - loss = 0.6407793760299683\n",
      "this is the iteration number 52 - loss = 0.6523181796073914\n",
      "this is the iteration number 53 - loss = 0.642037570476532\n",
      "this is the iteration number 54 - loss = 0.6707757115364075\n",
      "this is the iteration number 55 - loss = 0.6655939221382141\n",
      "this is the iteration number 56 - loss = 0.6472162008285522\n",
      "this is the iteration number 57 - loss = 0.6361865401268005\n",
      "this is the iteration number 58 - loss = 0.6434201598167419\n",
      "this is the iteration number 59 - loss = 0.6453153491020203\n",
      "this is the iteration number 60 - loss = 0.6579698324203491\n",
      "this is the iteration number 61 - loss = 0.6604191064834595\n",
      "this is the iteration number 62 - loss = 0.6583321690559387\n",
      "this is the iteration number 63 - loss = 0.6529350280761719\n",
      "this is the iteration number 64 - loss = 0.6378482580184937\n",
      "this is the iteration number 65 - loss = 0.6372902989387512\n",
      "this is the iteration number 66 - loss = 0.6517166495323181\n",
      "this is the iteration number 67 - loss = 0.6391250491142273\n",
      "this is the iteration number 68 - loss = 0.6712430715560913\n",
      "this is the iteration number 69 - loss = 0.6394815444946289\n",
      "this is the iteration number 70 - loss = 0.6429333686828613\n",
      "this is the iteration number 71 - loss = 0.6385776400566101\n",
      "this is the iteration number 72 - loss = 0.6586712002754211\n",
      "this is the iteration number 73 - loss = 0.656909167766571\n",
      "this is the iteration number 74 - loss = 0.6258483529090881\n",
      "this is the iteration number 75 - loss = 0.6426267027854919\n",
      "this is the iteration number 76 - loss = 0.6581464409828186\n",
      "this is the iteration number 77 - loss = 0.6476908326148987\n",
      "this is the iteration number 78 - loss = 0.6445671916007996\n",
      "this is the iteration number 79 - loss = 0.661694347858429\n",
      "this is the iteration number 80 - loss = 0.6379317045211792\n",
      "this is the iteration number 81 - loss = 0.638332724571228\n",
      "this is the iteration number 82 - loss = 0.646312415599823\n",
      "this is the iteration number 83 - loss = 0.635472297668457\n",
      "this is the iteration number 84 - loss = 0.6534009575843811\n",
      "this is the iteration number 85 - loss = 0.6760925650596619\n",
      "this is the iteration number 86 - loss = 0.6429171562194824\n",
      "this is the iteration number 87 - loss = 0.6214237213134766\n",
      "this is the iteration number 88 - loss = 0.6295790672302246\n",
      "this is the iteration number 89 - loss = 0.6571272611618042\n",
      "this is the iteration number 90 - loss = 0.632782518863678\n",
      "this is the iteration number 91 - loss = 0.652410626411438\n",
      "this is the iteration number 92 - loss = 0.6677462458610535\n",
      "this is the iteration number 93 - loss = 0.6589683294296265\n",
      "this is the iteration number 94 - loss = 0.6623822450637817\n",
      "this is the iteration number 95 - loss = 0.644439160823822\n",
      "this is the iteration number 96 - loss = 0.6323601603507996\n",
      "this is the iteration number 97 - loss = 0.6355970501899719\n",
      "this is the iteration number 98 - loss = 0.643956184387207\n",
      "this is the iteration number 99 - loss = 0.6273819804191589\n",
      "this is the iteration number 100 - loss = 0.6389249563217163\n",
      "this is the iteration number 101 - loss = 0.6365455389022827\n",
      "this is the iteration number 0 - loss = 0.6087154150009155\n",
      "this is the iteration number 1 - loss = 0.6518877744674683\n",
      "this is the iteration number 2 - loss = 0.6458075642585754\n",
      "this is the iteration number 3 - loss = 0.6347503066062927\n",
      "this is the iteration number 4 - loss = 0.6492499709129333\n",
      "this is the iteration number 5 - loss = 0.6796261072158813\n",
      "this is the iteration number 6 - loss = 0.6546191573143005\n",
      "this is the iteration number 7 - loss = 0.6328587532043457\n",
      "this is the iteration number 8 - loss = 0.6218723654747009\n",
      "this is the iteration number 9 - loss = 0.6235648989677429\n",
      "this is the iteration number 10 - loss = 0.635986328125\n",
      "this is the iteration number 11 - loss = 0.634323000907898\n",
      "this is the iteration number 12 - loss = 0.6265329718589783\n",
      "this is the iteration number 13 - loss = 0.6559423804283142\n",
      "this is the iteration number 14 - loss = 0.6481840014457703\n",
      "this is the iteration number 15 - loss = 0.6348248720169067\n",
      "this is the iteration number 16 - loss = 0.6161895990371704\n",
      "this is the iteration number 17 - loss = 0.6198068857192993\n",
      "this is the iteration number 18 - loss = 0.6271981000900269\n",
      "this is the iteration number 19 - loss = 0.6303706169128418\n",
      "this is the iteration number 20 - loss = 0.6390278935432434\n",
      "this is the iteration number 21 - loss = 0.6169147491455078\n",
      "this is the iteration number 22 - loss = 0.6446479558944702\n",
      "this is the iteration number 23 - loss = 0.6261078119277954\n",
      "this is the iteration number 24 - loss = 0.6706841588020325\n",
      "this is the iteration number 25 - loss = 0.632149875164032\n",
      "this is the iteration number 26 - loss = 0.6221471428871155\n",
      "this is the iteration number 27 - loss = 0.6207802891731262\n",
      "this is the iteration number 28 - loss = 0.6413808465003967\n",
      "this is the iteration number 29 - loss = 0.633316159248352\n",
      "this is the iteration number 30 - loss = 0.6478115320205688\n",
      "this is the iteration number 31 - loss = 0.6279438734054565\n",
      "this is the iteration number 32 - loss = 0.6446351408958435\n",
      "this is the iteration number 33 - loss = 0.6262100338935852\n",
      "this is the iteration number 34 - loss = 0.6379922032356262\n",
      "this is the iteration number 35 - loss = 0.6399189233779907\n",
      "this is the iteration number 36 - loss = 0.6199910044670105\n",
      "this is the iteration number 37 - loss = 0.6110095381736755\n",
      "this is the iteration number 38 - loss = 0.6537327766418457\n",
      "this is the iteration number 39 - loss = 0.639519214630127\n",
      "this is the iteration number 40 - loss = 0.6108085513114929\n",
      "this is the iteration number 41 - loss = 0.6379766464233398\n",
      "this is the iteration number 42 - loss = 0.6635018587112427\n",
      "this is the iteration number 43 - loss = 0.6050944924354553\n",
      "this is the iteration number 44 - loss = 0.6257840991020203\n",
      "this is the iteration number 45 - loss = 0.6031054854393005\n",
      "this is the iteration number 46 - loss = 0.6313058733940125\n",
      "this is the iteration number 47 - loss = 0.6192973256111145\n",
      "this is the iteration number 48 - loss = 0.6222832798957825\n",
      "this is the iteration number 49 - loss = 0.6396335959434509\n",
      "this is the iteration number 50 - loss = 0.603333592414856\n",
      "this is the iteration number 51 - loss = 0.6293107867240906\n",
      "this is the iteration number 52 - loss = 0.5915228128433228\n",
      "this is the iteration number 53 - loss = 0.6321936249732971\n",
      "this is the iteration number 54 - loss = 0.6116518378257751\n",
      "this is the iteration number 55 - loss = 0.6295303106307983\n",
      "this is the iteration number 56 - loss = 0.6717665791511536\n",
      "this is the iteration number 57 - loss = 0.6290939450263977\n",
      "this is the iteration number 58 - loss = 0.642004132270813\n",
      "this is the iteration number 59 - loss = 0.6325731873512268\n",
      "this is the iteration number 60 - loss = 0.6179468035697937\n",
      "this is the iteration number 61 - loss = 0.6268558502197266\n",
      "this is the iteration number 62 - loss = 0.6554674506187439\n",
      "this is the iteration number 63 - loss = 0.637450098991394\n",
      "this is the iteration number 64 - loss = 0.6087889075279236\n",
      "this is the iteration number 65 - loss = 0.6059397459030151\n",
      "this is the iteration number 66 - loss = 0.6188933253288269\n",
      "this is the iteration number 67 - loss = 0.622241199016571\n",
      "this is the iteration number 68 - loss = 0.600525438785553\n",
      "this is the iteration number 69 - loss = 0.6104027628898621\n",
      "this is the iteration number 70 - loss = 0.64191073179245\n",
      "this is the iteration number 71 - loss = 0.6237682700157166\n",
      "this is the iteration number 72 - loss = 0.6312946081161499\n",
      "this is the iteration number 73 - loss = 0.6203543543815613\n",
      "this is the iteration number 74 - loss = 0.5973609089851379\n",
      "this is the iteration number 75 - loss = 0.6266172528266907\n",
      "this is the iteration number 76 - loss = 0.6373540759086609\n",
      "this is the iteration number 77 - loss = 0.6225530505180359\n",
      "this is the iteration number 78 - loss = 0.6353154182434082\n",
      "this is the iteration number 79 - loss = 0.633993923664093\n",
      "this is the iteration number 80 - loss = 0.6517616510391235\n",
      "this is the iteration number 81 - loss = 0.6211680769920349\n",
      "this is the iteration number 82 - loss = 0.625867486000061\n",
      "this is the iteration number 83 - loss = 0.6312915086746216\n",
      "this is the iteration number 84 - loss = 0.6221362352371216\n",
      "this is the iteration number 85 - loss = 0.6156801581382751\n",
      "this is the iteration number 86 - loss = 0.6412873864173889\n",
      "this is the iteration number 87 - loss = 0.6394844651222229\n",
      "this is the iteration number 88 - loss = 0.6045727729797363\n",
      "this is the iteration number 89 - loss = 0.6103727221488953\n",
      "this is the iteration number 90 - loss = 0.6258568167686462\n",
      "this is the iteration number 91 - loss = 0.5966244339942932\n",
      "this is the iteration number 92 - loss = 0.6207833290100098\n",
      "this is the iteration number 93 - loss = 0.6225860714912415\n",
      "this is the iteration number 94 - loss = 0.5925664901733398\n",
      "this is the iteration number 95 - loss = 0.6125186085700989\n",
      "this is the iteration number 96 - loss = 0.632929801940918\n",
      "this is the iteration number 97 - loss = 0.626238226890564\n",
      "this is the iteration number 98 - loss = 0.5949353575706482\n",
      "this is the iteration number 99 - loss = 0.6116655468940735\n",
      "this is the iteration number 100 - loss = 0.6460323333740234\n",
      "this is the iteration number 101 - loss = 0.6156572699546814\n",
      "this is the iteration number 0 - loss = 0.6187447309494019\n",
      "this is the iteration number 1 - loss = 0.6655658483505249\n",
      "this is the iteration number 2 - loss = 0.5857673287391663\n",
      "this is the iteration number 3 - loss = 0.6322559714317322\n",
      "this is the iteration number 4 - loss = 0.6003720164299011\n",
      "this is the iteration number 5 - loss = 0.6347413659095764\n",
      "this is the iteration number 6 - loss = 0.6251950860023499\n",
      "this is the iteration number 7 - loss = 0.5682867765426636\n",
      "this is the iteration number 8 - loss = 0.6295698285102844\n",
      "this is the iteration number 9 - loss = 0.6270159482955933\n",
      "this is the iteration number 10 - loss = 0.6250702142715454\n",
      "this is the iteration number 11 - loss = 0.601377010345459\n",
      "this is the iteration number 12 - loss = 0.5876498222351074\n",
      "this is the iteration number 13 - loss = 0.6550210118293762\n",
      "this is the iteration number 14 - loss = 0.6157199144363403\n",
      "this is the iteration number 15 - loss = 0.6077345013618469\n",
      "this is the iteration number 16 - loss = 0.619172990322113\n",
      "this is the iteration number 17 - loss = 0.6067677736282349\n",
      "this is the iteration number 18 - loss = 0.6050702929496765\n",
      "this is the iteration number 19 - loss = 0.6084179282188416\n",
      "this is the iteration number 20 - loss = 0.6068742871284485\n",
      "this is the iteration number 21 - loss = 0.5753989219665527\n",
      "this is the iteration number 22 - loss = 0.589479386806488\n",
      "this is the iteration number 23 - loss = 0.6519754528999329\n",
      "this is the iteration number 24 - loss = 0.5748959183692932\n",
      "this is the iteration number 25 - loss = 0.6172652244567871\n",
      "this is the iteration number 26 - loss = 0.6130936741828918\n",
      "this is the iteration number 27 - loss = 0.6079702973365784\n",
      "this is the iteration number 28 - loss = 0.6342881321907043\n",
      "this is the iteration number 29 - loss = 0.6243596076965332\n",
      "this is the iteration number 30 - loss = 0.572537362575531\n",
      "this is the iteration number 31 - loss = 0.5844046473503113\n",
      "this is the iteration number 32 - loss = 0.591582715511322\n",
      "this is the iteration number 33 - loss = 0.6091293692588806\n",
      "this is the iteration number 34 - loss = 0.6094687581062317\n",
      "this is the iteration number 35 - loss = 0.544852614402771\n",
      "this is the iteration number 36 - loss = 0.5927401185035706\n",
      "this is the iteration number 37 - loss = 0.6076536774635315\n",
      "this is the iteration number 38 - loss = 0.6160582304000854\n",
      "this is the iteration number 39 - loss = 0.6308824419975281\n",
      "this is the iteration number 40 - loss = 0.5795753598213196\n",
      "this is the iteration number 41 - loss = 0.577606201171875\n",
      "this is the iteration number 42 - loss = 0.5775150656700134\n",
      "this is the iteration number 43 - loss = 0.6090573072433472\n",
      "this is the iteration number 44 - loss = 0.6256937384605408\n",
      "this is the iteration number 45 - loss = 0.6065917015075684\n",
      "this is the iteration number 46 - loss = 0.6084027886390686\n",
      "this is the iteration number 47 - loss = 0.609071671962738\n",
      "this is the iteration number 48 - loss = 0.6301344037055969\n",
      "this is the iteration number 49 - loss = 0.6105022430419922\n",
      "this is the iteration number 50 - loss = 0.5742641091346741\n",
      "this is the iteration number 51 - loss = 0.5826534032821655\n",
      "this is the iteration number 52 - loss = 0.623227059841156\n",
      "this is the iteration number 53 - loss = 0.5990832448005676\n",
      "this is the iteration number 54 - loss = 0.626125693321228\n",
      "this is the iteration number 55 - loss = 0.5890026092529297\n",
      "this is the iteration number 56 - loss = 0.6147628426551819\n",
      "this is the iteration number 57 - loss = 0.5899289846420288\n",
      "this is the iteration number 58 - loss = 0.6217461824417114\n",
      "this is the iteration number 59 - loss = 0.5863043069839478\n",
      "this is the iteration number 60 - loss = 0.584993839263916\n",
      "this is the iteration number 61 - loss = 0.58782559633255\n",
      "this is the iteration number 62 - loss = 0.6203345060348511\n",
      "this is the iteration number 63 - loss = 0.6312283277511597\n",
      "this is the iteration number 64 - loss = 0.6008000373840332\n",
      "this is the iteration number 65 - loss = 0.6188866496086121\n",
      "this is the iteration number 66 - loss = 0.638795793056488\n",
      "this is the iteration number 67 - loss = 0.6136976480484009\n",
      "this is the iteration number 68 - loss = 0.5965991020202637\n",
      "this is the iteration number 69 - loss = 0.5839117765426636\n",
      "this is the iteration number 70 - loss = 0.5745042562484741\n",
      "this is the iteration number 71 - loss = 0.5766979455947876\n",
      "this is the iteration number 72 - loss = 0.5902073979377747\n",
      "this is the iteration number 73 - loss = 0.5964863896369934\n",
      "this is the iteration number 74 - loss = 0.6105478405952454\n",
      "this is the iteration number 75 - loss = 0.5980159044265747\n",
      "this is the iteration number 76 - loss = 0.5715702176094055\n",
      "this is the iteration number 77 - loss = 0.5795199275016785\n",
      "this is the iteration number 78 - loss = 0.6207289695739746\n",
      "this is the iteration number 79 - loss = 0.5852598547935486\n",
      "this is the iteration number 80 - loss = 0.5954937934875488\n",
      "this is the iteration number 81 - loss = 0.6161900162696838\n",
      "this is the iteration number 82 - loss = 0.612625241279602\n",
      "this is the iteration number 83 - loss = 0.5424212217330933\n",
      "this is the iteration number 84 - loss = 0.597920835018158\n",
      "this is the iteration number 85 - loss = 0.5688942074775696\n",
      "this is the iteration number 86 - loss = 0.5887037515640259\n",
      "this is the iteration number 87 - loss = 0.5386908650398254\n",
      "this is the iteration number 88 - loss = 0.5976447463035583\n",
      "this is the iteration number 89 - loss = 0.580467164516449\n",
      "this is the iteration number 90 - loss = 0.6315627694129944\n",
      "this is the iteration number 91 - loss = 0.575061023235321\n",
      "this is the iteration number 92 - loss = 0.5565674304962158\n",
      "this is the iteration number 93 - loss = 0.5807617902755737\n",
      "this is the iteration number 94 - loss = 0.5700085163116455\n",
      "this is the iteration number 95 - loss = 0.569239616394043\n",
      "this is the iteration number 96 - loss = 0.5354331731796265\n",
      "this is the iteration number 97 - loss = 0.605575442314148\n",
      "this is the iteration number 98 - loss = 0.6128417253494263\n",
      "this is the iteration number 99 - loss = 0.5812246203422546\n",
      "this is the iteration number 100 - loss = 0.6100074648857117\n",
      "this is the iteration number 101 - loss = 0.5377233624458313\n",
      "this is the iteration number 0 - loss = 0.5777153968811035\n",
      "this is the iteration number 1 - loss = 0.5939746499061584\n",
      "this is the iteration number 2 - loss = 0.531993567943573\n",
      "this is the iteration number 3 - loss = 0.578377366065979\n",
      "this is the iteration number 4 - loss = 0.5547221302986145\n",
      "this is the iteration number 5 - loss = 0.5975375175476074\n",
      "this is the iteration number 6 - loss = 0.536380410194397\n",
      "this is the iteration number 7 - loss = 0.5949656367301941\n",
      "this is the iteration number 8 - loss = 0.5881572365760803\n",
      "this is the iteration number 9 - loss = 0.5969109535217285\n",
      "this is the iteration number 10 - loss = 0.5965166687965393\n",
      "this is the iteration number 11 - loss = 0.59564608335495\n",
      "this is the iteration number 12 - loss = 0.5794662237167358\n",
      "this is the iteration number 13 - loss = 0.5915066003799438\n",
      "this is the iteration number 14 - loss = 0.6087793707847595\n",
      "this is the iteration number 15 - loss = 0.6142082214355469\n",
      "this is the iteration number 16 - loss = 0.5547651052474976\n",
      "this is the iteration number 17 - loss = 0.5527219772338867\n",
      "this is the iteration number 18 - loss = 0.639340341091156\n",
      "this is the iteration number 19 - loss = 0.5927874445915222\n",
      "this is the iteration number 20 - loss = 0.5366977453231812\n",
      "this is the iteration number 21 - loss = 0.5420800447463989\n",
      "this is the iteration number 22 - loss = 0.5769059062004089\n",
      "this is the iteration number 23 - loss = 0.5632547736167908\n",
      "this is the iteration number 24 - loss = 0.579463541507721\n",
      "this is the iteration number 25 - loss = 0.5658701658248901\n",
      "this is the iteration number 26 - loss = 0.5670025944709778\n",
      "this is the iteration number 27 - loss = 0.5568593740463257\n",
      "this is the iteration number 28 - loss = 0.5667586326599121\n",
      "this is the iteration number 29 - loss = 0.5405577421188354\n",
      "this is the iteration number 30 - loss = 0.581965446472168\n",
      "this is the iteration number 31 - loss = 0.579747200012207\n",
      "this is the iteration number 32 - loss = 0.5696517825126648\n",
      "this is the iteration number 33 - loss = 0.5787460207939148\n",
      "this is the iteration number 34 - loss = 0.5906333923339844\n",
      "this is the iteration number 35 - loss = 0.5420829057693481\n",
      "this is the iteration number 36 - loss = 0.6107578277587891\n",
      "this is the iteration number 37 - loss = 0.586391031742096\n",
      "this is the iteration number 38 - loss = 0.5930576324462891\n",
      "this is the iteration number 39 - loss = 0.5806303024291992\n",
      "this is the iteration number 40 - loss = 0.608711302280426\n",
      "this is the iteration number 41 - loss = 0.541007936000824\n",
      "this is the iteration number 42 - loss = 0.5899327993392944\n",
      "this is the iteration number 43 - loss = 0.5352610945701599\n",
      "this is the iteration number 44 - loss = 0.5567349791526794\n",
      "this is the iteration number 45 - loss = 0.582080066204071\n",
      "this is the iteration number 46 - loss = 0.5498352646827698\n",
      "this is the iteration number 47 - loss = 0.560031533241272\n",
      "this is the iteration number 48 - loss = 0.5580011010169983\n",
      "this is the iteration number 49 - loss = 0.578192412853241\n",
      "this is the iteration number 50 - loss = 0.6076547503471375\n",
      "this is the iteration number 51 - loss = 0.6040789484977722\n",
      "this is the iteration number 52 - loss = 0.5807139277458191\n",
      "this is the iteration number 53 - loss = 0.5506225824356079\n",
      "this is the iteration number 54 - loss = 0.5768464207649231\n",
      "this is the iteration number 55 - loss = 0.556069552898407\n",
      "this is the iteration number 56 - loss = 0.5811360478401184\n",
      "this is the iteration number 57 - loss = 0.5609624981880188\n",
      "this is the iteration number 58 - loss = 0.5804553031921387\n",
      "this is the iteration number 59 - loss = 0.5288246273994446\n",
      "this is the iteration number 60 - loss = 0.5532354116439819\n",
      "this is the iteration number 61 - loss = 0.5743576884269714\n",
      "this is the iteration number 62 - loss = 0.544915497303009\n",
      "this is the iteration number 63 - loss = 0.5992356538772583\n",
      "this is the iteration number 64 - loss = 0.5681706070899963\n",
      "this is the iteration number 65 - loss = 0.5580946207046509\n",
      "this is the iteration number 66 - loss = 0.5317347645759583\n",
      "this is the iteration number 67 - loss = 0.6251460909843445\n",
      "this is the iteration number 68 - loss = 0.554146945476532\n",
      "this is the iteration number 69 - loss = 0.6130722165107727\n",
      "this is the iteration number 70 - loss = 0.5216118693351746\n",
      "this is the iteration number 71 - loss = 0.5719806551933289\n",
      "this is the iteration number 72 - loss = 0.5707482695579529\n",
      "this is the iteration number 73 - loss = 0.5752063393592834\n",
      "this is the iteration number 74 - loss = 0.5704681277275085\n",
      "this is the iteration number 75 - loss = 0.5672979354858398\n",
      "this is the iteration number 76 - loss = 0.5750795006752014\n",
      "this is the iteration number 77 - loss = 0.5821327567100525\n",
      "this is the iteration number 78 - loss = 0.5490933060646057\n",
      "this is the iteration number 79 - loss = 0.6000991463661194\n",
      "this is the iteration number 80 - loss = 0.5542882680892944\n",
      "this is the iteration number 81 - loss = 0.5557063817977905\n",
      "this is the iteration number 82 - loss = 0.5706347227096558\n",
      "this is the iteration number 83 - loss = 0.5982075929641724\n",
      "this is the iteration number 84 - loss = 0.5568477511405945\n",
      "this is the iteration number 85 - loss = 0.5519732236862183\n",
      "this is the iteration number 86 - loss = 0.5955296158790588\n",
      "this is the iteration number 87 - loss = 0.559328556060791\n",
      "this is the iteration number 88 - loss = 0.5100908279418945\n",
      "this is the iteration number 89 - loss = 0.6406711339950562\n",
      "this is the iteration number 90 - loss = 0.5809637308120728\n",
      "this is the iteration number 91 - loss = 0.5034648776054382\n",
      "this is the iteration number 92 - loss = 0.5638376474380493\n",
      "this is the iteration number 93 - loss = 0.5741780996322632\n",
      "this is the iteration number 94 - loss = 0.6012309789657593\n",
      "this is the iteration number 95 - loss = 0.557758092880249\n",
      "this is the iteration number 96 - loss = 0.5953897833824158\n",
      "this is the iteration number 97 - loss = 0.5756176114082336\n",
      "this is the iteration number 98 - loss = 0.5597474575042725\n",
      "this is the iteration number 99 - loss = 0.5821772217750549\n",
      "this is the iteration number 100 - loss = 0.5617897510528564\n",
      "this is the iteration number 101 - loss = 0.50335294008255\n",
      "this is the iteration number 0 - loss = 0.5729127526283264\n",
      "this is the iteration number 1 - loss = 0.5654603242874146\n",
      "this is the iteration number 2 - loss = 0.5831003189086914\n",
      "this is the iteration number 3 - loss = 0.5563812255859375\n",
      "this is the iteration number 4 - loss = 0.5823928713798523\n",
      "this is the iteration number 5 - loss = 0.610357940196991\n",
      "this is the iteration number 6 - loss = 0.6284995079040527\n",
      "this is the iteration number 7 - loss = 0.5693807005882263\n",
      "this is the iteration number 8 - loss = 0.6092647314071655\n",
      "this is the iteration number 9 - loss = 0.5725294947624207\n",
      "this is the iteration number 10 - loss = 0.5680972933769226\n",
      "this is the iteration number 11 - loss = 0.5305114388465881\n",
      "this is the iteration number 12 - loss = 0.5340856909751892\n",
      "this is the iteration number 13 - loss = 0.565788984298706\n",
      "this is the iteration number 14 - loss = 0.5375064611434937\n",
      "this is the iteration number 15 - loss = 0.5584360957145691\n",
      "this is the iteration number 16 - loss = 0.5599643588066101\n",
      "this is the iteration number 17 - loss = 0.5748783946037292\n",
      "this is the iteration number 18 - loss = 0.5428828001022339\n",
      "this is the iteration number 19 - loss = 0.6169975399971008\n",
      "this is the iteration number 20 - loss = 0.6140156984329224\n",
      "this is the iteration number 21 - loss = 0.5641018152236938\n",
      "this is the iteration number 22 - loss = 0.5578500628471375\n",
      "this is the iteration number 23 - loss = 0.5686994791030884\n",
      "this is the iteration number 24 - loss = 0.5387455821037292\n",
      "this is the iteration number 25 - loss = 0.6086740493774414\n",
      "this is the iteration number 26 - loss = 0.5375739932060242\n",
      "this is the iteration number 27 - loss = 0.5264864563941956\n",
      "this is the iteration number 28 - loss = 0.5716615319252014\n",
      "this is the iteration number 29 - loss = 0.6263241171836853\n",
      "this is the iteration number 30 - loss = 0.500007152557373\n",
      "this is the iteration number 31 - loss = 0.5526333451271057\n",
      "this is the iteration number 32 - loss = 0.570734977722168\n",
      "this is the iteration number 33 - loss = 0.5413936376571655\n",
      "this is the iteration number 34 - loss = 0.5572059750556946\n",
      "this is the iteration number 35 - loss = 0.5768980979919434\n",
      "this is the iteration number 36 - loss = 0.5647057294845581\n",
      "this is the iteration number 37 - loss = 0.5775537490844727\n",
      "this is the iteration number 38 - loss = 0.5170958638191223\n",
      "this is the iteration number 39 - loss = 0.5274469256401062\n",
      "this is the iteration number 40 - loss = 0.5656986832618713\n",
      "this is the iteration number 41 - loss = 0.534927487373352\n",
      "this is the iteration number 42 - loss = 0.6126013398170471\n",
      "this is the iteration number 43 - loss = 0.5533082485198975\n",
      "this is the iteration number 44 - loss = 0.5756170153617859\n",
      "this is the iteration number 45 - loss = 0.49838829040527344\n",
      "this is the iteration number 46 - loss = 0.5746454000473022\n",
      "this is the iteration number 47 - loss = 0.5561329126358032\n",
      "this is the iteration number 48 - loss = 0.5834736227989197\n",
      "this is the iteration number 49 - loss = 0.5627883672714233\n",
      "this is the iteration number 50 - loss = 0.5522538423538208\n",
      "this is the iteration number 51 - loss = 0.5515783429145813\n",
      "this is the iteration number 52 - loss = 0.5268924236297607\n",
      "this is the iteration number 53 - loss = 0.5540913343429565\n",
      "this is the iteration number 54 - loss = 0.5497733354568481\n",
      "this is the iteration number 55 - loss = 0.5762186646461487\n",
      "this is the iteration number 56 - loss = 0.5531201362609863\n",
      "this is the iteration number 57 - loss = 0.5210749506950378\n",
      "this is the iteration number 58 - loss = 0.5802587270736694\n",
      "this is the iteration number 59 - loss = 0.5764755010604858\n",
      "this is the iteration number 60 - loss = 0.5619761347770691\n",
      "this is the iteration number 61 - loss = 0.5179294347763062\n",
      "this is the iteration number 62 - loss = 0.5498365759849548\n",
      "this is the iteration number 63 - loss = 0.5408913493156433\n",
      "this is the iteration number 64 - loss = 0.5813952088356018\n",
      "this is the iteration number 65 - loss = 0.5580061078071594\n",
      "this is the iteration number 66 - loss = 0.5758582949638367\n",
      "this is the iteration number 67 - loss = 0.5545423626899719\n",
      "this is the iteration number 68 - loss = 0.5129045844078064\n",
      "this is the iteration number 69 - loss = 0.5055522322654724\n",
      "this is the iteration number 70 - loss = 0.5562872290611267\n",
      "this is the iteration number 71 - loss = 0.5765150785446167\n",
      "this is the iteration number 72 - loss = 0.49907663464546204\n",
      "this is the iteration number 73 - loss = 0.5432756543159485\n",
      "this is the iteration number 74 - loss = 0.5716770887374878\n",
      "this is the iteration number 75 - loss = 0.5282085537910461\n",
      "this is the iteration number 76 - loss = 0.5445181727409363\n",
      "this is the iteration number 77 - loss = 0.5440811514854431\n",
      "this is the iteration number 78 - loss = 0.5688719153404236\n",
      "this is the iteration number 79 - loss = 0.5240482091903687\n",
      "this is the iteration number 80 - loss = 0.5569576621055603\n",
      "this is the iteration number 81 - loss = 0.5572845339775085\n",
      "this is the iteration number 82 - loss = 0.5680851340293884\n",
      "this is the iteration number 83 - loss = 0.522041380405426\n",
      "this is the iteration number 84 - loss = 0.5846605896949768\n",
      "this is the iteration number 85 - loss = 0.5974488258361816\n",
      "this is the iteration number 86 - loss = 0.5147400498390198\n",
      "this is the iteration number 87 - loss = 0.5281635522842407\n",
      "this is the iteration number 88 - loss = 0.5501739382743835\n",
      "this is the iteration number 89 - loss = 0.5118274092674255\n",
      "this is the iteration number 90 - loss = 0.5185548067092896\n",
      "this is the iteration number 91 - loss = 0.5560917258262634\n",
      "this is the iteration number 92 - loss = 0.5672460198402405\n",
      "this is the iteration number 93 - loss = 0.5486184358596802\n",
      "this is the iteration number 94 - loss = 0.5206809639930725\n",
      "this is the iteration number 95 - loss = 0.5360286235809326\n",
      "this is the iteration number 96 - loss = 0.5717948079109192\n",
      "this is the iteration number 97 - loss = 0.5521999001502991\n",
      "this is the iteration number 98 - loss = 0.5509380102157593\n",
      "this is the iteration number 99 - loss = 0.4942386746406555\n",
      "this is the iteration number 100 - loss = 0.5406798720359802\n",
      "this is the iteration number 101 - loss = 0.5467481017112732\n",
      "this is the iteration number 0 - loss = 0.5691724419593811\n",
      "this is the iteration number 1 - loss = 0.5983794331550598\n",
      "this is the iteration number 2 - loss = 0.5691674947738647\n",
      "this is the iteration number 3 - loss = 0.5714196562767029\n",
      "this is the iteration number 4 - loss = 0.5638548731803894\n",
      "this is the iteration number 5 - loss = 0.570776104927063\n",
      "this is the iteration number 6 - loss = 0.5432420372962952\n",
      "this is the iteration number 7 - loss = 0.5895656943321228\n",
      "this is the iteration number 8 - loss = 0.552731454372406\n",
      "this is the iteration number 9 - loss = 0.54368656873703\n",
      "this is the iteration number 10 - loss = 0.5550947785377502\n",
      "this is the iteration number 11 - loss = 0.5305550694465637\n",
      "this is the iteration number 12 - loss = 0.5739487409591675\n",
      "this is the iteration number 13 - loss = 0.5210902094841003\n",
      "this is the iteration number 14 - loss = 0.5117353200912476\n",
      "this is the iteration number 15 - loss = 0.5342565774917603\n",
      "this is the iteration number 16 - loss = 0.5753874778747559\n",
      "this is the iteration number 17 - loss = 0.5602743029594421\n",
      "this is the iteration number 18 - loss = 0.5189787149429321\n",
      "this is the iteration number 19 - loss = 0.5660200119018555\n",
      "this is the iteration number 20 - loss = 0.5043438673019409\n",
      "this is the iteration number 21 - loss = 0.5362311005592346\n",
      "this is the iteration number 22 - loss = 0.5366181135177612\n",
      "this is the iteration number 23 - loss = 0.5139392018318176\n",
      "this is the iteration number 24 - loss = 0.5239001512527466\n",
      "this is the iteration number 25 - loss = 0.5319178104400635\n",
      "this is the iteration number 26 - loss = 0.5199970006942749\n",
      "this is the iteration number 27 - loss = 0.5438696146011353\n",
      "this is the iteration number 28 - loss = 0.5374135375022888\n",
      "this is the iteration number 29 - loss = 0.5747207403182983\n",
      "this is the iteration number 30 - loss = 0.5367306470870972\n",
      "this is the iteration number 31 - loss = 0.5648688673973083\n",
      "this is the iteration number 32 - loss = 0.5823507308959961\n",
      "this is the iteration number 33 - loss = 0.5556201338768005\n",
      "this is the iteration number 34 - loss = 0.5463389158248901\n",
      "this is the iteration number 35 - loss = 0.5503600835800171\n",
      "this is the iteration number 36 - loss = 0.5199514627456665\n",
      "this is the iteration number 37 - loss = 0.5078531503677368\n",
      "this is the iteration number 38 - loss = 0.611511766910553\n",
      "this is the iteration number 39 - loss = 0.5864599347114563\n",
      "this is the iteration number 40 - loss = 0.5521860718727112\n",
      "this is the iteration number 41 - loss = 0.5589120388031006\n",
      "this is the iteration number 42 - loss = 0.5352915525436401\n",
      "this is the iteration number 43 - loss = 0.5090415477752686\n",
      "this is the iteration number 44 - loss = 0.5671013593673706\n",
      "this is the iteration number 45 - loss = 0.541830837726593\n",
      "this is the iteration number 46 - loss = 0.5083490610122681\n",
      "this is the iteration number 47 - loss = 0.5305246710777283\n",
      "this is the iteration number 48 - loss = 0.6007542014122009\n",
      "this is the iteration number 49 - loss = 0.5972968339920044\n",
      "this is the iteration number 50 - loss = 0.586700975894928\n",
      "this is the iteration number 51 - loss = 0.5603853464126587\n",
      "this is the iteration number 52 - loss = 0.5759233832359314\n",
      "this is the iteration number 53 - loss = 0.5373386144638062\n",
      "this is the iteration number 54 - loss = 0.4894774556159973\n",
      "this is the iteration number 55 - loss = 0.5337377786636353\n",
      "this is the iteration number 56 - loss = 0.5671260952949524\n",
      "this is the iteration number 57 - loss = 0.49266523122787476\n",
      "this is the iteration number 58 - loss = 0.5762828588485718\n",
      "this is the iteration number 59 - loss = 0.4883227050304413\n",
      "this is the iteration number 60 - loss = 0.4986462891101837\n",
      "this is the iteration number 61 - loss = 0.5593605041503906\n",
      "this is the iteration number 62 - loss = 0.5262089967727661\n",
      "this is the iteration number 63 - loss = 0.5574880242347717\n",
      "this is the iteration number 64 - loss = 0.5733842849731445\n",
      "this is the iteration number 65 - loss = 0.6361261606216431\n",
      "this is the iteration number 66 - loss = 0.5435561537742615\n",
      "this is the iteration number 67 - loss = 0.4977295696735382\n",
      "this is the iteration number 68 - loss = 0.5551631450653076\n",
      "this is the iteration number 69 - loss = 0.6021188497543335\n",
      "this is the iteration number 70 - loss = 0.5863251090049744\n",
      "this is the iteration number 71 - loss = 0.5045965909957886\n",
      "this is the iteration number 72 - loss = 0.5527889132499695\n",
      "this is the iteration number 73 - loss = 0.5322203040122986\n",
      "this is the iteration number 74 - loss = 0.5449984669685364\n",
      "this is the iteration number 75 - loss = 0.5035625100135803\n",
      "this is the iteration number 76 - loss = 0.5541921257972717\n",
      "this is the iteration number 77 - loss = 0.5408324003219604\n",
      "this is the iteration number 78 - loss = 0.501207172870636\n",
      "this is the iteration number 79 - loss = 0.5404946208000183\n",
      "this is the iteration number 80 - loss = 0.5373579263687134\n",
      "this is the iteration number 81 - loss = 0.5343762636184692\n",
      "this is the iteration number 82 - loss = 0.5758556723594666\n",
      "this is the iteration number 83 - loss = 0.5710409879684448\n",
      "this is the iteration number 84 - loss = 0.4929245412349701\n",
      "this is the iteration number 85 - loss = 0.5708079934120178\n",
      "this is the iteration number 86 - loss = 0.5543509125709534\n",
      "this is the iteration number 87 - loss = 0.5296514630317688\n",
      "this is the iteration number 88 - loss = 0.5338425636291504\n",
      "this is the iteration number 89 - loss = 0.5587911605834961\n",
      "this is the iteration number 90 - loss = 0.5583879947662354\n",
      "this is the iteration number 91 - loss = 0.5121335387229919\n",
      "this is the iteration number 92 - loss = 0.5610783100128174\n",
      "this is the iteration number 93 - loss = 0.5299664735794067\n",
      "this is the iteration number 94 - loss = 0.49149179458618164\n",
      "this is the iteration number 95 - loss = 0.5396851897239685\n",
      "this is the iteration number 96 - loss = 0.5541719794273376\n",
      "this is the iteration number 97 - loss = 0.5348168611526489\n",
      "this is the iteration number 98 - loss = 0.5037750005722046\n",
      "this is the iteration number 99 - loss = 0.5232950448989868\n",
      "this is the iteration number 100 - loss = 0.6098275184631348\n",
      "this is the iteration number 101 - loss = 0.5741319060325623\n",
      "this is the iteration number 0 - loss = 0.5404701828956604\n",
      "this is the iteration number 1 - loss = 0.6109011769294739\n",
      "this is the iteration number 2 - loss = 0.5226213932037354\n",
      "this is the iteration number 3 - loss = 0.5400099158287048\n",
      "this is the iteration number 4 - loss = 0.5741513967514038\n",
      "this is the iteration number 5 - loss = 0.5669962763786316\n",
      "this is the iteration number 6 - loss = 0.5115179419517517\n",
      "this is the iteration number 7 - loss = 0.5073431134223938\n",
      "this is the iteration number 8 - loss = 0.45696821808815\n",
      "this is the iteration number 9 - loss = 0.540716290473938\n",
      "this is the iteration number 10 - loss = 0.5092897415161133\n",
      "this is the iteration number 11 - loss = 0.5462456345558167\n",
      "this is the iteration number 12 - loss = 0.6010479927062988\n",
      "this is the iteration number 13 - loss = 0.5459897518157959\n",
      "this is the iteration number 14 - loss = 0.5232213139533997\n",
      "this is the iteration number 15 - loss = 0.5816777348518372\n",
      "this is the iteration number 16 - loss = 0.5501703023910522\n",
      "this is the iteration number 17 - loss = 0.4602627754211426\n",
      "this is the iteration number 18 - loss = 0.5388513803482056\n",
      "this is the iteration number 19 - loss = 0.5683919191360474\n",
      "this is the iteration number 20 - loss = 0.5436326265335083\n",
      "this is the iteration number 21 - loss = 0.517248809337616\n",
      "this is the iteration number 22 - loss = 0.4888480603694916\n",
      "this is the iteration number 23 - loss = 0.5043741464614868\n",
      "this is the iteration number 24 - loss = 0.516626238822937\n",
      "this is the iteration number 25 - loss = 0.5882373452186584\n",
      "this is the iteration number 26 - loss = 0.5297607183456421\n",
      "this is the iteration number 27 - loss = 0.5629062056541443\n",
      "this is the iteration number 28 - loss = 0.5184341073036194\n",
      "this is the iteration number 29 - loss = 0.47462156414985657\n",
      "this is the iteration number 30 - loss = 0.5357059240341187\n",
      "this is the iteration number 31 - loss = 0.5495006442070007\n",
      "this is the iteration number 32 - loss = 0.5229742527008057\n",
      "this is the iteration number 33 - loss = 0.552759051322937\n",
      "this is the iteration number 34 - loss = 0.5344859957695007\n",
      "this is the iteration number 35 - loss = 0.5019305348396301\n",
      "this is the iteration number 36 - loss = 0.5628588199615479\n",
      "this is the iteration number 37 - loss = 0.5352433323860168\n",
      "this is the iteration number 38 - loss = 0.5073959231376648\n",
      "this is the iteration number 39 - loss = 0.5885161757469177\n",
      "this is the iteration number 40 - loss = 0.5248498320579529\n",
      "this is the iteration number 41 - loss = 0.5373998880386353\n",
      "this is the iteration number 42 - loss = 0.542759895324707\n",
      "this is the iteration number 43 - loss = 0.5159493684768677\n",
      "this is the iteration number 44 - loss = 0.5758441686630249\n",
      "this is the iteration number 45 - loss = 0.5687400102615356\n",
      "this is the iteration number 46 - loss = 0.5849303007125854\n",
      "this is the iteration number 47 - loss = 0.5224496126174927\n",
      "this is the iteration number 48 - loss = 0.5176190137863159\n",
      "this is the iteration number 49 - loss = 0.5437654256820679\n",
      "this is the iteration number 50 - loss = 0.5093517899513245\n",
      "this is the iteration number 51 - loss = 0.5385178327560425\n",
      "this is the iteration number 52 - loss = 0.5710967183113098\n",
      "this is the iteration number 53 - loss = 0.5673497915267944\n",
      "this is the iteration number 54 - loss = 0.5199224352836609\n",
      "this is the iteration number 55 - loss = 0.5042865872383118\n",
      "this is the iteration number 56 - loss = 0.5578802227973938\n",
      "this is the iteration number 57 - loss = 0.495415598154068\n",
      "this is the iteration number 58 - loss = 0.5021407008171082\n",
      "this is the iteration number 59 - loss = 0.5889521837234497\n",
      "this is the iteration number 60 - loss = 0.5510944724082947\n",
      "this is the iteration number 61 - loss = 0.5034204721450806\n",
      "this is the iteration number 62 - loss = 0.6085261106491089\n",
      "this is the iteration number 63 - loss = 0.5450146794319153\n",
      "this is the iteration number 64 - loss = 0.5898109674453735\n",
      "this is the iteration number 65 - loss = 0.5441305041313171\n",
      "this is the iteration number 66 - loss = 0.5737704634666443\n",
      "this is the iteration number 67 - loss = 0.547732949256897\n",
      "this is the iteration number 68 - loss = 0.5763498544692993\n",
      "this is the iteration number 69 - loss = 0.5823022127151489\n",
      "this is the iteration number 70 - loss = 0.5164942145347595\n",
      "this is the iteration number 71 - loss = 0.5714210271835327\n",
      "this is the iteration number 72 - loss = 0.5355414152145386\n",
      "this is the iteration number 73 - loss = 0.5444580316543579\n",
      "this is the iteration number 74 - loss = 0.5174010992050171\n",
      "this is the iteration number 75 - loss = 0.5298122763633728\n",
      "this is the iteration number 76 - loss = 0.5596878528594971\n",
      "this is the iteration number 77 - loss = 0.5743705630302429\n",
      "this is the iteration number 78 - loss = 0.6057237386703491\n",
      "this is the iteration number 79 - loss = 0.5350005030632019\n",
      "this is the iteration number 80 - loss = 0.5131211876869202\n",
      "this is the iteration number 81 - loss = 0.5055474042892456\n",
      "this is the iteration number 82 - loss = 0.5054327249526978\n",
      "this is the iteration number 83 - loss = 0.5241889357566833\n",
      "this is the iteration number 84 - loss = 0.5433992147445679\n",
      "this is the iteration number 85 - loss = 0.5349883437156677\n",
      "this is the iteration number 86 - loss = 0.5613455772399902\n",
      "this is the iteration number 87 - loss = 0.5138034224510193\n",
      "this is the iteration number 88 - loss = 0.5244802832603455\n",
      "this is the iteration number 89 - loss = 0.567722499370575\n",
      "this is the iteration number 90 - loss = 0.5866342186927795\n",
      "this is the iteration number 91 - loss = 0.5083732008934021\n",
      "this is the iteration number 92 - loss = 0.5647626519203186\n",
      "this is the iteration number 93 - loss = 0.5064249038696289\n",
      "this is the iteration number 94 - loss = 0.5153608918190002\n",
      "this is the iteration number 95 - loss = 0.5136273503303528\n",
      "this is the iteration number 96 - loss = 0.540427029132843\n",
      "this is the iteration number 97 - loss = 0.47257304191589355\n",
      "this is the iteration number 98 - loss = 0.5698208808898926\n",
      "this is the iteration number 99 - loss = 0.5950279235839844\n",
      "this is the iteration number 100 - loss = 0.5378535389900208\n",
      "this is the iteration number 101 - loss = 0.528327465057373\n",
      "this is the iteration number 0 - loss = 0.552749752998352\n",
      "this is the iteration number 1 - loss = 0.48292094469070435\n",
      "this is the iteration number 2 - loss = 0.5350167155265808\n",
      "this is the iteration number 3 - loss = 0.5667014718055725\n",
      "this is the iteration number 4 - loss = 0.569218099117279\n",
      "this is the iteration number 5 - loss = 0.5859748721122742\n",
      "this is the iteration number 6 - loss = 0.5696209073066711\n",
      "this is the iteration number 7 - loss = 0.48260149359703064\n",
      "this is the iteration number 8 - loss = 0.5878919363021851\n",
      "this is the iteration number 9 - loss = 0.5093387961387634\n",
      "this is the iteration number 10 - loss = 0.5383216142654419\n",
      "this is the iteration number 11 - loss = 0.6066940426826477\n",
      "this is the iteration number 12 - loss = 0.5738240480422974\n",
      "this is the iteration number 13 - loss = 0.518615186214447\n",
      "this is the iteration number 14 - loss = 0.5349451303482056\n",
      "this is the iteration number 15 - loss = 0.4874850809574127\n",
      "this is the iteration number 16 - loss = 0.537942111492157\n",
      "this is the iteration number 17 - loss = 0.5625539422035217\n",
      "this is the iteration number 18 - loss = 0.48214301466941833\n",
      "this is the iteration number 19 - loss = 0.5076137781143188\n",
      "this is the iteration number 20 - loss = 0.5761122107505798\n",
      "this is the iteration number 21 - loss = 0.5147185921669006\n",
      "this is the iteration number 22 - loss = 0.5347980856895447\n",
      "this is the iteration number 23 - loss = 0.5266236662864685\n",
      "this is the iteration number 24 - loss = 0.5718327760696411\n",
      "this is the iteration number 25 - loss = 0.5560270547866821\n",
      "this is the iteration number 26 - loss = 0.48276302218437195\n",
      "this is the iteration number 27 - loss = 0.5283894538879395\n",
      "this is the iteration number 28 - loss = 0.4770844578742981\n",
      "this is the iteration number 29 - loss = 0.5557045936584473\n",
      "this is the iteration number 30 - loss = 0.5072426795959473\n",
      "this is the iteration number 31 - loss = 0.5495017170906067\n",
      "this is the iteration number 32 - loss = 0.5369101762771606\n",
      "this is the iteration number 33 - loss = 0.5144177675247192\n",
      "this is the iteration number 34 - loss = 0.514244794845581\n",
      "this is the iteration number 35 - loss = 0.5319784879684448\n",
      "this is the iteration number 36 - loss = 0.5387886762619019\n",
      "this is the iteration number 37 - loss = 0.5380023717880249\n",
      "this is the iteration number 38 - loss = 0.5824337601661682\n",
      "this is the iteration number 39 - loss = 0.5542808175086975\n",
      "this is the iteration number 40 - loss = 0.48668307065963745\n",
      "this is the iteration number 41 - loss = 0.5519921183586121\n",
      "this is the iteration number 42 - loss = 0.5057722926139832\n",
      "this is the iteration number 43 - loss = 0.5900874733924866\n",
      "this is the iteration number 44 - loss = 0.544780433177948\n",
      "this is the iteration number 45 - loss = 0.5342638492584229\n",
      "this is the iteration number 46 - loss = 0.5690314173698425\n",
      "this is the iteration number 47 - loss = 0.48116105794906616\n",
      "this is the iteration number 48 - loss = 0.5183481574058533\n",
      "this is the iteration number 49 - loss = 0.5158751010894775\n",
      "this is the iteration number 50 - loss = 0.4760771691799164\n",
      "this is the iteration number 51 - loss = 0.5332106947898865\n",
      "this is the iteration number 52 - loss = 0.5024101734161377\n",
      "this is the iteration number 53 - loss = 0.5315542817115784\n",
      "this is the iteration number 54 - loss = 0.5313325524330139\n",
      "this is the iteration number 55 - loss = 0.514186680316925\n",
      "this is the iteration number 56 - loss = 0.5908846855163574\n",
      "this is the iteration number 57 - loss = 0.5126709342002869\n",
      "this is the iteration number 58 - loss = 0.5011951327323914\n",
      "this is the iteration number 59 - loss = 0.555535078048706\n",
      "this is the iteration number 60 - loss = 0.5347021818161011\n",
      "this is the iteration number 61 - loss = 0.4985460937023163\n",
      "this is the iteration number 62 - loss = 0.560258686542511\n",
      "this is the iteration number 63 - loss = 0.5415225625038147\n",
      "this is the iteration number 64 - loss = 0.5388879179954529\n",
      "this is the iteration number 65 - loss = 0.5268958806991577\n",
      "this is the iteration number 66 - loss = 0.5514363050460815\n",
      "this is the iteration number 67 - loss = 0.5336595177650452\n",
      "this is the iteration number 68 - loss = 0.5386446118354797\n",
      "this is the iteration number 69 - loss = 0.5718234777450562\n",
      "this is the iteration number 70 - loss = 0.5239384770393372\n",
      "this is the iteration number 71 - loss = 0.5210896730422974\n",
      "this is the iteration number 72 - loss = 0.5460366010665894\n",
      "this is the iteration number 73 - loss = 0.5110460519790649\n",
      "this is the iteration number 74 - loss = 0.505607545375824\n",
      "this is the iteration number 75 - loss = 0.5299169421195984\n",
      "this is the iteration number 76 - loss = 0.5619540810585022\n",
      "this is the iteration number 77 - loss = 0.5427566766738892\n",
      "this is the iteration number 78 - loss = 0.5194308161735535\n",
      "this is the iteration number 79 - loss = 0.5467735528945923\n",
      "this is the iteration number 80 - loss = 0.5649738907814026\n",
      "this is the iteration number 81 - loss = 0.5290644764900208\n",
      "this is the iteration number 82 - loss = 0.49515822529792786\n",
      "this is the iteration number 83 - loss = 0.5701597332954407\n",
      "this is the iteration number 84 - loss = 0.5290039777755737\n",
      "this is the iteration number 85 - loss = 0.5422340035438538\n",
      "this is the iteration number 86 - loss = 0.5418735146522522\n",
      "this is the iteration number 87 - loss = 0.5477710366249084\n",
      "this is the iteration number 88 - loss = 0.5957065224647522\n",
      "this is the iteration number 89 - loss = 0.5379258990287781\n",
      "this is the iteration number 90 - loss = 0.5066733956336975\n",
      "this is the iteration number 91 - loss = 0.5486888289451599\n",
      "this is the iteration number 92 - loss = 0.49489709734916687\n",
      "this is the iteration number 93 - loss = 0.5260643362998962\n",
      "this is the iteration number 94 - loss = 0.5220603346824646\n",
      "this is the iteration number 95 - loss = 0.5996131300926208\n",
      "this is the iteration number 96 - loss = 0.5392249226570129\n",
      "this is the iteration number 97 - loss = 0.508630096912384\n",
      "this is the iteration number 98 - loss = 0.515761137008667\n",
      "this is the iteration number 99 - loss = 0.5213766694068909\n",
      "this is the iteration number 100 - loss = 0.5339918732643127\n",
      "this is the iteration number 101 - loss = 0.4878939688205719\n",
      "this is the iteration number 0 - loss = 0.5632579922676086\n",
      "this is the iteration number 1 - loss = 0.5152105689048767\n",
      "this is the iteration number 2 - loss = 0.5682787299156189\n",
      "this is the iteration number 3 - loss = 0.5090487003326416\n",
      "this is the iteration number 4 - loss = 0.49058517813682556\n",
      "this is the iteration number 5 - loss = 0.5025177597999573\n",
      "this is the iteration number 6 - loss = 0.5675902366638184\n",
      "this is the iteration number 7 - loss = 0.499896764755249\n",
      "this is the iteration number 8 - loss = 0.526874303817749\n",
      "this is the iteration number 9 - loss = 0.5279828310012817\n",
      "this is the iteration number 10 - loss = 0.5868002772331238\n",
      "this is the iteration number 11 - loss = 0.5166874527931213\n",
      "this is the iteration number 12 - loss = 0.5282345414161682\n",
      "this is the iteration number 13 - loss = 0.54151850938797\n",
      "this is the iteration number 14 - loss = 0.5357704758644104\n",
      "this is the iteration number 15 - loss = 0.5177523493766785\n",
      "this is the iteration number 16 - loss = 0.5149935483932495\n",
      "this is the iteration number 17 - loss = 0.5528391003608704\n",
      "this is the iteration number 18 - loss = 0.5253604650497437\n",
      "this is the iteration number 19 - loss = 0.526690661907196\n",
      "this is the iteration number 20 - loss = 0.5842652320861816\n",
      "this is the iteration number 21 - loss = 0.5377215147018433\n",
      "this is the iteration number 22 - loss = 0.5322006344795227\n",
      "this is the iteration number 23 - loss = 0.5520746111869812\n",
      "this is the iteration number 24 - loss = 0.5362340211868286\n",
      "this is the iteration number 25 - loss = 0.5031371116638184\n",
      "this is the iteration number 26 - loss = 0.5161206722259521\n",
      "this is the iteration number 27 - loss = 0.5340232253074646\n",
      "this is the iteration number 28 - loss = 0.5668176412582397\n",
      "this is the iteration number 29 - loss = 0.5249281525611877\n",
      "this is the iteration number 30 - loss = 0.5062601566314697\n",
      "this is the iteration number 31 - loss = 0.5009101629257202\n",
      "this is the iteration number 32 - loss = 0.5180331468582153\n",
      "this is the iteration number 33 - loss = 0.5495854616165161\n",
      "this is the iteration number 34 - loss = 0.5091586709022522\n",
      "this is the iteration number 35 - loss = 0.5490931272506714\n",
      "this is the iteration number 36 - loss = 0.5227827429771423\n",
      "this is the iteration number 37 - loss = 0.5089619755744934\n",
      "this is the iteration number 38 - loss = 0.5201820731163025\n",
      "this is the iteration number 39 - loss = 0.5541357398033142\n",
      "this is the iteration number 40 - loss = 0.5310025811195374\n",
      "this is the iteration number 41 - loss = 0.47388073801994324\n",
      "this is the iteration number 42 - loss = 0.5414220690727234\n",
      "this is the iteration number 43 - loss = 0.5241648554801941\n",
      "this is the iteration number 44 - loss = 0.5757652521133423\n",
      "this is the iteration number 45 - loss = 0.5219122171401978\n",
      "this is the iteration number 46 - loss = 0.5545505285263062\n",
      "this is the iteration number 47 - loss = 0.5431386828422546\n",
      "this is the iteration number 48 - loss = 0.5232285261154175\n",
      "this is the iteration number 49 - loss = 0.4981215298175812\n",
      "this is the iteration number 50 - loss = 0.5184239745140076\n",
      "this is the iteration number 51 - loss = 0.5358637571334839\n",
      "this is the iteration number 52 - loss = 0.5461847186088562\n",
      "this is the iteration number 53 - loss = 0.49457406997680664\n",
      "this is the iteration number 54 - loss = 0.5544382929801941\n",
      "this is the iteration number 55 - loss = 0.544583261013031\n",
      "this is the iteration number 56 - loss = 0.5252941846847534\n",
      "this is the iteration number 57 - loss = 0.5092592239379883\n",
      "this is the iteration number 58 - loss = 0.5555420517921448\n",
      "this is the iteration number 59 - loss = 0.5623393058776855\n",
      "this is the iteration number 60 - loss = 0.5076712369918823\n",
      "this is the iteration number 61 - loss = 0.5303349494934082\n",
      "this is the iteration number 62 - loss = 0.5409271717071533\n",
      "this is the iteration number 63 - loss = 0.5397191643714905\n",
      "this is the iteration number 64 - loss = 0.5457586646080017\n",
      "this is the iteration number 65 - loss = 0.503301203250885\n",
      "this is the iteration number 66 - loss = 0.5066023468971252\n",
      "this is the iteration number 67 - loss = 0.49590855836868286\n",
      "this is the iteration number 68 - loss = 0.47198519110679626\n",
      "this is the iteration number 69 - loss = 0.5035570859909058\n",
      "this is the iteration number 70 - loss = 0.5646446347236633\n",
      "this is the iteration number 71 - loss = 0.5474919676780701\n",
      "this is the iteration number 72 - loss = 0.5289656519889832\n",
      "this is the iteration number 73 - loss = 0.5537835359573364\n",
      "this is the iteration number 74 - loss = 0.5063751935958862\n",
      "this is the iteration number 75 - loss = 0.5412183403968811\n",
      "this is the iteration number 76 - loss = 0.4436279833316803\n",
      "this is the iteration number 77 - loss = 0.4995590150356293\n",
      "this is the iteration number 78 - loss = 0.5691055655479431\n",
      "this is the iteration number 79 - loss = 0.5013017058372498\n",
      "this is the iteration number 80 - loss = 0.575102686882019\n",
      "this is the iteration number 81 - loss = 0.49877840280532837\n",
      "this is the iteration number 82 - loss = 0.5435425639152527\n",
      "this is the iteration number 83 - loss = 0.51499342918396\n",
      "this is the iteration number 84 - loss = 0.5622668862342834\n",
      "this is the iteration number 85 - loss = 0.5259420871734619\n",
      "this is the iteration number 86 - loss = 0.5500518083572388\n",
      "this is the iteration number 87 - loss = 0.6245575547218323\n",
      "this is the iteration number 88 - loss = 0.5601992607116699\n",
      "this is the iteration number 89 - loss = 0.5259663462638855\n",
      "this is the iteration number 90 - loss = 0.5762184858322144\n",
      "this is the iteration number 91 - loss = 0.4804520606994629\n",
      "this is the iteration number 92 - loss = 0.5269706845283508\n",
      "this is the iteration number 93 - loss = 0.5379217267036438\n",
      "this is the iteration number 94 - loss = 0.5190171599388123\n",
      "this is the iteration number 95 - loss = 0.551556408405304\n",
      "this is the iteration number 96 - loss = 0.5178307294845581\n",
      "this is the iteration number 97 - loss = 0.5335090756416321\n",
      "this is the iteration number 98 - loss = 0.48425737023353577\n",
      "this is the iteration number 99 - loss = 0.48695531487464905\n",
      "this is the iteration number 100 - loss = 0.5373085737228394\n",
      "this is the iteration number 101 - loss = 0.5064008831977844\n",
      "this is the iteration number 0 - loss = 0.48707762360572815\n",
      "this is the iteration number 1 - loss = 0.5312605500221252\n",
      "this is the iteration number 2 - loss = 0.5014732480049133\n",
      "this is the iteration number 3 - loss = 0.5904722809791565\n",
      "this is the iteration number 4 - loss = 0.5311664938926697\n",
      "this is the iteration number 5 - loss = 0.5583087801933289\n",
      "this is the iteration number 6 - loss = 0.5098248720169067\n",
      "this is the iteration number 7 - loss = 0.4866315424442291\n",
      "this is the iteration number 8 - loss = 0.537051796913147\n",
      "this is the iteration number 9 - loss = 0.528540849685669\n",
      "this is the iteration number 10 - loss = 0.5432940721511841\n",
      "this is the iteration number 11 - loss = 0.4868625998497009\n",
      "this is the iteration number 12 - loss = 0.44854989647865295\n",
      "this is the iteration number 13 - loss = 0.5158504247665405\n",
      "this is the iteration number 14 - loss = 0.4888630509376526\n",
      "this is the iteration number 15 - loss = 0.5366920828819275\n",
      "this is the iteration number 16 - loss = 0.5288068652153015\n",
      "this is the iteration number 17 - loss = 0.5439000129699707\n",
      "this is the iteration number 18 - loss = 0.554474413394928\n",
      "this is the iteration number 19 - loss = 0.5230039954185486\n",
      "this is the iteration number 20 - loss = 0.5235264897346497\n",
      "this is the iteration number 21 - loss = 0.5261066555976868\n",
      "this is the iteration number 22 - loss = 0.5096750855445862\n",
      "this is the iteration number 23 - loss = 0.5613570809364319\n",
      "this is the iteration number 24 - loss = 0.5249093770980835\n",
      "this is the iteration number 25 - loss = 0.47877296805381775\n",
      "this is the iteration number 26 - loss = 0.5177780389785767\n",
      "this is the iteration number 27 - loss = 0.5359653234481812\n",
      "this is the iteration number 28 - loss = 0.5361424684524536\n",
      "this is the iteration number 29 - loss = 0.5023032426834106\n",
      "this is the iteration number 30 - loss = 0.5325691103935242\n",
      "this is the iteration number 31 - loss = 0.5076597332954407\n",
      "this is the iteration number 32 - loss = 0.48647385835647583\n",
      "this is the iteration number 33 - loss = 0.46094101667404175\n",
      "this is the iteration number 34 - loss = 0.5851587653160095\n",
      "this is the iteration number 35 - loss = 0.5502775311470032\n",
      "this is the iteration number 36 - loss = 0.5474504232406616\n",
      "this is the iteration number 37 - loss = 0.6206480264663696\n",
      "this is the iteration number 38 - loss = 0.4755389392375946\n",
      "this is the iteration number 39 - loss = 0.5280120372772217\n",
      "this is the iteration number 40 - loss = 0.5204765200614929\n",
      "this is the iteration number 41 - loss = 0.568816602230072\n",
      "this is the iteration number 42 - loss = 0.5779330134391785\n",
      "this is the iteration number 43 - loss = 0.4969874918460846\n",
      "this is the iteration number 44 - loss = 0.47988662123680115\n",
      "this is the iteration number 45 - loss = 0.5048130750656128\n",
      "this is the iteration number 46 - loss = 0.5446570515632629\n",
      "this is the iteration number 47 - loss = 0.554878294467926\n",
      "this is the iteration number 48 - loss = 0.5634183883666992\n",
      "this is the iteration number 49 - loss = 0.46640342473983765\n",
      "this is the iteration number 50 - loss = 0.5573412179946899\n",
      "this is the iteration number 51 - loss = 0.5652254223823547\n",
      "this is the iteration number 52 - loss = 0.5170606374740601\n",
      "this is the iteration number 53 - loss = 0.5283827185630798\n",
      "this is the iteration number 54 - loss = 0.5032011866569519\n",
      "this is the iteration number 55 - loss = 0.5039698481559753\n",
      "this is the iteration number 56 - loss = 0.5328198075294495\n",
      "this is the iteration number 57 - loss = 0.546461284160614\n",
      "this is the iteration number 58 - loss = 0.5253412127494812\n",
      "this is the iteration number 59 - loss = 0.5915670394897461\n",
      "this is the iteration number 60 - loss = 0.5284963846206665\n",
      "this is the iteration number 61 - loss = 0.573870062828064\n",
      "this is the iteration number 62 - loss = 0.5217751860618591\n",
      "this is the iteration number 63 - loss = 0.5178810954093933\n",
      "this is the iteration number 64 - loss = 0.503684937953949\n",
      "this is the iteration number 65 - loss = 0.5755466222763062\n",
      "this is the iteration number 66 - loss = 0.5207224488258362\n",
      "this is the iteration number 67 - loss = 0.516521155834198\n",
      "this is the iteration number 68 - loss = 0.4840141236782074\n",
      "this is the iteration number 69 - loss = 0.5091429948806763\n",
      "this is the iteration number 70 - loss = 0.4995918273925781\n",
      "this is the iteration number 71 - loss = 0.5300405621528625\n",
      "this is the iteration number 72 - loss = 0.5176870822906494\n",
      "this is the iteration number 73 - loss = 0.5556215047836304\n",
      "this is the iteration number 74 - loss = 0.5227986574172974\n",
      "this is the iteration number 75 - loss = 0.5572382211685181\n",
      "this is the iteration number 76 - loss = 0.49699145555496216\n",
      "this is the iteration number 77 - loss = 0.5088661313056946\n",
      "this is the iteration number 78 - loss = 0.551720917224884\n",
      "this is the iteration number 79 - loss = 0.5453627109527588\n",
      "this is the iteration number 80 - loss = 0.4989728033542633\n",
      "this is the iteration number 81 - loss = 0.4989910423755646\n",
      "this is the iteration number 82 - loss = 0.5394457578659058\n",
      "this is the iteration number 83 - loss = 0.565780520439148\n",
      "this is the iteration number 84 - loss = 0.534879744052887\n",
      "this is the iteration number 85 - loss = 0.4331115186214447\n",
      "this is the iteration number 86 - loss = 0.5463622808456421\n",
      "this is the iteration number 87 - loss = 0.5796566605567932\n",
      "this is the iteration number 88 - loss = 0.5388360023498535\n",
      "this is the iteration number 89 - loss = 0.4650680720806122\n",
      "this is the iteration number 90 - loss = 0.5000919699668884\n",
      "this is the iteration number 91 - loss = 0.506874680519104\n",
      "this is the iteration number 92 - loss = 0.5647938847541809\n",
      "this is the iteration number 93 - loss = 0.521973729133606\n",
      "this is the iteration number 94 - loss = 0.5066033601760864\n",
      "this is the iteration number 95 - loss = 0.5064926743507385\n",
      "this is the iteration number 96 - loss = 0.577100932598114\n",
      "this is the iteration number 97 - loss = 0.5064109563827515\n",
      "this is the iteration number 98 - loss = 0.4945800006389618\n",
      "this is the iteration number 99 - loss = 0.5483933687210083\n",
      "this is the iteration number 100 - loss = 0.5318666100502014\n",
      "this is the iteration number 101 - loss = 0.5218428373336792\n",
      "this is the iteration number 0 - loss = 0.4831295609474182\n",
      "this is the iteration number 1 - loss = 0.5390405654907227\n",
      "this is the iteration number 2 - loss = 0.5044970512390137\n",
      "this is the iteration number 3 - loss = 0.5337492823600769\n",
      "this is the iteration number 4 - loss = 0.5654588937759399\n",
      "this is the iteration number 5 - loss = 0.5539425015449524\n",
      "this is the iteration number 6 - loss = 0.5292946100234985\n",
      "this is the iteration number 7 - loss = 0.5562463998794556\n",
      "this is the iteration number 8 - loss = 0.5195863842964172\n",
      "this is the iteration number 9 - loss = 0.491760790348053\n",
      "this is the iteration number 10 - loss = 0.5002378225326538\n",
      "this is the iteration number 11 - loss = 0.5433422327041626\n",
      "this is the iteration number 12 - loss = 0.5764794945716858\n",
      "this is the iteration number 13 - loss = 0.5062121748924255\n",
      "this is the iteration number 14 - loss = 0.5056245923042297\n",
      "this is the iteration number 15 - loss = 0.543389618396759\n",
      "this is the iteration number 16 - loss = 0.5412989258766174\n",
      "this is the iteration number 17 - loss = 0.5858955979347229\n",
      "this is the iteration number 18 - loss = 0.5100666284561157\n",
      "this is the iteration number 19 - loss = 0.4844887852668762\n",
      "this is the iteration number 20 - loss = 0.5006642937660217\n",
      "this is the iteration number 21 - loss = 0.579431414604187\n",
      "this is the iteration number 22 - loss = 0.4682859480381012\n",
      "this is the iteration number 23 - loss = 0.523497462272644\n",
      "this is the iteration number 24 - loss = 0.4890466332435608\n",
      "this is the iteration number 25 - loss = 0.5213496685028076\n",
      "this is the iteration number 26 - loss = 0.5048463940620422\n",
      "this is the iteration number 27 - loss = 0.5317694544792175\n",
      "this is the iteration number 28 - loss = 0.5171111822128296\n",
      "this is the iteration number 29 - loss = 0.48527294397354126\n",
      "this is the iteration number 30 - loss = 0.5183192491531372\n",
      "this is the iteration number 31 - loss = 0.513039767742157\n",
      "this is the iteration number 32 - loss = 0.518056333065033\n",
      "this is the iteration number 33 - loss = 0.5564338564872742\n",
      "this is the iteration number 34 - loss = 0.5134031176567078\n",
      "this is the iteration number 35 - loss = 0.5217745900154114\n",
      "this is the iteration number 36 - loss = 0.5315867066383362\n",
      "this is the iteration number 37 - loss = 0.5402997732162476\n",
      "this is the iteration number 38 - loss = 0.5132575631141663\n",
      "this is the iteration number 39 - loss = 0.5523239970207214\n",
      "this is the iteration number 40 - loss = 0.5067423582077026\n",
      "this is the iteration number 41 - loss = 0.5180448293685913\n",
      "this is the iteration number 42 - loss = 0.48677974939346313\n",
      "this is the iteration number 43 - loss = 0.5065109133720398\n",
      "this is the iteration number 44 - loss = 0.46321240067481995\n",
      "this is the iteration number 45 - loss = 0.5681618452072144\n",
      "this is the iteration number 46 - loss = 0.5532649755477905\n",
      "this is the iteration number 47 - loss = 0.5822389721870422\n",
      "this is the iteration number 48 - loss = 0.5099353790283203\n",
      "this is the iteration number 49 - loss = 0.4773145318031311\n",
      "this is the iteration number 50 - loss = 0.4982723295688629\n",
      "this is the iteration number 51 - loss = 0.5808902978897095\n",
      "this is the iteration number 52 - loss = 0.5323939919471741\n",
      "this is the iteration number 53 - loss = 0.5293701887130737\n",
      "this is the iteration number 54 - loss = 0.4921557307243347\n",
      "this is the iteration number 55 - loss = 0.5312967300415039\n",
      "this is the iteration number 56 - loss = 0.48629096150398254\n",
      "this is the iteration number 57 - loss = 0.505691647529602\n",
      "this is the iteration number 58 - loss = 0.5388120412826538\n",
      "this is the iteration number 59 - loss = 0.5385099053382874\n",
      "this is the iteration number 60 - loss = 0.4852084517478943\n",
      "this is the iteration number 61 - loss = 0.5057910680770874\n",
      "this is the iteration number 62 - loss = 0.5330885052680969\n",
      "this is the iteration number 63 - loss = 0.5796176791191101\n",
      "this is the iteration number 64 - loss = 0.555915117263794\n",
      "this is the iteration number 65 - loss = 0.489645779132843\n",
      "this is the iteration number 66 - loss = 0.5078056454658508\n",
      "this is the iteration number 67 - loss = 0.5219650864601135\n",
      "this is the iteration number 68 - loss = 0.5421959757804871\n",
      "this is the iteration number 69 - loss = 0.5121124386787415\n",
      "this is the iteration number 70 - loss = 0.49246835708618164\n",
      "this is the iteration number 71 - loss = 0.5332973599433899\n",
      "this is the iteration number 72 - loss = 0.46866926550865173\n",
      "this is the iteration number 73 - loss = 0.5329383611679077\n",
      "this is the iteration number 74 - loss = 0.5601101517677307\n",
      "this is the iteration number 75 - loss = 0.512272298336029\n",
      "this is the iteration number 76 - loss = 0.4951847195625305\n",
      "this is the iteration number 77 - loss = 0.5179216265678406\n",
      "this is the iteration number 78 - loss = 0.500595211982727\n",
      "this is the iteration number 79 - loss = 0.5293682217597961\n",
      "this is the iteration number 80 - loss = 0.5155903697013855\n",
      "this is the iteration number 81 - loss = 0.4815647006034851\n",
      "this is the iteration number 82 - loss = 0.5246501564979553\n",
      "this is the iteration number 83 - loss = 0.5431708097457886\n",
      "this is the iteration number 84 - loss = 0.5416395664215088\n",
      "this is the iteration number 85 - loss = 0.5126283764839172\n",
      "this is the iteration number 86 - loss = 0.5422389507293701\n",
      "this is the iteration number 87 - loss = 0.4806886315345764\n",
      "this is the iteration number 88 - loss = 0.5233045816421509\n",
      "this is the iteration number 89 - loss = 0.5352540612220764\n",
      "this is the iteration number 90 - loss = 0.555696427822113\n",
      "this is the iteration number 91 - loss = 0.5473349094390869\n",
      "this is the iteration number 92 - loss = 0.5533814430236816\n",
      "this is the iteration number 93 - loss = 0.5490593910217285\n",
      "this is the iteration number 94 - loss = 0.563360333442688\n",
      "this is the iteration number 95 - loss = 0.5378333330154419\n",
      "this is the iteration number 96 - loss = 0.47709861397743225\n",
      "this is the iteration number 97 - loss = 0.48911240696907043\n",
      "this is the iteration number 98 - loss = 0.4944058060646057\n",
      "this is the iteration number 99 - loss = 0.5108803510665894\n",
      "this is the iteration number 100 - loss = 0.4894726276397705\n",
      "this is the iteration number 101 - loss = 0.5367343425750732\n",
      "this is the iteration number 0 - loss = 0.586886465549469\n",
      "this is the iteration number 1 - loss = 0.5149102807044983\n",
      "this is the iteration number 2 - loss = 0.5688524842262268\n",
      "this is the iteration number 3 - loss = 0.5569395422935486\n",
      "this is the iteration number 4 - loss = 0.5495790839195251\n",
      "this is the iteration number 5 - loss = 0.5550037622451782\n",
      "this is the iteration number 6 - loss = 0.5304117202758789\n",
      "this is the iteration number 7 - loss = 0.5145770311355591\n",
      "this is the iteration number 8 - loss = 0.49934831261634827\n",
      "this is the iteration number 9 - loss = 0.47545427083969116\n",
      "this is the iteration number 10 - loss = 0.5261290669441223\n",
      "this is the iteration number 11 - loss = 0.486149400472641\n",
      "this is the iteration number 12 - loss = 0.5323110818862915\n",
      "this is the iteration number 13 - loss = 0.5359843373298645\n",
      "this is the iteration number 14 - loss = 0.5618916749954224\n",
      "this is the iteration number 15 - loss = 0.49421510100364685\n",
      "this is the iteration number 16 - loss = 0.5066468715667725\n",
      "this is the iteration number 17 - loss = 0.5477298498153687\n",
      "this is the iteration number 18 - loss = 0.5335232019424438\n",
      "this is the iteration number 19 - loss = 0.5189642906188965\n",
      "this is the iteration number 20 - loss = 0.5234286785125732\n",
      "this is the iteration number 21 - loss = 0.5215404629707336\n",
      "this is the iteration number 22 - loss = 0.4735856056213379\n",
      "this is the iteration number 23 - loss = 0.5258857011795044\n",
      "this is the iteration number 24 - loss = 0.5559155941009521\n",
      "this is the iteration number 25 - loss = 0.5172911286354065\n",
      "this is the iteration number 26 - loss = 0.5349720120429993\n",
      "this is the iteration number 27 - loss = 0.5287384986877441\n",
      "this is the iteration number 28 - loss = 0.49020522832870483\n",
      "this is the iteration number 29 - loss = 0.560562252998352\n",
      "this is the iteration number 30 - loss = 0.4665454924106598\n",
      "this is the iteration number 31 - loss = 0.5148124098777771\n",
      "this is the iteration number 32 - loss = 0.47877272963523865\n",
      "this is the iteration number 33 - loss = 0.49418947100639343\n",
      "this is the iteration number 34 - loss = 0.49125170707702637\n",
      "this is the iteration number 35 - loss = 0.573357105255127\n",
      "this is the iteration number 36 - loss = 0.5271010994911194\n",
      "this is the iteration number 37 - loss = 0.5314999222755432\n",
      "this is the iteration number 38 - loss = 0.5270113348960876\n",
      "this is the iteration number 39 - loss = 0.5219122171401978\n",
      "this is the iteration number 40 - loss = 0.5337121486663818\n",
      "this is the iteration number 41 - loss = 0.5539907813072205\n",
      "this is the iteration number 42 - loss = 0.5710718035697937\n",
      "this is the iteration number 43 - loss = 0.5267550945281982\n",
      "this is the iteration number 44 - loss = 0.4891829490661621\n",
      "this is the iteration number 45 - loss = 0.5058037638664246\n",
      "this is the iteration number 46 - loss = 0.5377638936042786\n",
      "this is the iteration number 47 - loss = 0.4953625500202179\n",
      "this is the iteration number 48 - loss = 0.5269032120704651\n",
      "this is the iteration number 49 - loss = 0.5412254333496094\n",
      "this is the iteration number 50 - loss = 0.4323291480541229\n",
      "this is the iteration number 51 - loss = 0.5486070513725281\n",
      "this is the iteration number 52 - loss = 0.49407172203063965\n",
      "this is the iteration number 53 - loss = 0.5002015233039856\n",
      "this is the iteration number 54 - loss = 0.4760349690914154\n",
      "this is the iteration number 55 - loss = 0.518165647983551\n",
      "this is the iteration number 56 - loss = 0.5190278887748718\n",
      "this is the iteration number 57 - loss = 0.4792196750640869\n",
      "this is the iteration number 58 - loss = 0.5239979028701782\n",
      "this is the iteration number 59 - loss = 0.5289615392684937\n",
      "this is the iteration number 60 - loss = 0.5336061120033264\n",
      "this is the iteration number 61 - loss = 0.5528061985969543\n",
      "this is the iteration number 62 - loss = 0.5939029455184937\n",
      "this is the iteration number 63 - loss = 0.5258072018623352\n",
      "this is the iteration number 64 - loss = 0.5101549029350281\n",
      "this is the iteration number 65 - loss = 0.5866561532020569\n",
      "this is the iteration number 66 - loss = 0.5033729076385498\n",
      "this is the iteration number 67 - loss = 0.5255380272865295\n",
      "this is the iteration number 68 - loss = 0.47957390546798706\n",
      "this is the iteration number 69 - loss = 0.5329736471176147\n",
      "this is the iteration number 70 - loss = 0.5279924273490906\n",
      "this is the iteration number 71 - loss = 0.46683162450790405\n",
      "this is the iteration number 72 - loss = 0.45335811376571655\n",
      "this is the iteration number 73 - loss = 0.4968806207180023\n",
      "this is the iteration number 74 - loss = 0.4929613769054413\n",
      "this is the iteration number 75 - loss = 0.492540180683136\n",
      "this is the iteration number 76 - loss = 0.5589291453361511\n",
      "this is the iteration number 77 - loss = 0.4743579924106598\n",
      "this is the iteration number 78 - loss = 0.49333974719047546\n",
      "this is the iteration number 79 - loss = 0.5062236189842224\n",
      "this is the iteration number 80 - loss = 0.46939072012901306\n",
      "this is the iteration number 81 - loss = 0.5244269371032715\n",
      "this is the iteration number 82 - loss = 0.5224598050117493\n",
      "this is the iteration number 83 - loss = 0.5382627248764038\n",
      "this is the iteration number 84 - loss = 0.5068374872207642\n",
      "this is the iteration number 85 - loss = 0.5417191386222839\n",
      "this is the iteration number 86 - loss = 0.5244477987289429\n",
      "this is the iteration number 87 - loss = 0.5302621722221375\n",
      "this is the iteration number 88 - loss = 0.49010568857192993\n",
      "this is the iteration number 89 - loss = 0.5405970811843872\n",
      "this is the iteration number 90 - loss = 0.49098387360572815\n",
      "this is the iteration number 91 - loss = 0.5606632828712463\n",
      "this is the iteration number 92 - loss = 0.49542146921157837\n",
      "this is the iteration number 93 - loss = 0.48665738105773926\n",
      "this is the iteration number 94 - loss = 0.48439258337020874\n",
      "this is the iteration number 95 - loss = 0.4986564815044403\n",
      "this is the iteration number 96 - loss = 0.5265550017356873\n",
      "this is the iteration number 97 - loss = 0.5033569931983948\n",
      "this is the iteration number 98 - loss = 0.5184646844863892\n",
      "this is the iteration number 99 - loss = 0.5886419415473938\n",
      "this is the iteration number 100 - loss = 0.4718894958496094\n",
      "this is the iteration number 101 - loss = 0.5288775563240051\n",
      "this is the iteration number 0 - loss = 0.49182265996932983\n",
      "this is the iteration number 1 - loss = 0.5371902585029602\n",
      "this is the iteration number 2 - loss = 0.549871027469635\n",
      "this is the iteration number 3 - loss = 0.4773588180541992\n",
      "this is the iteration number 4 - loss = 0.5179715752601624\n",
      "this is the iteration number 5 - loss = 0.4934617578983307\n",
      "this is the iteration number 6 - loss = 0.4762851297855377\n",
      "this is the iteration number 7 - loss = 0.5567640662193298\n",
      "this is the iteration number 8 - loss = 0.5414422750473022\n",
      "this is the iteration number 9 - loss = 0.5092037916183472\n",
      "this is the iteration number 10 - loss = 0.520736813545227\n",
      "this is the iteration number 11 - loss = 0.5005731582641602\n",
      "this is the iteration number 12 - loss = 0.5233141183853149\n",
      "this is the iteration number 13 - loss = 0.5350372195243835\n",
      "this is the iteration number 14 - loss = 0.5239042043685913\n",
      "this is the iteration number 15 - loss = 0.5507660508155823\n",
      "this is the iteration number 16 - loss = 0.5604137778282166\n",
      "this is the iteration number 17 - loss = 0.5442601442337036\n",
      "this is the iteration number 18 - loss = 0.554336667060852\n",
      "this is the iteration number 19 - loss = 0.4858977198600769\n",
      "this is the iteration number 20 - loss = 0.5040736198425293\n",
      "this is the iteration number 21 - loss = 0.44720524549484253\n",
      "this is the iteration number 22 - loss = 0.49050942063331604\n",
      "this is the iteration number 23 - loss = 0.5518321394920349\n",
      "this is the iteration number 24 - loss = 0.5533332228660583\n",
      "this is the iteration number 25 - loss = 0.4648769497871399\n",
      "this is the iteration number 26 - loss = 0.5696665048599243\n",
      "this is the iteration number 27 - loss = 0.5282799601554871\n",
      "this is the iteration number 28 - loss = 0.48774316906929016\n",
      "this is the iteration number 29 - loss = 0.5019697546958923\n",
      "this is the iteration number 30 - loss = 0.5187918543815613\n",
      "this is the iteration number 31 - loss = 0.5163968801498413\n",
      "this is the iteration number 32 - loss = 0.4909377098083496\n",
      "this is the iteration number 33 - loss = 0.5309510827064514\n",
      "this is the iteration number 34 - loss = 0.5105868577957153\n",
      "this is the iteration number 35 - loss = 0.518323540687561\n",
      "this is the iteration number 36 - loss = 0.44004470109939575\n",
      "this is the iteration number 37 - loss = 0.5321534276008606\n",
      "this is the iteration number 38 - loss = 0.4842486083507538\n",
      "this is the iteration number 39 - loss = 0.5048812627792358\n",
      "this is the iteration number 40 - loss = 0.5227596163749695\n",
      "this is the iteration number 41 - loss = 0.521234393119812\n",
      "this is the iteration number 42 - loss = 0.48855939507484436\n",
      "this is the iteration number 43 - loss = 0.5181326270103455\n",
      "this is the iteration number 44 - loss = 0.5330389142036438\n",
      "this is the iteration number 45 - loss = 0.5200330018997192\n",
      "this is the iteration number 46 - loss = 0.521198570728302\n",
      "this is the iteration number 47 - loss = 0.5705697536468506\n",
      "this is the iteration number 48 - loss = 0.5405780076980591\n",
      "this is the iteration number 49 - loss = 0.4835355281829834\n",
      "this is the iteration number 50 - loss = 0.5473235845565796\n",
      "this is the iteration number 51 - loss = 0.541244387626648\n",
      "this is the iteration number 52 - loss = 0.5612717270851135\n",
      "this is the iteration number 53 - loss = 0.4710504114627838\n",
      "this is the iteration number 54 - loss = 0.4601114094257355\n",
      "this is the iteration number 55 - loss = 0.5490041971206665\n",
      "this is the iteration number 56 - loss = 0.5069918632507324\n",
      "this is the iteration number 57 - loss = 0.4684869349002838\n",
      "this is the iteration number 58 - loss = 0.5107899308204651\n",
      "this is the iteration number 59 - loss = 0.5035354495048523\n",
      "this is the iteration number 60 - loss = 0.5364576578140259\n",
      "this is the iteration number 61 - loss = 0.4870089888572693\n",
      "this is the iteration number 62 - loss = 0.5050287246704102\n",
      "this is the iteration number 63 - loss = 0.5214194655418396\n",
      "this is the iteration number 64 - loss = 0.5953277349472046\n",
      "this is the iteration number 65 - loss = 0.5218057036399841\n",
      "this is the iteration number 66 - loss = 0.501924455165863\n",
      "this is the iteration number 67 - loss = 0.4483110010623932\n",
      "this is the iteration number 68 - loss = 0.536807656288147\n",
      "this is the iteration number 69 - loss = 0.5185366868972778\n",
      "this is the iteration number 70 - loss = 0.4897543489933014\n",
      "this is the iteration number 71 - loss = 0.5987967252731323\n",
      "this is the iteration number 72 - loss = 0.5091191530227661\n",
      "this is the iteration number 73 - loss = 0.49858126044273376\n",
      "this is the iteration number 74 - loss = 0.5226897597312927\n",
      "this is the iteration number 75 - loss = 0.5142690539360046\n",
      "this is the iteration number 76 - loss = 0.4880901873111725\n",
      "this is the iteration number 77 - loss = 0.5263653993606567\n",
      "this is the iteration number 78 - loss = 0.465730756521225\n",
      "this is the iteration number 79 - loss = 0.5472785830497742\n",
      "this is the iteration number 80 - loss = 0.49982476234436035\n",
      "this is the iteration number 81 - loss = 0.493237167596817\n",
      "this is the iteration number 82 - loss = 0.4832698702812195\n",
      "this is the iteration number 83 - loss = 0.5251054167747498\n",
      "this is the iteration number 84 - loss = 0.5914639234542847\n",
      "this is the iteration number 85 - loss = 0.5288589596748352\n",
      "this is the iteration number 86 - loss = 0.5045347809791565\n",
      "this is the iteration number 87 - loss = 0.5000864267349243\n",
      "this is the iteration number 88 - loss = 0.47182172536849976\n",
      "this is the iteration number 89 - loss = 0.5340222716331482\n",
      "this is the iteration number 90 - loss = 0.46064522862434387\n",
      "this is the iteration number 91 - loss = 0.5422734022140503\n",
      "this is the iteration number 92 - loss = 0.4804166257381439\n",
      "this is the iteration number 93 - loss = 0.5822099447250366\n",
      "this is the iteration number 94 - loss = 0.46540841460227966\n",
      "this is the iteration number 95 - loss = 0.5115178823471069\n",
      "this is the iteration number 96 - loss = 0.4460345208644867\n",
      "this is the iteration number 97 - loss = 0.5662149786949158\n",
      "this is the iteration number 98 - loss = 0.5334295034408569\n",
      "this is the iteration number 99 - loss = 0.5494920611381531\n",
      "this is the iteration number 100 - loss = 0.5050203204154968\n",
      "this is the iteration number 101 - loss = 0.5763953924179077\n",
      "this is the iteration number 0 - loss = 0.5342459082603455\n",
      "this is the iteration number 1 - loss = 0.458989679813385\n",
      "this is the iteration number 2 - loss = 0.4972192645072937\n",
      "this is the iteration number 3 - loss = 0.542252242565155\n",
      "this is the iteration number 4 - loss = 0.44769248366355896\n",
      "this is the iteration number 5 - loss = 0.5199041366577148\n",
      "this is the iteration number 6 - loss = 0.4963114857673645\n",
      "this is the iteration number 7 - loss = 0.5163038969039917\n",
      "this is the iteration number 8 - loss = 0.4614984095096588\n",
      "this is the iteration number 9 - loss = 0.48166424036026\n",
      "this is the iteration number 10 - loss = 0.4953037202358246\n",
      "this is the iteration number 11 - loss = 0.5224204659461975\n",
      "this is the iteration number 12 - loss = 0.5301200747489929\n",
      "this is the iteration number 13 - loss = 0.5210356116294861\n",
      "this is the iteration number 14 - loss = 0.5473821759223938\n",
      "this is the iteration number 15 - loss = 0.5577086806297302\n",
      "this is the iteration number 16 - loss = 0.5876421928405762\n",
      "this is the iteration number 17 - loss = 0.5062933564186096\n",
      "this is the iteration number 18 - loss = 0.4574868679046631\n",
      "this is the iteration number 19 - loss = 0.5164341926574707\n",
      "this is the iteration number 20 - loss = 0.45942917466163635\n",
      "this is the iteration number 21 - loss = 0.5162866711616516\n",
      "this is the iteration number 22 - loss = 0.4870641231536865\n",
      "this is the iteration number 23 - loss = 0.5380505919456482\n",
      "this is the iteration number 24 - loss = 0.4992985427379608\n",
      "this is the iteration number 25 - loss = 0.48532000184059143\n",
      "this is the iteration number 26 - loss = 0.4575825333595276\n",
      "this is the iteration number 27 - loss = 0.5102519989013672\n",
      "this is the iteration number 28 - loss = 0.5137888789176941\n",
      "this is the iteration number 29 - loss = 0.47854405641555786\n",
      "this is the iteration number 30 - loss = 0.5614059567451477\n",
      "this is the iteration number 31 - loss = 0.5260088443756104\n",
      "this is the iteration number 32 - loss = 0.5093051195144653\n",
      "this is the iteration number 33 - loss = 0.5169498324394226\n",
      "this is the iteration number 34 - loss = 0.4960257411003113\n",
      "this is the iteration number 35 - loss = 0.5368191003799438\n",
      "this is the iteration number 36 - loss = 0.4852706491947174\n",
      "this is the iteration number 37 - loss = 0.5632593035697937\n",
      "this is the iteration number 38 - loss = 0.511350154876709\n",
      "this is the iteration number 39 - loss = 0.5376332998275757\n",
      "this is the iteration number 40 - loss = 0.4895777404308319\n",
      "this is the iteration number 41 - loss = 0.5377696752548218\n",
      "this is the iteration number 42 - loss = 0.4873511791229248\n",
      "this is the iteration number 43 - loss = 0.5422295331954956\n",
      "this is the iteration number 44 - loss = 0.5164753198623657\n",
      "this is the iteration number 45 - loss = 0.5181625485420227\n",
      "this is the iteration number 46 - loss = 0.5512697100639343\n",
      "this is the iteration number 47 - loss = 0.5232707858085632\n",
      "this is the iteration number 48 - loss = 0.5048525333404541\n",
      "this is the iteration number 49 - loss = 0.5204591155052185\n",
      "this is the iteration number 50 - loss = 0.5227895379066467\n",
      "this is the iteration number 51 - loss = 0.5429512858390808\n",
      "this is the iteration number 52 - loss = 0.47671955823898315\n",
      "this is the iteration number 53 - loss = 0.4808173179626465\n",
      "this is the iteration number 54 - loss = 0.5070657134056091\n",
      "this is the iteration number 55 - loss = 0.5097960233688354\n",
      "this is the iteration number 56 - loss = 0.47357597947120667\n",
      "this is the iteration number 57 - loss = 0.5323520302772522\n",
      "this is the iteration number 58 - loss = 0.4510509669780731\n",
      "this is the iteration number 59 - loss = 0.5048648715019226\n",
      "this is the iteration number 60 - loss = 0.5494869351387024\n",
      "this is the iteration number 61 - loss = 0.5504902601242065\n",
      "this is the iteration number 62 - loss = 0.502933144569397\n",
      "this is the iteration number 63 - loss = 0.5339263081550598\n",
      "this is the iteration number 64 - loss = 0.5318921208381653\n",
      "this is the iteration number 65 - loss = 0.49343082308769226\n",
      "this is the iteration number 66 - loss = 0.5148721933364868\n",
      "this is the iteration number 67 - loss = 0.49892422556877136\n",
      "this is the iteration number 68 - loss = 0.4984925389289856\n",
      "this is the iteration number 69 - loss = 0.5105723738670349\n",
      "this is the iteration number 70 - loss = 0.5203450322151184\n",
      "this is the iteration number 71 - loss = 0.5196465253829956\n",
      "this is the iteration number 72 - loss = 0.5084362626075745\n",
      "this is the iteration number 73 - loss = 0.5665653944015503\n",
      "this is the iteration number 74 - loss = 0.5036786794662476\n",
      "this is the iteration number 75 - loss = 0.5265308618545532\n",
      "this is the iteration number 76 - loss = 0.5328788161277771\n",
      "this is the iteration number 77 - loss = 0.47708600759506226\n",
      "this is the iteration number 78 - loss = 0.5265437960624695\n",
      "this is the iteration number 79 - loss = 0.490339994430542\n",
      "this is the iteration number 80 - loss = 0.47453543543815613\n",
      "this is the iteration number 81 - loss = 0.5557944178581238\n",
      "this is the iteration number 82 - loss = 0.47266292572021484\n",
      "this is the iteration number 83 - loss = 0.515816330909729\n",
      "this is the iteration number 84 - loss = 0.49710389971733093\n",
      "this is the iteration number 85 - loss = 0.5078054070472717\n",
      "this is the iteration number 86 - loss = 0.5788801908493042\n",
      "this is the iteration number 87 - loss = 0.5040168166160583\n",
      "this is the iteration number 88 - loss = 0.5037482380867004\n",
      "this is the iteration number 89 - loss = 0.5361298322677612\n",
      "this is the iteration number 90 - loss = 0.556763231754303\n",
      "this is the iteration number 91 - loss = 0.4837369918823242\n",
      "this is the iteration number 92 - loss = 0.6164094805717468\n",
      "this is the iteration number 93 - loss = 0.5332983136177063\n",
      "this is the iteration number 94 - loss = 0.4894968867301941\n",
      "this is the iteration number 95 - loss = 0.5150827765464783\n",
      "this is the iteration number 96 - loss = 0.492270290851593\n",
      "this is the iteration number 97 - loss = 0.5136369466781616\n",
      "this is the iteration number 98 - loss = 0.513915479183197\n",
      "this is the iteration number 99 - loss = 0.48866981267929077\n",
      "this is the iteration number 100 - loss = 0.5046740174293518\n",
      "this is the iteration number 101 - loss = 0.4678870439529419\n",
      "this is the iteration number 0 - loss = 0.574135422706604\n",
      "this is the iteration number 1 - loss = 0.5044723153114319\n",
      "this is the iteration number 2 - loss = 0.5125356316566467\n",
      "this is the iteration number 3 - loss = 0.5511075258255005\n",
      "this is the iteration number 4 - loss = 0.5455905795097351\n",
      "this is the iteration number 5 - loss = 0.5432978868484497\n",
      "this is the iteration number 6 - loss = 0.532859206199646\n",
      "this is the iteration number 7 - loss = 0.5043033361434937\n",
      "this is the iteration number 8 - loss = 0.5389795899391174\n",
      "this is the iteration number 9 - loss = 0.49384573101997375\n",
      "this is the iteration number 10 - loss = 0.5525582432746887\n",
      "this is the iteration number 11 - loss = 0.48984602093696594\n",
      "this is the iteration number 12 - loss = 0.5639275908470154\n",
      "this is the iteration number 13 - loss = 0.5156428217887878\n",
      "this is the iteration number 14 - loss = 0.5081428289413452\n",
      "this is the iteration number 15 - loss = 0.5588173866271973\n",
      "this is the iteration number 16 - loss = 0.4907168745994568\n",
      "this is the iteration number 17 - loss = 0.5043290257453918\n",
      "this is the iteration number 18 - loss = 0.562885582447052\n",
      "this is the iteration number 19 - loss = 0.5478038787841797\n",
      "this is the iteration number 20 - loss = 0.5144414901733398\n",
      "this is the iteration number 21 - loss = 0.48840904235839844\n",
      "this is the iteration number 22 - loss = 0.49904385209083557\n",
      "this is the iteration number 23 - loss = 0.5054655075073242\n",
      "this is the iteration number 24 - loss = 0.4584229588508606\n",
      "this is the iteration number 25 - loss = 0.5235853791236877\n",
      "this is the iteration number 26 - loss = 0.5040948987007141\n",
      "this is the iteration number 27 - loss = 0.4537854790687561\n",
      "this is the iteration number 28 - loss = 0.5513867735862732\n",
      "this is the iteration number 29 - loss = 0.4894162714481354\n",
      "this is the iteration number 30 - loss = 0.4960581958293915\n",
      "this is the iteration number 31 - loss = 0.5158604383468628\n",
      "this is the iteration number 32 - loss = 0.5205256938934326\n",
      "this is the iteration number 33 - loss = 0.4683784544467926\n",
      "this is the iteration number 34 - loss = 0.44132301211357117\n",
      "this is the iteration number 35 - loss = 0.5616822838783264\n",
      "this is the iteration number 36 - loss = 0.4683743417263031\n",
      "this is the iteration number 37 - loss = 0.4637799561023712\n",
      "this is the iteration number 38 - loss = 0.49016183614730835\n",
      "this is the iteration number 39 - loss = 0.5137245059013367\n",
      "this is the iteration number 40 - loss = 0.5373526215553284\n",
      "this is the iteration number 41 - loss = 0.45780691504478455\n",
      "this is the iteration number 42 - loss = 0.5017088055610657\n",
      "this is the iteration number 43 - loss = 0.5228642821311951\n",
      "this is the iteration number 44 - loss = 0.502707302570343\n",
      "this is the iteration number 45 - loss = 0.5030635595321655\n",
      "this is the iteration number 46 - loss = 0.4745032787322998\n",
      "this is the iteration number 47 - loss = 0.5237656831741333\n",
      "this is the iteration number 48 - loss = 0.524441659450531\n",
      "this is the iteration number 49 - loss = 0.5087785124778748\n",
      "this is the iteration number 50 - loss = 0.5153194069862366\n",
      "this is the iteration number 51 - loss = 0.4730979800224304\n",
      "this is the iteration number 52 - loss = 0.5704912543296814\n",
      "this is the iteration number 53 - loss = 0.4506078362464905\n",
      "this is the iteration number 54 - loss = 0.5250040292739868\n",
      "this is the iteration number 55 - loss = 0.4721544086933136\n",
      "this is the iteration number 56 - loss = 0.5323879718780518\n",
      "this is the iteration number 57 - loss = 0.4536956250667572\n",
      "this is the iteration number 58 - loss = 0.5175983309745789\n",
      "this is the iteration number 59 - loss = 0.5578614473342896\n",
      "this is the iteration number 60 - loss = 0.5095316767692566\n",
      "this is the iteration number 61 - loss = 0.576999843120575\n",
      "this is the iteration number 62 - loss = 0.46351829171180725\n",
      "this is the iteration number 63 - loss = 0.5311692953109741\n",
      "this is the iteration number 64 - loss = 0.5123254656791687\n",
      "this is the iteration number 65 - loss = 0.4853805899620056\n",
      "this is the iteration number 66 - loss = 0.4984373152256012\n",
      "this is the iteration number 67 - loss = 0.49951013922691345\n",
      "this is the iteration number 68 - loss = 0.45396512746810913\n",
      "this is the iteration number 69 - loss = 0.46630358695983887\n",
      "this is the iteration number 70 - loss = 0.5072785019874573\n",
      "this is the iteration number 71 - loss = 0.521203875541687\n",
      "this is the iteration number 72 - loss = 0.48563334345817566\n",
      "this is the iteration number 73 - loss = 0.5159046053886414\n",
      "this is the iteration number 74 - loss = 0.4585469365119934\n",
      "this is the iteration number 75 - loss = 0.48748835921287537\n",
      "this is the iteration number 76 - loss = 0.5303248763084412\n",
      "this is the iteration number 77 - loss = 0.47554853558540344\n",
      "this is the iteration number 78 - loss = 0.540407657623291\n",
      "this is the iteration number 79 - loss = 0.5003753304481506\n",
      "this is the iteration number 80 - loss = 0.5191857218742371\n",
      "this is the iteration number 81 - loss = 0.4904949963092804\n",
      "this is the iteration number 82 - loss = 0.49856284260749817\n",
      "this is the iteration number 83 - loss = 0.5312119722366333\n",
      "this is the iteration number 84 - loss = 0.5319237112998962\n",
      "this is the iteration number 85 - loss = 0.47771191596984863\n",
      "this is the iteration number 86 - loss = 0.5175865888595581\n",
      "this is the iteration number 87 - loss = 0.5094594955444336\n",
      "this is the iteration number 88 - loss = 0.5130497217178345\n",
      "this is the iteration number 89 - loss = 0.47878211736679077\n",
      "this is the iteration number 90 - loss = 0.4742012023925781\n",
      "this is the iteration number 91 - loss = 0.5438054203987122\n",
      "this is the iteration number 92 - loss = 0.5435600280761719\n",
      "this is the iteration number 93 - loss = 0.4929981231689453\n",
      "this is the iteration number 94 - loss = 0.5131681561470032\n",
      "this is the iteration number 95 - loss = 0.5195261240005493\n",
      "this is the iteration number 96 - loss = 0.5354604721069336\n",
      "this is the iteration number 97 - loss = 0.563525378704071\n",
      "this is the iteration number 98 - loss = 0.5795760750770569\n",
      "this is the iteration number 99 - loss = 0.4892415404319763\n",
      "this is the iteration number 100 - loss = 0.5321758389472961\n",
      "this is the iteration number 101 - loss = 0.4629649221897125\n",
      "this is the iteration number 0 - loss = 0.4618743062019348\n",
      "this is the iteration number 1 - loss = 0.4768930971622467\n",
      "this is the iteration number 2 - loss = 0.5180884599685669\n",
      "this is the iteration number 3 - loss = 0.5061602592468262\n",
      "this is the iteration number 4 - loss = 0.48414093255996704\n",
      "this is the iteration number 5 - loss = 0.48790496587753296\n",
      "this is the iteration number 6 - loss = 0.4668292999267578\n",
      "this is the iteration number 7 - loss = 0.5610266923904419\n",
      "this is the iteration number 8 - loss = 0.49211379885673523\n",
      "this is the iteration number 9 - loss = 0.48107266426086426\n",
      "this is the iteration number 10 - loss = 0.5238367319107056\n",
      "this is the iteration number 11 - loss = 0.5588250160217285\n",
      "this is the iteration number 12 - loss = 0.4658619463443756\n",
      "this is the iteration number 13 - loss = 0.5590570569038391\n",
      "this is the iteration number 14 - loss = 0.4985923171043396\n",
      "this is the iteration number 15 - loss = 0.5047076344490051\n",
      "this is the iteration number 16 - loss = 0.5397698879241943\n",
      "this is the iteration number 17 - loss = 0.5358157753944397\n",
      "this is the iteration number 18 - loss = 0.47768542170524597\n",
      "this is the iteration number 19 - loss = 0.5317046046257019\n",
      "this is the iteration number 20 - loss = 0.5394309759140015\n",
      "this is the iteration number 21 - loss = 0.5065887570381165\n",
      "this is the iteration number 22 - loss = 0.5178363919258118\n",
      "this is the iteration number 23 - loss = 0.5819350481033325\n",
      "this is the iteration number 24 - loss = 0.5360746383666992\n",
      "this is the iteration number 25 - loss = 0.5007852911949158\n",
      "this is the iteration number 26 - loss = 0.5085864067077637\n",
      "this is the iteration number 27 - loss = 0.5236750245094299\n",
      "this is the iteration number 28 - loss = 0.5168476700782776\n",
      "this is the iteration number 29 - loss = 0.5184990763664246\n",
      "this is the iteration number 30 - loss = 0.47220858931541443\n",
      "this is the iteration number 31 - loss = 0.5096407532691956\n",
      "this is the iteration number 32 - loss = 0.5118811726570129\n",
      "this is the iteration number 33 - loss = 0.48149827122688293\n",
      "this is the iteration number 34 - loss = 0.5008561015129089\n",
      "this is the iteration number 35 - loss = 0.501764178276062\n",
      "this is the iteration number 36 - loss = 0.4791077971458435\n",
      "this is the iteration number 37 - loss = 0.5275620222091675\n",
      "this is the iteration number 38 - loss = 0.4967731535434723\n",
      "this is the iteration number 39 - loss = 0.5344181656837463\n",
      "this is the iteration number 40 - loss = 0.5197890996932983\n",
      "this is the iteration number 41 - loss = 0.5453915596008301\n",
      "this is the iteration number 42 - loss = 0.5097487568855286\n",
      "this is the iteration number 43 - loss = 0.4857749342918396\n",
      "this is the iteration number 44 - loss = 0.4800448417663574\n",
      "this is the iteration number 45 - loss = 0.5349711775779724\n",
      "this is the iteration number 46 - loss = 0.4908445477485657\n",
      "this is the iteration number 47 - loss = 0.5430055260658264\n",
      "this is the iteration number 48 - loss = 0.4615214169025421\n",
      "this is the iteration number 49 - loss = 0.48284462094306946\n",
      "this is the iteration number 50 - loss = 0.5338433980941772\n",
      "this is the iteration number 51 - loss = 0.5267350077629089\n",
      "this is the iteration number 52 - loss = 0.4982469975948334\n",
      "this is the iteration number 53 - loss = 0.46537265181541443\n",
      "this is the iteration number 54 - loss = 0.5275269150733948\n",
      "this is the iteration number 55 - loss = 0.49608802795410156\n",
      "this is the iteration number 56 - loss = 0.48826339840888977\n",
      "this is the iteration number 57 - loss = 0.45424649119377136\n",
      "this is the iteration number 58 - loss = 0.5021712779998779\n",
      "this is the iteration number 59 - loss = 0.46301355957984924\n",
      "this is the iteration number 60 - loss = 0.4906342625617981\n",
      "this is the iteration number 61 - loss = 0.5153208374977112\n",
      "this is the iteration number 62 - loss = 0.4886244833469391\n",
      "this is the iteration number 63 - loss = 0.5131832361221313\n",
      "this is the iteration number 64 - loss = 0.494041383266449\n",
      "this is the iteration number 65 - loss = 0.46217846870422363\n",
      "this is the iteration number 66 - loss = 0.513360857963562\n",
      "this is the iteration number 67 - loss = 0.5361743569374084\n",
      "this is the iteration number 68 - loss = 0.5080736875534058\n",
      "this is the iteration number 69 - loss = 0.5364049673080444\n",
      "this is the iteration number 70 - loss = 0.5851570963859558\n",
      "this is the iteration number 71 - loss = 0.5447372794151306\n",
      "this is the iteration number 72 - loss = 0.5448799729347229\n",
      "this is the iteration number 73 - loss = 0.5059307813644409\n",
      "this is the iteration number 74 - loss = 0.5592629909515381\n",
      "this is the iteration number 75 - loss = 0.5279622077941895\n",
      "this is the iteration number 76 - loss = 0.4983336925506592\n",
      "this is the iteration number 77 - loss = 0.525127112865448\n",
      "this is the iteration number 78 - loss = 0.47114044427871704\n",
      "this is the iteration number 79 - loss = 0.5337706804275513\n",
      "this is the iteration number 80 - loss = 0.547299861907959\n",
      "this is the iteration number 81 - loss = 0.49333837628364563\n",
      "this is the iteration number 82 - loss = 0.505791187286377\n",
      "this is the iteration number 83 - loss = 0.4973227083683014\n",
      "this is the iteration number 84 - loss = 0.4996238648891449\n",
      "this is the iteration number 85 - loss = 0.4966127872467041\n",
      "this is the iteration number 86 - loss = 0.4950510859489441\n",
      "this is the iteration number 87 - loss = 0.5582908987998962\n",
      "this is the iteration number 88 - loss = 0.515351414680481\n",
      "this is the iteration number 89 - loss = 0.509210467338562\n",
      "this is the iteration number 90 - loss = 0.5100516080856323\n",
      "this is the iteration number 91 - loss = 0.4656520485877991\n",
      "this is the iteration number 92 - loss = 0.5351750254631042\n",
      "this is the iteration number 93 - loss = 0.5099413394927979\n",
      "this is the iteration number 94 - loss = 0.4613471031188965\n",
      "this is the iteration number 95 - loss = 0.4927690923213959\n",
      "this is the iteration number 96 - loss = 0.45890361070632935\n",
      "this is the iteration number 97 - loss = 0.4822627604007721\n",
      "this is the iteration number 98 - loss = 0.47836998105049133\n",
      "this is the iteration number 99 - loss = 0.45744067430496216\n",
      "this is the iteration number 100 - loss = 0.5092028379440308\n",
      "this is the iteration number 101 - loss = 0.4812372028827667\n",
      "this is the iteration number 0 - loss = 0.5030784010887146\n",
      "this is the iteration number 1 - loss = 0.5236172080039978\n",
      "this is the iteration number 2 - loss = 0.44894319772720337\n",
      "this is the iteration number 3 - loss = 0.48348551988601685\n",
      "this is the iteration number 4 - loss = 0.5170825123786926\n",
      "this is the iteration number 5 - loss = 0.5083434581756592\n",
      "this is the iteration number 6 - loss = 0.5076465010643005\n",
      "this is the iteration number 7 - loss = 0.5452233552932739\n",
      "this is the iteration number 8 - loss = 0.5817230939865112\n",
      "this is the iteration number 9 - loss = 0.5023760199546814\n",
      "this is the iteration number 10 - loss = 0.5334300398826599\n",
      "this is the iteration number 11 - loss = 0.4829048812389374\n",
      "this is the iteration number 12 - loss = 0.5089823603630066\n",
      "this is the iteration number 13 - loss = 0.5520538687705994\n",
      "this is the iteration number 14 - loss = 0.5528727173805237\n",
      "this is the iteration number 15 - loss = 0.5651155710220337\n",
      "this is the iteration number 16 - loss = 0.5255104303359985\n",
      "this is the iteration number 17 - loss = 0.5140091776847839\n",
      "this is the iteration number 18 - loss = 0.41112571954727173\n",
      "this is the iteration number 19 - loss = 0.5382406115531921\n",
      "this is the iteration number 20 - loss = 0.4824005961418152\n",
      "this is the iteration number 21 - loss = 0.4574025571346283\n",
      "this is the iteration number 22 - loss = 0.4803927540779114\n",
      "this is the iteration number 23 - loss = 0.5304386019706726\n",
      "this is the iteration number 24 - loss = 0.5469832420349121\n",
      "this is the iteration number 25 - loss = 0.4815126955509186\n",
      "this is the iteration number 26 - loss = 0.5540488958358765\n",
      "this is the iteration number 27 - loss = 0.5376855134963989\n",
      "this is the iteration number 28 - loss = 0.5023787617683411\n",
      "this is the iteration number 29 - loss = 0.5322818756103516\n",
      "this is the iteration number 30 - loss = 0.507250964641571\n",
      "this is the iteration number 31 - loss = 0.4703395366668701\n",
      "this is the iteration number 32 - loss = 0.4915389120578766\n",
      "this is the iteration number 33 - loss = 0.44447633624076843\n",
      "this is the iteration number 34 - loss = 0.5112885236740112\n",
      "this is the iteration number 35 - loss = 0.4711722433567047\n",
      "this is the iteration number 36 - loss = 0.4544389843940735\n",
      "this is the iteration number 37 - loss = 0.4721524119377136\n",
      "this is the iteration number 38 - loss = 0.5072574615478516\n",
      "this is the iteration number 39 - loss = 0.4916188716888428\n",
      "this is the iteration number 40 - loss = 0.4948936104774475\n",
      "this is the iteration number 41 - loss = 0.5610493421554565\n",
      "this is the iteration number 42 - loss = 0.5161882042884827\n",
      "this is the iteration number 43 - loss = 0.4872210919857025\n",
      "this is the iteration number 44 - loss = 0.5202946662902832\n",
      "this is the iteration number 45 - loss = 0.5664066672325134\n",
      "this is the iteration number 46 - loss = 0.48772135376930237\n",
      "this is the iteration number 47 - loss = 0.47372835874557495\n",
      "this is the iteration number 48 - loss = 0.483929842710495\n",
      "this is the iteration number 49 - loss = 0.517596960067749\n",
      "this is the iteration number 50 - loss = 0.4970061480998993\n",
      "this is the iteration number 51 - loss = 0.5237637162208557\n",
      "this is the iteration number 52 - loss = 0.4935459494590759\n",
      "this is the iteration number 53 - loss = 0.49965885281562805\n",
      "this is the iteration number 54 - loss = 0.5162272453308105\n",
      "this is the iteration number 55 - loss = 0.5198449492454529\n",
      "this is the iteration number 56 - loss = 0.5245476961135864\n",
      "this is the iteration number 57 - loss = 0.5383426547050476\n",
      "this is the iteration number 58 - loss = 0.5293256044387817\n",
      "this is the iteration number 59 - loss = 0.4821074604988098\n",
      "this is the iteration number 60 - loss = 0.47117048501968384\n",
      "this is the iteration number 61 - loss = 0.5102820992469788\n",
      "this is the iteration number 62 - loss = 0.5186017155647278\n",
      "this is the iteration number 63 - loss = 0.5232376456260681\n",
      "this is the iteration number 64 - loss = 0.5105888843536377\n",
      "this is the iteration number 65 - loss = 0.45830583572387695\n",
      "this is the iteration number 66 - loss = 0.4896262288093567\n",
      "this is the iteration number 67 - loss = 0.5367081761360168\n",
      "this is the iteration number 68 - loss = 0.49864858388900757\n",
      "this is the iteration number 69 - loss = 0.4726000726222992\n",
      "this is the iteration number 70 - loss = 0.4766952693462372\n",
      "this is the iteration number 71 - loss = 0.5022155046463013\n",
      "this is the iteration number 72 - loss = 0.4963386058807373\n",
      "this is the iteration number 73 - loss = 0.47596243023872375\n",
      "this is the iteration number 74 - loss = 0.43691498041152954\n",
      "this is the iteration number 75 - loss = 0.5758639574050903\n",
      "this is the iteration number 76 - loss = 0.5256556868553162\n",
      "this is the iteration number 77 - loss = 0.491664320230484\n",
      "this is the iteration number 78 - loss = 0.44578665494918823\n",
      "this is the iteration number 79 - loss = 0.4970671534538269\n",
      "this is the iteration number 80 - loss = 0.5148537755012512\n",
      "this is the iteration number 81 - loss = 0.4781036674976349\n",
      "this is the iteration number 82 - loss = 0.5435668230056763\n",
      "this is the iteration number 83 - loss = 0.47343721985816956\n",
      "this is the iteration number 84 - loss = 0.49906012415885925\n",
      "this is the iteration number 85 - loss = 0.4725005328655243\n",
      "this is the iteration number 86 - loss = 0.5667127370834351\n",
      "this is the iteration number 87 - loss = 0.5493396520614624\n",
      "this is the iteration number 88 - loss = 0.46203914284706116\n",
      "this is the iteration number 89 - loss = 0.5161609053611755\n",
      "this is the iteration number 90 - loss = 0.48914626240730286\n",
      "this is the iteration number 91 - loss = 0.5115382075309753\n",
      "this is the iteration number 92 - loss = 0.45616722106933594\n",
      "this is the iteration number 93 - loss = 0.5113667249679565\n",
      "this is the iteration number 94 - loss = 0.48808881640434265\n",
      "this is the iteration number 95 - loss = 0.5153909921646118\n",
      "this is the iteration number 96 - loss = 0.5616129636764526\n",
      "this is the iteration number 97 - loss = 0.4500059485435486\n",
      "this is the iteration number 98 - loss = 0.5029165148735046\n",
      "this is the iteration number 99 - loss = 0.51609206199646\n",
      "this is the iteration number 100 - loss = 0.5515322685241699\n",
      "this is the iteration number 101 - loss = 0.5118108987808228\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(20):\n",
    "    for index, (X,y) in enumerate(train_loader):\n",
    "        \n",
    "        prediction = model(X)\n",
    "\n",
    "        loss = criterion(prediction,y.type(torch.long))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'this is the iteration number {index} - loss = {loss}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.max(prediction,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.max(model(X_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8309859154929577"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([(v == y_test[i]).numpy() for i,v  in enumerate(indices)])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_test = torch.concat((X_test, y_test.unsqueeze(1)), dim=1)\n",
    "\n",
    "testloader = DataLoader(dataset=tensor_ds(tensor_train), batch_size=math.floor(X_train.shape[0]/100), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: no_avc is 89.7 %\n",
      "Accuracy for class: avc   is 66.0 %\n"
     ]
    }
   ],
   "source": [
    "correct_pred = {classname: 0 for classname in ['no_avc','avc']}\n",
    "total_pred = {classname: 0 for classname in ['no_avc','avc']}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        symptoms, labels = data\n",
    "        outputs = model(symptoms)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[['no_avc','avc'][int(label)]] += 1\n",
    "            total_pred[['no_avc','avc'][int(label)]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dc_claas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19b3c190b9d69770ce2ddeaf9d52a9dde852f18a5bf9768f2dbe8da33de81e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
